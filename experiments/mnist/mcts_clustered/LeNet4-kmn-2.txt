Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'kmn'], random_seed=2, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7f6f3aa80f28>, tc2=<function tc2 at 0x7f6f3aa91048>, tc3=<function tc3 at 0x7f6f3aa91158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 11.7254
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7297f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729ba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729a58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.03521126760563398 3
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729eb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729a58> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.07042253521126796 4
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7352e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.10563380281690193 5
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729a58> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.10563380281690193 6
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7297f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.10563380281690193 7
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735128> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.10563380281690193 8
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.10563380281690193 9
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.10563380281690193 10
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735208> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.1408450704225359 11
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735128> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.1408450704225359 12
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729eb8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729a58> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.1408450704225359 13
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729c18> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.1760563380281699 14
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfba8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729c18> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.24647887323943785 15
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7297f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.24647887323943785 16
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.24647887323943785 17
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1390> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.2816901408450718 18
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729c18> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.2816901408450718 19
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729a58> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.2816901408450718 20
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #0
root
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729c50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.3169014084507058 21
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.3169014084507058 22
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.3521126760563398 23
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.38732394366197376 24
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7356d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.42253521126760774 25
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf780> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.4929577464788757 26
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1278> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.3169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.5281690140845097 27
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.3169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.5281690140845097 28
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729c50> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.3169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.5281690140845097 29
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1e80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.3521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.5633802816901436 30
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.3521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.5633802816901436 31
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.38732394366197376 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.5985915492957776 32
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.38732394366197376 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.5985915492957776 33
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.38732394366197376 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.5985915492957776 34
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1d68> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.42253521126760774 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.6338028169014116 35
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.42253521126760774 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.6338028169014116 36
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6951d0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.1760563380281699 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.4929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.7042253521126796 37
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695f98> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.21126760563380387 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.5281690140845097 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.7394366197183135 38
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #2
root->2->7
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2278> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.24647887323943785 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.2816901408450718 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.5985915492957776 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.8098591549295815 39
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.3169014084507058 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.3521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.6690140845070456 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.8802816901408494 40
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #3
root->2->7->8
Best Reward: 0.07042253521126796
coverage_call_count 100
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650278> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.3521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.38732394366197376 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.7042253521126796 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.9154929577464834 41
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650d30> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.38732394366197376 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.42253521126760774 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.7394366197183135 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.9507042253521174 42
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #4
root->2->7->8->4
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7290b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.1760563380281699 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.42253521126760774 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.4577464788732417 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.7746478873239475 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.9859154929577514 43
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.1760563380281699 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.24647887323943785 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.4929577464788757 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.5281690140845097 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.8450704225352155 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.0563380281690193 44
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.21126760563380387 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.2816901408450718 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.5281690140845097 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.5633802816901436 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.8802816901408494 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.0915492957746533 45
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.24647887323943785 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.3169014084507058 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.5633802816901436 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.5985915492957776 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.9154929577464834 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.1267605633802873 46
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.2816901408450718 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.3521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.5985915492957776 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.6338028169014116 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.9507042253521174 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.1619718309859213 47
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6507f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.3169014084507058 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.38732394366197376 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.6338028169014116 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.6690140845070456 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.9859154929577514 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.1971830985915553 48
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #5
root->2->7->8->4->2
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119128> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.38732394366197376 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.4577464788732417 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.7042253521126796 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.7394366197183135 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 1.0563380281690193 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.2676056338028232 49
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #6
root->2->7->8->4->2->26
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128908> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.21126760563380387 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.4577464788732417 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.5281690140845097 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.7746478873239475 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.8098591549295815 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 1.1267605633802873 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.3380281690140912 50
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b4e0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.21126760563380387 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.2816901408450718 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.5281690140845097 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.5985915492957776 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.8450704225352155 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.8802816901408494 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 1.1971830985915553 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.4084507042253591 51
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bc50> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.2816901408450718 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.3521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.5985915492957776 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.6690140845070456 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.9154929577464834 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.9507042253521174 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 1.2676056338028232 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.478873239436627 52
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2898> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2668> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bc50> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.3169014084507058 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.38732394366197376 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.6338028169014116 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.7042253521126796 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 0.9507042253521174 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.9859154929577514 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 1.3028169014084572 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.514084507042261 53
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650518> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.38732394366197376 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.4577464788732417 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.7042253521126796 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.7746478873239475 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 1.0211267605633854 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 1.0563380281690193 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 1.3732394366197251 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.584507042253529 54
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650b70> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f90f0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119128> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.4577464788732417 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.5281690140845097 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.7746478873239475 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.8450704225352155 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 1.0915492957746533 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 1.1267605633802873 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 1.443661971830993 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.654929577464797 55
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #7
root->2->7->8->4->2->26->8
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
coverage_call_count 200
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1190b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2208> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119128> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.4929577464788757 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.5633802816901436 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.8098591549295815 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.8802816901408494 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 1.1267605633802873 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 1.1619718309859213 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 1.478873239436627 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.690140845070431 56
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bd30> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f90f0> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119128> 0.24647887323943785 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.5633802816901436 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.6338028169014116 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650048> 0.8802816901408494 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.9507042253521174 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d68> 1.1971830985915553 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 1.2323943661971892 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 1.549295774647895 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 1.760563380281699 57
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #8
root->2->7->8->4->2->26->8->8
Best Reward: 0.07042253521126796
iteration: 0
found coverage increase 0.07042253521126796
Current Total Coverage 11.795774647887324
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 12
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 13
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 14
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 15
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 16
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 17
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 18
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 19
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 20
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 21
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 22
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 23
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 24
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 25
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 26
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 27
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 28
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 29
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 30
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 31
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 32
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 33
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 34
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 35
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 36
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 37
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 38
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.03521126760563398 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.03521126760563398 39
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1015f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.07042253521126796 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.07042253521126796 40
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101cc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b8d0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.10563380281690193 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.10563380281690193 41
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09abe0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.1408450704225359 29
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.1408450704225359 42
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaac8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101cc0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b8d0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.1760563380281699 30
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.1760563380281699 43
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.1760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.1760563380281699 31
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.1760563380281699 44
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.1760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.1760563380281699 32
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.1760563380281699 45
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 33
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 46
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 34
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 47
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b8d0> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 35
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 48
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2860> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 36
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 49
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 37
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 50
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0435f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 38
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 51
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0520f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 39
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 52
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 40
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 53
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 41
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 54
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->0->17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.21126760563380387 42
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.21126760563380387 55
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.24647887323943785 43
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.24647887323943785 56
Completed Iteration #1
Best Reward: 0.03521126760563398
coverage_call_count 300
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa3c8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.2816901408450718 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.2816901408450718 44
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.2816901408450718 57
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.2816901408450718 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.2816901408450718 45
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.2816901408450718 58
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.2816901408450718 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.2816901408450718 46
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.2816901408450718 59
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.3169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.3169014084507058 47
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.3169014084507058 60
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043400> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.3169014084507058 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.3169014084507058 48
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.3169014084507058 61
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0522b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.3521126760563398 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.3521126760563398 49
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.3521126760563398 62
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.3521126760563398 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.3521126760563398 50
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.3521126760563398 63
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.24647887323943785 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.38732394366197376 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.38732394366197376 51
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.38732394366197376 64
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0522b0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.38732394366197376 29
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.38732394366197376 52
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.38732394366197376 65
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa3c8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.24647887323943785 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.38732394366197376 30
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.38732394366197376 53
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.38732394366197376 66
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.2816901408450718 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.42253521126760774 31
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.42253521126760774 54
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.42253521126760774 67
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d6a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.3169014084507058 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.4577464788732417 32
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.4577464788732417 55
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.4577464788732417 68
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.3169014084507058 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.4577464788732417 33
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.4577464788732417 56
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.4577464788732417 69
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.3169014084507058 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.4577464788732417 34
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.4577464788732417 57
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.4577464788732417 70
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.3521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.4929577464788757 35
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.4929577464788757 58
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.4929577464788757 71
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043ba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.38732394366197376 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5281690140845097 36
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5281690140845097 59
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5281690140845097 72
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09add8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.42253521126760774 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5633802816901436 37
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5633802816901436 60
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5633802816901436 73
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #3
root->0->17->6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.42253521126760774 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5633802816901436 38
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5633802816901436 61
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5633802816901436 74
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.42253521126760774 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5633802816901436 39
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5633802816901436 62
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5633802816901436 75
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.42253521126760774 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5633802816901436 40
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5633802816901436 63
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5633802816901436 76
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.42253521126760774 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5633802816901436 41
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5633802816901436 64
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5633802816901436 77
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.42253521126760774 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5633802816901436 42
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5633802816901436 65
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5633802816901436 78
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.42253521126760774 29
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5633802816901436 43
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5633802816901436 66
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5633802816901436 79
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043b70> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dd68> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4577464788732417 30
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5985915492957776 44
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5985915492957776 67
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5985915492957776 80
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4577464788732417 31
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5985915492957776 45
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5985915492957776 68
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5985915492957776 81
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4577464788732417 32
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5985915492957776 46
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5985915492957776 69
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5985915492957776 82
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4577464788732417 33
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5985915492957776 47
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5985915492957776 70
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5985915492957776 83
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4577464788732417 34
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5985915492957776 48
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5985915492957776 71
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5985915492957776 84
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.10563380281690193 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4577464788732417 35
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5985915492957776 49
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5985915492957776 72
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5985915492957776 85
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.10563380281690193 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4577464788732417 36
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5985915492957776 50
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5985915492957776 73
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5985915492957776 86
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #4
root->0->17->6->11
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.10563380281690193 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4577464788732417 37
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.5985915492957776 51
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.5985915492957776 74
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.5985915492957776 87
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003c18> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.1408450704225359 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4929577464788757 38
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.6338028169014116 52
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.6338028169014116 75
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.6338028169014116 88
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.1408450704225359 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.6338028169014116 53
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.6338028169014116 76
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.6338028169014116 89
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.1408450704225359 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4929577464788757 40
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.6338028169014116 54
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.6338028169014116 77
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.6338028169014116 90
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.1408450704225359 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4929577464788757 41
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.6338028169014116 55
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.6338028169014116 78
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.6338028169014116 91
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.1408450704225359 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4929577464788757 42
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.6338028169014116 56
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.6338028169014116 79
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.6338028169014116 92
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.07042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.1408450704225359 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.4929577464788757 43
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.6338028169014116 57
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.6338028169014116 80
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.6338028169014116 93
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023d68> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.1760563380281699 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.5281690140845097 44
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.6690140845070456 58
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.6690140845070456 81
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.6690140845070456 94
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #5
root->0->17->6->11->2
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.1760563380281699 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.5281690140845097 45
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.6690140845070456 59
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.6690140845070456 82
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.6690140845070456 95
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.1760563380281699 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.5281690140845097 46
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.6690140845070456 60
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.6690140845070456 83
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.6690140845070456 96
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023cf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023a90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.1408450704225359 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.21126760563380387 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.5633802816901436 47
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.7042253521126796 61
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.7042253521126796 84
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.7042253521126796 97
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.1408450704225359 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.21126760563380387 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.5633802816901436 48
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.7042253521126796 62
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.7042253521126796 85
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.7042253521126796 98
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fb00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.24647887323943785 29
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.5985915492957776 49
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.7394366197183135 63
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.7394366197183135 86
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.7394366197183135 99
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f2b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.2816901408450718 30
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.6338028169014116 50
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.7746478873239475 64
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.7746478873239475 87
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.7746478873239475 100
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fb00> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.2816901408450718 31
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.6338028169014116 51
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.7746478873239475 65
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.7746478873239475 88
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.7746478873239475 101
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023a90> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.21126760563380387 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.2816901408450718 32
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.6338028169014116 52
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.7746478873239475 66
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.7746478873239475 89
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.7746478873239475 102
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.21126760563380387 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.2816901408450718 33
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.6338028169014116 53
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.7746478873239475 67
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.7746478873239475 90
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.7746478873239475 103
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.21126760563380387 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.2816901408450718 34
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.6338028169014116 54
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.7746478873239475 68
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.7746478873239475 91
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.7746478873239475 104
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003f98> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06def0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.24647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.3169014084507058 35
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.6690140845070456 55
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.8098591549295815 69
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.8098591549295815 92
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.8098591549295815 105
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #6
root->0->17->6->11->2->0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.24647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.3169014084507058 36
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.6690140845070456 56
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.8098591549295815 70
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.8098591549295815 93
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.8098591549295815 106
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006a58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.2816901408450718 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.3521126760563398 37
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7042253521126796 57
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.8450704225352155 71
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.8450704225352155 94
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.8450704225352155 107
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.2816901408450718 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.3521126760563398 38
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7042253521126796 58
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.8450704225352155 72
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.8450704225352155 95
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.8450704225352155 108
Completed Iteration #7
Best Reward: 0.03521126760563398
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.21126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.2816901408450718 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.3521126760563398 39
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7042253521126796 59
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.8450704225352155 73
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.8450704225352155 96
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.8450704225352155 109
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.2816901408450718 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.3521126760563398 40
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7042253521126796 60
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.8450704225352155 74
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.8450704225352155 97
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.8450704225352155 110
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.2816901408450718 29
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.3521126760563398 41
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7042253521126796 61
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.8450704225352155 75
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.8450704225352155 98
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.8450704225352155 111
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b630> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.3169014084507058 30
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.38732394366197376 42
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7394366197183135 62
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.8802816901408494 76
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.8802816901408494 99
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.8802816901408494 112
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0069b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.24647887323943785 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.3169014084507058 31
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.38732394366197376 43
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7394366197183135 63
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.8802816901408494 77
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.8802816901408494 100
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.8802816901408494 113
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.2816901408450718 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.3521126760563398 32
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.42253521126760774 44
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7746478873239475 64
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9154929577464834 78
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9154929577464834 101
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9154929577464834 114
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06c52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f2b0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.2816901408450718 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.3521126760563398 33
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.42253521126760774 45
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7746478873239475 65
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9154929577464834 79
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9154929577464834 102
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9154929577464834 115
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #7
root->0->17->6->11->2->0->3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.2816901408450718 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.3521126760563398 34
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.42253521126760774 46
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7746478873239475 66
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9154929577464834 80
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9154929577464834 103
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9154929577464834 116
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1017f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.2816901408450718 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.3521126760563398 35
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.42253521126760774 47
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.7746478873239475 67
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9154929577464834 81
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9154929577464834 104
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9154929577464834 117
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.3169014084507058 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.38732394366197376 36
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.4577464788732417 48
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8098591549295815 68
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9507042253521174 82
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9507042253521174 105
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9507042253521174 118
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06d52eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.3169014084507058 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.38732394366197376 37
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.4577464788732417 49
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8098591549295815 69
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9507042253521174 83
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9507042253521174 106
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9507042253521174 119
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06dec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be128> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.1760563380281699 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.3169014084507058 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.38732394366197376 38
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.4577464788732417 50
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8098591549295815 70
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9507042253521174 84
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9507042253521174 107
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9507042253521174 120
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be128> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.1760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.3169014084507058 29
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.38732394366197376 39
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.4577464788732417 51
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8098591549295815 71
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9507042253521174 85
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9507042253521174 108
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9507042253521174 121
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be128> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.3521126760563398 30
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.42253521126760774 40
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.4929577464788757 52
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8450704225352155 72
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9859154929577514 86
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9859154929577514 109
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9859154929577514 122
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.21126760563380387 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.3521126760563398 31
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.42253521126760774 41
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.4929577464788757 53
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8450704225352155 73
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9859154929577514 87
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9859154929577514 110
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9859154929577514 123
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be128> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.21126760563380387 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.3521126760563398 32
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.42253521126760774 42
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.4929577464788757 54
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8450704225352155 74
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9859154929577514 88
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9859154929577514 111
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9859154929577514 124
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.21126760563380387 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.3521126760563398 33
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.42253521126760774 43
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.4929577464788757 55
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8450704225352155 75
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.9859154929577514 89
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.9859154929577514 112
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 0.9859154929577514 125
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86b38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006320> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.24647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.38732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.4577464788732417 44
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.5281690140845097 56
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8802816901408494 76
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 1.0211267605633854 90
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 1.0211267605633854 113
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 1.0211267605633854 126
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.24647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.38732394366197376 35
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.4577464788732417 45
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.5281690140845097 57
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.8802816901408494 77
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 1.0211267605633854 91
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 1.0211267605633854 114
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 1.0211267605633854 127
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735cf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1016a0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.2816901408450718 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.42253521126760774 36
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.4929577464788757 46
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.5633802816901436 58
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.9154929577464834 78
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 1.0563380281690193 92
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 1.0563380281690193 115
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 1.0563380281690193 128
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1016a0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d128> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.2816901408450718 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c20f0> 0.42253521126760774 37
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052048> 0.4929577464788757 47
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.5633802816901436 59
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.9154929577464834 79
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 1.0563380281690193 93
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 1.0563380281690193 116
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee7f0> 1.0563380281690193 129
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #8
root->0->17->6->11->2->0->3->0
Best Reward: 0.03521126760563398
iteration: 1
found coverage increase 0.03521126760563398
Current Total Coverage 11.830985915492958
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e840437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e840434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 11.830985915492958
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1190f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 11.830985915492958
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1194a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 11.830985915492958
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128ac8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043898> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.0352112676056322 3
Completed Iteration #1
Best Reward: 0.0352112676056322
Completed Iteration #2
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.0352112676056322 4
Completed Iteration #3
Best Reward: 0.0352112676056322
Completed Iteration #4
Best Reward: 0.0352112676056322
Completed Iteration #5
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.0352112676056322 5
Completed Iteration #6
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.0352112676056322 6
Completed Iteration #7
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be2b0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.0704225352112644 7
Completed Iteration #8
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.0704225352112644 8
Completed Iteration #9
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.0704225352112644 9
Completed Iteration #10
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6688d0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.1056338028168966 10
Completed Iteration #11
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.1056338028168966 11
Completed Iteration #12
Best Reward: 0.0352112676056322
Completed Iteration #13
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.1056338028168966 12
Completed Iteration #14
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aab38> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2240> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be2b0> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.1056338028168966 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.1408450704225288 13
Completed Iteration #15
Best Reward: 0.0352112676056322
Completed Iteration #16
Best Reward: 0.0352112676056322
Completed Iteration #17
Best Reward: 0.0352112676056322
Completed Iteration #18
Best Reward: 0.0352112676056322
Completed Iteration #19
Best Reward: 0.0352112676056322
Completed Iteration #20
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86b00> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c27b8> 0.0352112676056322 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.176056338028161 14
Completed Iteration #21
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6682b0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.1408450704225288 5
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.2112676056337932 15
Completed Iteration #22
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c27b8> 0.0352112676056322 5
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.2112676056337932 16
Completed Iteration #23
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.2112676056337932 17
Completed Iteration #24
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.2112676056337932 18
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #0
root
Best Reward: 0.0352112676056322
Completed Iteration #0
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6782b0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.176056338028161 6
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.2464788732394254 19
Completed Iteration #1
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.176056338028161 7
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.2464788732394254 20
Completed Iteration #2
Best Reward: 0.0352112676056322
Completed Iteration #3
Best Reward: 0.0352112676056322
Completed Iteration #4
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.176056338028161 8
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.2464788732394254 21
Completed Iteration #5
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.176056338028161 9
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.2464788732394254 22
Completed Iteration #6
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.176056338028161 10
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.2464788732394254 23
Completed Iteration #7
Best Reward: 0.0352112676056322
Completed Iteration #8
Best Reward: 0.0352112676056322
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650630> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.2464788732394272 11
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.3169014084506916 24
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678630> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.2816901408450594 12
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.3521126760563238 25
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.2816901408450594 13
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.3521126760563238 26
Completed Iteration #13
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a358> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.3169014084506916 14
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.387323943661956 27
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6868d0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a898> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6682b0> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.3521126760563238 15
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.4225352112675882 28
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650630> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.3521126760563238 16
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.4225352112675882 29
Completed Iteration #18
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.42253521126758997 17
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.4929577464788544 30
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6864e0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686ac8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6782b0> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.49295774647885615 18
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.5633802816901206 31
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.49295774647885615 19
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.5633802816901206 32
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.49295774647885615 20
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.5633802816901206 33
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.07042253521126618
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.49295774647885615 21
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.5633802816901206 34
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be160> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.14084507042253236 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.5633802816901223 22
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.6338028169013867 35
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.14084507042253236 5
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.5633802816901223 23
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.6338028169013867 36
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.14084507042253236 6
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.5633802816901223 24
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.6338028169013867 37
Completed Iteration #5
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650208> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.21126760563379854 7
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6338028169013885 25
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7042253521126529 38
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.21126760563379854 8
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6338028169013885 26
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7042253521126529 39
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.21126760563379854 9
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6338028169013885 27
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7042253521126529 40
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686be0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.24647887323943074 10
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6690140845070207 28
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7394366197182851 41
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.24647887323943074 11
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6690140845070207 29
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7394366197182851 42
Completed Iteration #15
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.24647887323943074 12
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6690140845070207 30
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7394366197182851 43
Completed Iteration #16
Best Reward: 0.07042253521126618
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.07042253521126618 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.24647887323943074 13
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6690140845070207 31
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7394366197182851 44
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.24647887323943074 14
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6690140845070207 32
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7394366197182851 45
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.24647887323943074 15
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6690140845070207 33
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7394366197182851 46
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #2
root->5->11
Best Reward: 0.07042253521126618
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.10563380281689838 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.24647887323943074 16
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.6690140845070207 34
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7394366197182851 47
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9e80> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.14084507042253058 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.28169014084506294 17
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.7042253521126529 35
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7746478873239173 48
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.14084507042253058 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.28169014084506294 18
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.7042253521126529 36
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.7746478873239173 49
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e13c8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.17605633802816278 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.31690140845069514 19
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.7394366197182851 37
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.8098591549295495 50
Completed Iteration #5
Best Reward: 0.07042253521126618
coverage_call_count 600
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b7b8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101898> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e13c8> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.21126760563379499 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.35211267605632735 20
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.7746478873239173 38
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.8450704225351817 51
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.28169014084506117 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.4225352112675935 21
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.8450704225351835 39
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.9154929577464479 52
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.28169014084506117 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.4225352112675935 22
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.8450704225351835 40
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.9154929577464479 53
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119160> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.31690140845069337 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.4577464788732257 23
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.8802816901408157 41
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.9507042253520801 54
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650208> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.31690140845069337 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.4577464788732257 24
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.8802816901408157 42
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.9507042253520801 55
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686e80> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6861d0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119160> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.38732394366195955 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.5281690140844919 25
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.9507042253520819 43
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.0211267605633463 56
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9438> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9f28> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650208> 0.14084507042253236 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.4577464788732257 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.5985915492957581 26
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.021126760563348 44
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.0915492957746125 57
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e18d0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.14084507042253236 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.5281690140844919 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.6690140845070243 27
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.0915492957746142 45
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.1619718309858786 58
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9780> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1780> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9198> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.5633802816901241 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.7042253521126565 28
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.1267605633802464 46
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.1971830985915108 59
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #3
root->5->11->2
Best Reward: 0.07042253521126618
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.14084507042253236 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.5633802816901241 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.7042253521126565 29
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.1267605633802464 47
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.1971830985915108 60
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf6a0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1e80> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.17605633802816456 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.5985915492957563 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.7394366197182887 30
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.1619718309858786 48
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.232394366197143 61
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfd30> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.24647887323943074 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.6690140845070225 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.8098591549295548 31
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.2323943661971448 49
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.3028169014084092 62
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.24647887323943074 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.6690140845070225 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.8098591549295548 32
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.2323943661971448 50
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.3028169014084092 63
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695ba8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a5f8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.28169014084506294 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.7042253521126547 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.845070422535187 33
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.267605633802777 51
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.3380281690140414 64
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9208> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.21126760563379854 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.3521126760563291 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.7746478873239209 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.9154929577464532 34
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.3380281690140432 52
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.4084507042253076 65
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1da0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e17f0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e18d0> 0.10563380281689838 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.24647887323943074 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.3873239436619613 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.8098591549295531 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 0.9507042253520854 35
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.3732394366196754 53
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.4436619718309398 66
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65aba8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.3169014084506969 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.4577464788732275 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.8802816901408193 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0211267605633516 36
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.4436619718309416 54
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.514084507042206 67
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.4577464788732275 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.8802816901408193 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0211267605633516 37
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.4436619718309416 55
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.514084507042206 68
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfd30> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.3169014084506969 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.4577464788732275 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.8802816901408193 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0211267605633516 38
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.4436619718309416 56
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.514084507042206 69
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.3169014084506969 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.4577464788732275 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.8802816901408193 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0211267605633516 39
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.4436619718309416 57
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.514084507042206 70
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #4
root->5->11->2->10
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.3169014084506969 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.4577464788732275 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.8802816901408193 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0211267605633516 40
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.4436619718309416 58
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.514084507042206 71
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.3169014084506969 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.4577464788732275 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.8802816901408193 29
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0211267605633516 41
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.4436619718309416 59
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.514084507042206 72
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.3169014084506969 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.4577464788732275 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.8802816901408193 30
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0211267605633516 42
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.4436619718309416 60
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.514084507042206 73
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.3169014084506969 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.4577464788732275 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.8802816901408193 31
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0211267605633516 43
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.4436619718309416 61
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.514084507042206 74
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.3873239436619631 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.5281690140844937 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.9507042253520854 32
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0915492957746178 44
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.5140845070422078 62
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.5845070422534722 75
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.3873239436619631 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.5281690140844937 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.9507042253520854 33
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.0915492957746178 45
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.5140845070422078 63
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.5845070422534722 76
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2400> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.4225352112675953 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.5633802816901259 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.9859154929577176 34
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.12676056338025 46
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.54929577464784 64
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.6197183098591044 77
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.4929577464788615 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.6338028169013921 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.0563380281689838 35
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.1971830985915162 47
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.6197183098591061 65
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.6901408450703705 78
Completed Iteration #11
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.4929577464788615 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.6338028169013921 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.0563380281689838 36
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.1971830985915162 48
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.6197183098591061 66
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.6901408450703705 79
Completed Iteration #12
Best Reward: 0.07042253521126618
Completed Iteration #13
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695668> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.5633802816901277 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.7042253521126582 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.12676056338025 37
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.2676056338027824 49
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.6901408450703723 67
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.7605633802816367 80
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2400> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.5633802816901277 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.7042253521126582 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.12676056338025 38
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.2676056338027824 50
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.6901408450703723 68
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.7605633802816367 81
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.5633802816901277 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.7042253521126582 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.12676056338025 39
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.2676056338027824 51
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.6901408450703723 69
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.7605633802816367 82
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.6338028169013938 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.7746478873239244 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.1971830985915162 40
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.3380281690140485 52
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.7605633802816385 70
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.830985915492903 83
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.6338028169013938 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.7746478873239244 29
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.1971830985915162 41
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.3380281690140485 53
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.7605633802816385 71
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.830985915492903 84
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #5
root->5->11->2->10->0
Best Reward: 0.07042253521126618
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.14084507042253236 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.6338028169013938 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.7746478873239244 30
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.1971830985915162 42
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.3380281690140485 54
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.7605633802816385 72
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.830985915492903 85
Completed Iteration #1
Best Reward: 0.07042253521126618
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.14084507042253236 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.6338028169013938 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.7746478873239244 31
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.1971830985915162 43
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.3380281690140485 55
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.7605633802816385 73
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.830985915492903 86
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9860> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023320> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.17605633802816456 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.669014084507026 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.8098591549295566 32
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.2323943661971484 44
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.3732394366196807 56
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.7957746478872707 74
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.866197183098535 87
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae7f0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.24647887323943074 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.7394366197182922 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.8802816901408228 33
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.3028169014084146 45
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.443661971830947 57
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.8661971830985369 75
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.9366197183098013 88
Completed Iteration #15
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae7f0> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.14084507042253236 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.24647887323943074 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.7394366197182922 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.8802816901408228 34
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.3028169014084146 46
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.443661971830947 58
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.8661971830985369 76
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.9366197183098013 89
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.24647887323943074 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.7394366197182922 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.8802816901408228 35
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.3028169014084146 47
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.443661971830947 59
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.8661971830985369 77
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 1.9366197183098013 90
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dc18> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d978> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.21126760563379854 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.3169014084506969 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.8098591549295584 29
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.950704225352089 36
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.3732394366196807 48
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.514084507042213 60
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.936619718309803 78
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.0070422535210675 91
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.3169014084506969 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.8098591549295584 30
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.950704225352089 37
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.3732394366196807 49
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.514084507042213 61
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.936619718309803 79
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.0070422535210675 92
Completed Iteration #21
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.3169014084506969 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.8098591549295584 31
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.950704225352089 38
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.3732394366196807 50
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.514084507042213 62
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.936619718309803 80
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.0070422535210675 93
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023320> 0.0352112676056322 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.3169014084506969 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.8098591549295584 32
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 0.950704225352089 39
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.3732394366196807 51
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.514084507042213 63
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 1.936619718309803 81
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.0070422535210675 94
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #6
root->5->11->2->10->0->6
Best Reward: 0.07042253521126618
Completed Iteration #0
Best Reward: 0.07042253521126618
Completed Iteration #1
Best Reward: 0.07042253521126618
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
coverage_call_count 700
Completed Iteration #12
Best Reward: 0.07042253521126618
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003f60> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.2816901408450647 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.3873239436619631 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.8802816901408246 33
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.0211267605633552 40
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.443661971830947 52
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.5845070422534793 64
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.0070422535210692 82
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.0774647887323336 95
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #7
root->5->11->2->10->0->6->0
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6f06caea58> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06caec50> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.17605633802816456 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.3169014084506969 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.4225352112675953 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.9154929577464568 34
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.0563380281689874 41
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.4788732394365791 53
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.6197183098591115 65
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.0422535211267014 83
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.112676056337966 96
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dc18> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d978> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.17605633802816456 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.3169014084506969 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.4225352112675953 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.9154929577464568 35
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.0563380281689874 42
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.4788732394365791 54
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.6197183098591115 66
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.0422535211267014 84
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.112676056337966 97
Completed Iteration #1
Best Reward: 0.07042253521126618
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6f06caecc0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6950b8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.24647887323943074 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.3873239436619631 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.4929577464788615 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 0.985915492957723 36
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.1267605633802535 43
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.5492957746478453 55
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.6901408450703777 67
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.1126760563379676 85
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.183098591549232 98
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3cf8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3d68> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.3169014084506969 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.4577464788732293 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.5633802816901277 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.0563380281689891 37
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.1971830985915197 44
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.6197183098591115 56
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.7605633802816438 68
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.183098591549234 86
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.253521126760498 99
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06caec50> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.3169014084506969 8
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.4577464788732293 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.5633802816901277 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.0563380281689891 38
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.1971830985915197 45
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.6197183098591115 57
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.7605633802816438 69
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.183098591549234 87
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.253521126760498 100
Completed Iteration #11
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.3169014084506969 9
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.4577464788732293 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.5633802816901277 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.0563380281689891 39
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.1971830985915197 46
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.6197183098591115 58
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.7605633802816438 70
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.183098591549234 88
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.253521126760498 101
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3940> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729668> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.3873239436619631 10
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.5281690140844955 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.6338028169013938 21
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.1267605633802553 40
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.267605633802786 47
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.6901408450703777 59
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.83098591549291 71
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.2535211267605 89
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.3239436619717644 102
Completed Iteration #13
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3cf8> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3d68> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.3873239436619631 11
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.5281690140844955 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.6338028169013938 22
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.1267605633802553 41
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.267605633802786 48
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.6901408450703777 60
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.83098591549291 72
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.2535211267605 90
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.3239436619717644 103
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6950b8> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.3873239436619631 12
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.5281690140844955 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.6338028169013938 23
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.1267605633802553 42
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.267605633802786 49
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.6901408450703777 61
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.83098591549291 73
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.2535211267605 91
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.3239436619717644 104
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d978> 0.07042253521126618 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.3873239436619631 13
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.5281690140844955 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.6338028169013938 24
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.1267605633802553 43
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.267605633802786 50
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.6901408450703777 62
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.83098591549291 74
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.2535211267605 92
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.3239436619717644 105
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.3873239436619631 14
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.5281690140844955 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.6338028169013938 25
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.1267605633802553 44
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.267605633802786 51
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.6901408450703777 63
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.83098591549291 75
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.2535211267605 93
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.3239436619717644 106
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.3873239436619631 15
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.5281690140844955 18
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.6338028169013938 26
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.1267605633802553 45
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.267605633802786 52
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.6901408450703777 64
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.83098591549291 76
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.2535211267605 94
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.3239436619717644 107
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9438> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc50> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.4577464788732293 16
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.5985915492957616 19
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.70422535211266 27
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.1971830985915215 46
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.338028169014052 53
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.7605633802816438 65
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.9014084507041762 77
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.323943661971766 95
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.3943661971830306 108
Completed Iteration #24
Best Reward: 0.07042253521126618
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7f6e387e93c8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d978> 0.10563380281689838 5
backprop <src.mcts.MCTS_Node object at 0x7f6ed0758ef0> 0.4929577464788615 17
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695550> 0.6338028169013938 20
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7298d0> 0.7394366197182922 28
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1400> 1.2323943661971537 47
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b00> 1.3732394366196843 54
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 1.795774647887276 66
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a588> 1.9366197183098084 78
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 2.3591549295773984 96
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 2.4295774647886628 109
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #8
root->5->11->2->10->0->6->0->22
Best Reward: 0.07042253521126618
iteration: 5
found coverage increase 0.07042253521126618
Current Total Coverage 11.901408450704224
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9b38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 16
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 17
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 18
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 19
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 20
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 21
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 22
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 23
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 24
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 25
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 26
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 27
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 28
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 29
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.03521126760563398 30
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.07042253521126796 13
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.07042253521126796 31
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.07042253521126796 14
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.07042253521126796 32
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.07042253521126796 15
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.07042253521126796 33
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.07042253521126796 16
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.07042253521126796 34
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.07042253521126796 17
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.07042253521126796 35
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f4e0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.10563380281690193 18
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.10563380281690193 36
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.10563380281690193 19
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.10563380281690193 37
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.1408450704225359 20
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.1408450704225359 38
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
coverage_call_count 800
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->6->6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ffd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.1760563380281699 21
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.1760563380281699 39
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c6d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.21126760563380387 22
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.21126760563380387 40
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387662b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.24647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.24647887323943785 41
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cda0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.21126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.24647887323943785 9
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.2816901408450718 24
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.2816901408450718 42
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.24647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.3169014084507058 25
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.3169014084507058 43
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.3169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.3521126760563398 26
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.3521126760563398 44
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387760f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.3169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.3521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.38732394366197376 27
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.38732394366197376 45
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.3521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.38732394366197376 13
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.42253521126760774 28
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.42253521126760774 46
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #3
root->6->6->0
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ccc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.38732394366197376 12
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.42253521126760774 14
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.4577464788732417 29
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.4577464788732417 47
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.38732394366197376 13
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.42253521126760774 15
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.4577464788732417 30
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.4577464788732417 48
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387765c0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.42253521126760774 14
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.4577464788732417 16
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.4929577464788757 31
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.4929577464788757 49
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38776cf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.4577464788732417 15
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.4929577464788757 17
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.5281690140845097 32
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.5281690140845097 50
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #4
root->6->6->0->2
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387664e0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.4929577464788757 16
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.5281690140845097 18
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.5633802816901436 33
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.5633802816901436 51
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e470> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.21126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.24647887323943785 9
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.5281690140845097 17
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.5633802816901436 19
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.5985915492957776 34
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.5985915492957776 52
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.24647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.5633802816901436 18
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.5985915492957776 20
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.6338028169014116 35
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.6338028169014116 53
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.3169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.5985915492957776 19
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.6338028169014116 21
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.6690140845070456 36
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.6690140845070456 54
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38726780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.3169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.3521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.6338028169014116 20
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.6690140845070456 22
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.7042253521126796 37
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.7042253521126796 55
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.3521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.38732394366197376 13
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.6690140845070456 21
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.7042253521126796 23
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.7394366197183135 38
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.7394366197183135 56
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387665f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.38732394366197376 12
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.42253521126760774 14
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.7042253521126796 22
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.7394366197183135 24
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.7746478873239475 39
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.7746478873239475 57
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e160> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.42253521126760774 13
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.4577464788732417 15
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.7394366197183135 23
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.7746478873239475 25
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.8098591549295815 40
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.8098591549295815 58
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387767f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.4577464788732417 14
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.4929577464788757 16
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.7746478873239475 24
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.8098591549295815 26
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.8450704225352155 41
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.8450704225352155 59
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #5
root->6->6->0->2->0
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e550> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.4929577464788757 15
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.5281690140845097 17
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.8098591549295815 25
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.8450704225352155 27
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.8802816901408494 42
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.8802816901408494 60
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.4929577464788757 16
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.5281690140845097 18
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.8098591549295815 26
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.8450704225352155 28
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.8802816901408494 43
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.8802816901408494 61
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
coverage_call_count 900
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #6
root->6->6->0->2->0->0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386da780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dacc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e550> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.5281690140845097 17
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.5633802816901436 19
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.8450704225352155 27
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.8802816901408494 29
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.9154929577464834 44
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.9154929577464834 62
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386daeb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.5633802816901436 18
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.5985915492957776 20
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.8802816901408494 28
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.9154929577464834 30
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.9507042253521174 45
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.9507042253521174 63
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1208> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.5985915492957776 19
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.6338028169014116 21
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.9154929577464834 29
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.9507042253521174 31
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.9859154929577514 46
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 0.9859154929577514 64
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38776080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.6338028169014116 20
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.6690140845070456 22
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.9507042253521174 30
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 0.9859154929577514 32
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.0211267605633854 47
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.0211267605633854 65
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e6d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.21126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.24647887323943785 9
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.6690140845070456 21
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.7042253521126796 23
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 0.9859154929577514 31
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.0211267605633854 33
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.0563380281690193 48
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.0563380281690193 66
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387660b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.24647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.7042253521126796 22
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.7394366197183135 24
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.0211267605633854 32
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.0563380281690193 34
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.0915492957746533 49
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.0915492957746533 67
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38726a20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.3169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.7394366197183135 23
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.7746478873239475 25
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.0563380281690193 33
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.0915492957746533 35
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.1267605633802873 50
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.1267605633802873 68
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8a90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.3169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.3521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.7746478873239475 24
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.8098591549295815 26
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.0915492957746533 34
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.1267605633802873 36
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.1619718309859213 51
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.1619718309859213 69
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386dab70> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.3521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.38732394366197376 13
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.8098591549295815 25
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.8450704225352155 27
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.1267605633802873 35
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.1619718309859213 37
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.1971830985915553 52
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.1971830985915553 70
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386da6d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.38732394366197376 12
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.42253521126760774 14
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.8450704225352155 26
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.8802816901408494 28
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.1619718309859213 36
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.1971830985915553 38
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.2323943661971892 53
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.2323943661971892 71
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daeb8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.42253521126760774 13
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.4577464788732417 15
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.8802816901408494 27
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.9154929577464834 29
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.1971830985915553 37
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.2323943661971892 39
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.2676056338028232 54
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.2676056338028232 72
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0c18> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.4577464788732417 14
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.4929577464788757 16
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.9154929577464834 28
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.9507042253521174 30
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.2323943661971892 38
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.2676056338028232 40
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.3028169014084572 55
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.3028169014084572 73
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eb00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.4929577464788757 15
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.5281690140845097 17
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.9507042253521174 29
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.9859154929577514 31
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.2676056338028232 39
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.3028169014084572 41
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.3380281690140912 56
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.3380281690140912 74
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #7
root->6->6->0->2->0->0->0
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e550> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.4929577464788757 16
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.5281690140845097 18
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.9507042253521174 30
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.9859154929577514 32
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.2676056338028232 40
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.3028169014084572 42
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.3380281690140912 57
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.3380281690140912 75
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e550> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.4929577464788757 17
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.5281690140845097 19
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.9507042253521174 31
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.9859154929577514 33
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.2676056338028232 41
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.3028169014084572 43
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.3380281690140912 58
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.3380281690140912 76
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386864e0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dacc0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e550> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.5281690140845097 18
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.5633802816901436 20
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.9859154929577514 32
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 1.0211267605633854 34
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.3028169014084572 42
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.3380281690140912 44
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.3732394366197251 59
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.3732394366197251 77
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dacc0> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e550> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.5633802816901436 19
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.5985915492957776 21
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 1.0211267605633854 33
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 1.0563380281690193 35
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.3380281690140912 43
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.3732394366197251 45
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.4084507042253591 60
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.4084507042253591 78
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38694ba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dacc0> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e550> 0.1760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7f6e387766d8> 0.5985915492957776 20
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.6338028169014116 22
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 1.0563380281690193 34
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 1.0915492957746533 36
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f2b0> 1.3732394366197251 44
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19b0> 1.4084507042253591 46
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 1.443661971830993 61
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b080> 1.443661971830993 79
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #8
root->6->6->0->2->0->0->0->4
Best Reward: 0.03521126760563398
iteration: 6
found coverage increase 0.03521126760563398
Current Total Coverage 11.936619718309858
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f710> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f6d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.03521126760563398 2
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f6d8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.03521126760563398 3
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.03521126760563398 4
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ca20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.07042253521126796 5
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f6d8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.07042253521126796 6
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.07042253521126796 7
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0588> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.10563380281690193 8
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f2b0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.1408450704225359 9
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.1408450704225359 10
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.1408450704225359 11
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.1408450704225359 12
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.1408450704225359 13
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38694710> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.1760563380281699 14
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38694f28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694e10> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.21126760563380387 15
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.21126760563380387 16
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.21126760563380387 17
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.21126760563380387 18
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fc50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.24647887323943785 19
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.24647887323943785 20
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.24647887323943785 21
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.24647887323943785 22
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38694a58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.2816901408450718 23
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.2816901408450718 24
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38645898> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.3169014084507058 25
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.3169014084507058 26
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38645cc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.3521126760563398 27
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694710> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.3521126760563398 28
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.21126760563380387 14
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.3521126760563398 29
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.3521126760563398 30
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38655320> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.24647887323943785 16
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.38732394366197376 31
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387266d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.2816901408450718 17
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.42253521126760774 32
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387266d8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.2816901408450718 18
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.42253521126760774 33
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386daac8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.3169014084507058 19
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.4577464788732417 34
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fc50> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.3169014084507058 20
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.4577464788732417 35
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.38732394366197553 21
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.5281690140845114 36
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
coverage_call_count 1000
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386455f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645588> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.4225352112676095 22
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.5633802816901454 37
Completed Iteration #22
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38645ac8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.4577464788732435 23
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.5985915492957794 38
Completed Iteration #23
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.4577464788732435 24
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.5985915492957794 39
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.07042253521126973
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.10563380281690371 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.4577464788732435 25
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.5985915492957794 40
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Completed Iteration #3
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38655f98> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655cc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.1408450704225377 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.49295774647887747 26
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.6338028169014134 41
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38665400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.17605633802817167 6
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.5281690140845114 27
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.6690140845070474 42
Completed Iteration #5
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e38665748> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655cc0> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.2464788732394414 7
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.5985915492957812 28
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.7394366197183171 43
Completed Iteration #6
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.2464788732394414 8
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.5985915492957812 29
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.7394366197183171 44
Completed Iteration #7
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e38665b00> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.31690140845071113 9
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.6690140845070509 30
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.8098591549295868 45
Completed Iteration #8
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.14084507042253946 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.38732394366198086 10
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.7394366197183206 31
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.8802816901408566 46
Completed Iteration #9
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e386700b8> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cf8> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.4577464788732506 11
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.8098591549295904 32
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.9507042253521263 47
Completed Iteration #10
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38670470> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386700f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.4929577464788846 12
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.8450704225352244 33
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 0.9859154929577603 48
Completed Iteration #11
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e386707b8> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655cc0> 0.17605633802817344 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.5633802816901543 13
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.9154929577464941 34
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.05633802816903 49
Completed Iteration #12
Best Reward: 0.07042253521126973
Completed Iteration #13
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e387768d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645588> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.5985915492957883 14
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.9507042253521281 35
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.091549295774664 50
Completed Iteration #14
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386700f0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.5985915492957883 15
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.9507042253521281 36
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.091549295774664 51
Completed Iteration #15
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645588> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.5985915492957883 16
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.9507042253521281 37
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.091549295774664 52
Completed Iteration #16
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655cc0> 0.17605633802817344 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.5985915492957883 17
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.9507042253521281 38
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.091549295774664 53
Completed Iteration #17
Best Reward: 0.07042253521126973
Completed Iteration #18
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e386555f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386700f0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.6338028169014223 18
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.985915492957762 39
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.126760563380298 54
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38655f60> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645588> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.6690140845070562 19
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.021126760563396 40
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.161971830985932 55
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #2
root->0->11
Best Reward: 0.07042253521126973
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e38670080> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.2112676056338092 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.739436619718326 20
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.0915492957746658 41
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.2323943661972017 56
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e38670978> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.28169014084507893 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.8098591549295957 21
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.1619718309859355 42
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.3028169014084714 57
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e38670f60> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.35211267605634866 6
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.8802816901408654 22
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.2323943661972052 43
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.3732394366197411 58
Completed Iteration #5
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665b00> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.35211267605634866 7
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.8802816901408654 23
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.2323943661972052 44
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.3732394366197411 59
Completed Iteration #6
Best Reward: 0.07042253521126973
Completed Iteration #7
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.35211267605634866 8
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.8802816901408654 24
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.2323943661972052 45
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.3732394366197411 60
Completed Iteration #8
Best Reward: 0.07042253521126973
Completed Iteration #9
Best Reward: 0.07042253521126973
Completed Iteration #10
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2908> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.38732394366198264 9
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.9154929577464994 25
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.2676056338028392 46
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.408450704225375 61
Completed Iteration #11
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.38732394366198264 10
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.9154929577464994 26
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.2676056338028392 47
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.408450704225375 62
Completed Iteration #12
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e383de208> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de048> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.14084507042253946 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.45774647887325237 11
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 0.9859154929577691 27
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.338028169014109 48
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.4788732394366448 63
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Completed Iteration #15
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e383d27b8> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.5281690140845221 12
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.0563380281690389 28
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.4084507042253787 49
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.5492957746479146 64
Completed Iteration #16
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383de7b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de6a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670f60> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.5633802816901561 13
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.0915492957746729 29
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.4436619718310126 50
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.5845070422535485 65
Completed Iteration #17
Best Reward: 0.07042253521126973
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Completed Iteration #22
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38655a20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.5985915492957901 14
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.1267605633803068 30
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.4788732394366466 51
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.6197183098591825 66
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #3
root->0->11->6
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38694c88> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de048> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.17605633802817344 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.633802816901424 15
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.1619718309859408 31
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.5140845070422806 52
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.6549295774648165 67
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e383d26a0> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2198> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.24647887323944317 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.7042253521126938 16
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.2323943661972105 32
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.5845070422535503 53
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.7253521126760862 68
Completed Iteration #1
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2198> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.24647887323944317 6
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.7042253521126938 17
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.2323943661972105 33
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.5845070422535503 54
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.7253521126760862 69
Completed Iteration #2
Best Reward: 0.07042253521126973
Completed Iteration #3
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de048> 0.10563380281690371 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.24647887323944317 7
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.7042253521126938 18
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.2323943661972105 34
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.5845070422535503 55
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.7253521126760862 70
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383de518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de390> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.28169014084507715 8
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.7394366197183277 19
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.2676056338028445 35
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.6197183098591843 56
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.7605633802817202 71
Completed Iteration #5
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.3521126760563469 9
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.8098591549295975 20
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.3380281690141143 36
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.690140845070454 57
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.83098591549299 72
Completed Iteration #6
Best Reward: 0.07042253521126973
Completed Iteration #7
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.3521126760563469 10
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.8098591549295975 21
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.3380281690141143 37
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.690140845070454 58
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.83098591549299 73
Completed Iteration #8
Best Reward: 0.07042253521126973
Completed Iteration #9
Best Reward: 0.07042253521126973
Completed Iteration #10
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383dee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.3521126760563469 11
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.8098591549295975 22
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.3380281690141143 38
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.690140845070454 59
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.83098591549299 74
Completed Iteration #11
Best Reward: 0.07042253521126973
Completed Iteration #12
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd898> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.14084507042253946 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.4225352112676166 12
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.8802816901408672 23
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.408450704225384 39
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.7605633802817238 60
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.9014084507042597 75
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.14084507042253946 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.4225352112676166 13
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.8802816901408672 24
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.408450704225384 40
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.7605633802817238 61
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.9014084507042597 76
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a0f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.4577464788732506 14
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.9154929577465012 25
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.443661971831018 41
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.7957746478873577 62
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.9366197183098937 77
Completed Iteration #17
Best Reward: 0.07042253521126973
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.4929577464788846 15
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.9507042253521352 26
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.478873239436652 42
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.8309859154929917 63
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.9718309859155276 78
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Completed Iteration #22
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cf8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.4929577464788846 16
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.9507042253521352 27
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.478873239436652 43
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.8309859154929917 64
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 1.9718309859155276 79
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #4
root->0->11->6->0
Best Reward: 0.07042253521126973
Completed Iteration #0
Best Reward: 0.07042253521126973
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Completed Iteration #3
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd630> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.17605633802817344 6
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.5281690140845186 17
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.9859154929577691 28
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.514084507042286 44
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.8661971830986257 65
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.0070422535211616 80
Completed Iteration #4
Best Reward: 0.07042253521126973
Completed Iteration #5
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd630> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.17605633802817344 7
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.5281690140845186 18
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 0.9859154929577691 29
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.514084507042286 45
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.8661971830986257 66
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.0070422535211616 81
Completed Iteration #6
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd8d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.21126760563380742 8
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.5633802816901525 19
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.0211267605634031 30
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.54929577464792 46
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.9014084507042597 67
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.0422535211267956 82
Completed Iteration #7
Best Reward: 0.07042253521126973
Completed Iteration #8
Best Reward: 0.07042253521126973
Completed Iteration #9
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.2464788732394414 9
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.5985915492957865 20
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.056338028169037 31
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.5845070422535539 47
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.9366197183098937 68
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.0774647887324296 83
Completed Iteration #10
Best Reward: 0.07042253521126973
Completed Iteration #11
Best Reward: 0.07042253521126973
Completed Iteration #12
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.2464788732394414 10
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.5985915492957865 21
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.056338028169037 32
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.5845070422535539 48
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.9366197183098937 69
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.0774647887324296 84
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Completed Iteration #15
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.2464788732394414 11
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.5985915492957865 22
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.056338028169037 33
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.5845070422535539 49
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.9366197183098937 70
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.0774647887324296 85
Completed Iteration #16
Best Reward: 0.07042253521126973
Completed Iteration #17
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.2464788732394414 12
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.5985915492957865 23
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.056338028169037 34
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.5845070422535539 50
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 1.9366197183098937 71
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.0774647887324296 86
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.31690140845071113 13
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.6690140845070562 24
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.1267605633803068 35
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.6549295774648236 51
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.0070422535211634 72
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.1478873239436993 87
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #5
root->0->11->6->0->3
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fe10> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839feb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.3521126760563451 14
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.7042253521126902 25
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.1619718309859408 36
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.6901408450704576 52
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.0422535211267974 73
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.1830985915493333 88
Completed Iteration #0
Best Reward: 0.07042253521126973
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839feb8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.10563380281690371 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.3521126760563451 15
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.7042253521126902 26
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.1619718309859408 37
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.6901408450704576 53
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.0422535211267974 74
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.1830985915493333 89
Completed Iteration #1
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.10563380281690371 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.3521126760563451 16
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.7042253521126902 27
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.1619718309859408 38
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.6901408450704576 54
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.0422535211267974 75
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.1830985915493333 90
Completed Iteration #2
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.10563380281690371 6
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.3521126760563451 17
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.7042253521126902 28
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.1619718309859408 39
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.6901408450704576 55
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.0422535211267974 76
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.1830985915493333 91
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Completed Iteration #5
Best Reward: 0.07042253521126973
Completed Iteration #6
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.10563380281690371 7
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.3521126760563451 18
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.7042253521126902 29
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.1619718309859408 40
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.6901408450704576 56
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.0422535211267974 77
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.1830985915493333 92
Completed Iteration #7
Best Reward: 0.07042253521126973
Completed Iteration #8
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f0f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.1408450704225377 8
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.3873239436619791 19
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.7394366197183242 30
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.1971830985915748 41
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.7253521126760916 57
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.0774647887324313 78
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.2183098591549673 93
Completed Iteration #9
Best Reward: 0.07042253521126973
Completed Iteration #10
Best Reward: 0.07042253521126973
Completed Iteration #11
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383ded68> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d28d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.17605633802817167 9
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.42253521126761306 20
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.7746478873239582 31
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.2323943661972088 42
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.7605633802817255 58
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.1126760563380653 79
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.2535211267606012 94
Completed Iteration #12
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.17605633802817167 10
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.42253521126761306 21
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.7746478873239582 32
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.2323943661972088 43
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.7605633802817255 59
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.1126760563380653 80
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.2535211267606012 95
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdcc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839feb8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.21126760563380564 11
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.45774647887324704 22
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.8098591549295922 33
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.2676056338028427 44
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.7957746478873595 60
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.1478873239436993 81
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.288732394366235 96
Completed Iteration #17
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.21126760563380564 12
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.45774647887324704 23
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.8098591549295922 34
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.2676056338028427 45
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.7957746478873595 61
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.1478873239436993 82
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.288732394366235 97
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e383be048> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.2816901408450754 13
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.5281690140845168 24
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.8802816901408619 35
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.3380281690141125 46
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.8661971830986293 62
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.218309859154969 83
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.359154929577505 98
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f0f0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f048> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.2816901408450754 14
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.5281690140845168 25
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.8802816901408619 36
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.3380281690141125 47
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.8661971830986293 63
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.218309859154969 84
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.359154929577505 99
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #6
root->0->11->6->0->3->1
Best Reward: 0.07042253521126973
Completed Iteration #0
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.2816901408450754 15
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.5281690140845168 26
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.8802816901408619 37
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.3380281690141125 48
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.8661971830986293 64
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.218309859154969 85
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.359154929577505 100
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.14084507042253946 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.3521126760563451 16
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.5985915492957865 27
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.9507042253521316 38
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.4084507042253822 49
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.936619718309899 65
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.2887323943662388 86
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.4295774647887747 101
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.14084507042253946 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.3521126760563451 17
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.5985915492957865 28
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.9507042253521316 39
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.4084507042253822 50
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.936619718309899 66
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.2887323943662388 87
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.4295774647887747 102
Completed Iteration #5
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be048> 0.07042253521126973 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.14084507042253946 6
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.3521126760563451 18
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.5985915492957865 29
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.9507042253521316 40
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.4084507042253822 51
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.936619718309899 67
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.2887323943662388 88
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.4295774647887747 103
Completed Iteration #6
Best Reward: 0.07042253521126973
Completed Iteration #7
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be630> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383def98> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.17605633802817344 7
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.3873239436619791 19
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.6338028169014205 30
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.9859154929577656 41
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.4436619718310162 52
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 1.971830985915533 68
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.3239436619718727 89
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.4647887323944087 104
Completed Iteration #8
Best Reward: 0.07042253521126973
Completed Iteration #9
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383beac8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b09b0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.21126760563380742 8
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.42253521126761306 20
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.6690140845070545 31
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.0211267605633996 42
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.4788732394366502 53
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.007042253521167 69
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.3591549295775067 90
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.5000000000000426 105
Completed Iteration #10
Best Reward: 0.07042253521126973
Completed Iteration #11
Best Reward: 0.07042253521126973
Completed Iteration #12
Best Reward: 0.07042253521126973
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.21126760563380742 9
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.42253521126761306 21
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.6690140845070545 32
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.0211267605633996 43
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.4788732394366502 54
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.007042253521167 70
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.3591549295775067 91
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.5000000000000426 106
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Completed Iteration #17
Best Reward: 0.07042253521126973
Completed Iteration #18
Best Reward: 0.07042253521126973
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.21126760563380742 10
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.42253521126761306 22
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.6690140845070545 33
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.0211267605633996 44
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.4788732394366502 55
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.007042253521167 71
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.3591549295775067 92
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.5000000000000426 107
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #7
root->0->11->6->0->3->1->3
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0cc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0c18> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.2464788732394414 11
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.45774647887324704 23
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.7042253521126884 34
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.0563380281690335 45
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.5140845070422841 56
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.042253521126801 72
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.3943661971831407 93
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.5352112676056766 108
Completed Iteration #0
Best Reward: 0.07042253521126973
Completed Iteration #1
Best Reward: 0.07042253521126973
Completed Iteration #2
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.10563380281690371 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.2464788732394414 12
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.45774647887324704 24
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.7042253521126884 35
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.0563380281690335 46
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.5140845070422841 57
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.042253521126801 73
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.3943661971831407 94
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.5352112676056766 109
Completed Iteration #3
Best Reward: 0.07042253521126973
Completed Iteration #4
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383bee10> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838afd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.1408450704225377 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.2816901408450754 13
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.492957746478881 25
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.7394366197183224 36
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.0915492957746675 47
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.5492957746479181 58
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.077464788732435 74
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.4295774647887747 95
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.5704225352113106 110
Completed Iteration #5
Best Reward: 0.07042253521126973
Completed Iteration #6
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.1408450704225377 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.2816901408450754 14
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.492957746478881 26
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.7394366197183224 37
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.0915492957746675 48
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.5492957746479181 59
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.077464788732435 75
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.4295774647887747 96
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.5704225352113106 111
Completed Iteration #7
Best Reward: 0.07042253521126973
Completed Iteration #8
Best Reward: 0.07042253521126973
Completed Iteration #9
Best Reward: 0.07042253521126973
Completed Iteration #10
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e38355dd8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838afd0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.17605633802817167 7
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.31690140845070935 15
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.528169014084515 27
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.7746478873239564 38
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.1267605633803015 49
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.584507042253552 60
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.112676056338069 76
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.4647887323944087 97
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.6056338028169446 112
Completed Iteration #11
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.17605633802817167 8
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.31690140845070935 16
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.528169014084515 28
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.7746478873239564 39
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.1267605633803015 50
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.584507042253552 61
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.112676056338069 77
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.4647887323944087 98
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.6056338028169446 113
Completed Iteration #12
Best Reward: 0.07042253521126973
Completed Iteration #13
Best Reward: 0.07042253521126973
Completed Iteration #14
Best Reward: 0.07042253521126973
Completed Iteration #15
Best Reward: 0.07042253521126973
Completed Iteration #16
Best Reward: 0.07042253521126973
Reward: 0.07042253521126973
backprop <src.mcts.MCTS_Node object at 0x7f6e38371fd0> 0.07042253521126973 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0c18> 0.10563380281690371 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.2464788732394414 9
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.3873239436619791 17
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.5985915492957847 29
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.8450704225352261 40
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.1971830985915712 51
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.6549295774648218 62
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.1830985915493386 78
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.5352112676056784 99
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.6760563380282143 114
Completed Iteration #17
Best Reward: 0.07042253521126973
Completed Iteration #18
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0c18> 0.10563380281690371 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.2464788732394414 10
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.3873239436619791 18
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.5985915492957847 30
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.8450704225352261 41
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.1971830985915712 52
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.6549295774648218 63
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.1830985915493386 79
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.5352112676056784 100
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.6760563380282143 115
Completed Iteration #19
Best Reward: 0.07042253521126973
Completed Iteration #20
Best Reward: 0.07042253521126973
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.2464788732394414 11
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.3873239436619791 19
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.5985915492957847 31
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.8450704225352261 42
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.1971830985915712 53
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.6549295774648218 64
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.1830985915493386 80
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.5352112676056784 101
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.6760563380282143 116
Completed Iteration #21
Best Reward: 0.07042253521126973
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7f6e383559b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0c18> 0.1408450704225377 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0e10> 0.2816901408450754 12
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.42253521126761306 20
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb38> 0.6338028169014187 32
backprop <src.mcts.MCTS_Node object at 0x7f6e383de978> 0.8802816901408601 43
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 1.2323943661972052 54
backprop <src.mcts.MCTS_Node object at 0x7f6e38655b70> 1.6901408450704558 65
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0240> 2.2183098591549726 81
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 2.5704225352113124 102
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f470> 2.7112676056338483 117
Completed Iteration #22
Best Reward: 0.07042253521126973
Completed Iteration #23
Best Reward: 0.07042253521126973
Completed Iteration #24
Best Reward: 0.07042253521126973
Completed Iteration #25
Best Reward: 0.07042253521126973
Completed MCTS Level/Depth: #8
root->0->11->6->0->3->1->3->1
Best Reward: 0.07042253521126973
iteration: 7
found coverage increase 0.07042253521126973
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383719b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383719b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383554a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383392e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383394a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383394e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383231d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383390f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383231d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38323240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383554a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383554a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383554a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a14e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aed30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382599e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38259dd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383391d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ef0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382215f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382216a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382216a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38236dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0f60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b05c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383dee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383def60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383def60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383def60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec88> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383deef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6d8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 1600
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386654e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386654e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386450f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38645dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386552e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386552e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386700f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386656d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382360f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38665f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386654a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386654a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386947b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38665400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0710> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38694dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386948d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387264e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386552e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387264e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e390> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387666a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 1900
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387b13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b13c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ff60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c87f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f0903a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06caed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a57b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06caea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06caea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387764a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3048> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 13
Completed Iteration #20
Best Reward: 0
coverage_call_count 2100
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0434a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ab38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06dc8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07350b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06d52eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07350b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07350b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0035c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0064e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387669b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0064e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 2200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387669b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0526d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0526d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0526d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0526d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0035c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06d52eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387669b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e840432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e840430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e840439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e840439b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e840430f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387666a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387669b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e840430f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387666a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387669b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0238d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 2300
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6507b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6507b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e84043f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06dec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0231d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e840430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 7
Completed Iteration #11
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6682e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06dec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e840432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6786d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e840432b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e840432b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e84043fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1287b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f97f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1287b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1287b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f97f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686f60> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0035f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0035f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7299b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0035f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1017b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6950b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1014e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6950b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 2600
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382475f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1014e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1014e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1014e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7297f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6509b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6509b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382470f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383391d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383397f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea46d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383397f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 2700
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38323da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383394e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0038d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383236a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383236a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07657b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07657b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dcf8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 2800
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07358d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07358d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07358d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06da90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f58b8c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bcc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f710> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38694518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed07659b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e97f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386653c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ec50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38655eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387269e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386da710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 15
Completed Iteration #24
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f9b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383396a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386655f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386655f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3838af28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06dc8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386452e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 15
Completed Iteration #22
Best Reward: 0
coverage_call_count 3100
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38665278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383ded68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383ded68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382219b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382475f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383de4e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383be668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 3200
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e840437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c29e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c29e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f0903a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7354e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101e80> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0067f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06dc8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387768d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e840432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0064e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0432e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0434a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0432e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1195f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386701d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7295f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386706d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1196d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e840432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6682b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e840437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e840437b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38766470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38766470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06dc8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06dc8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38355358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650278> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6956d8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae828> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc400> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316455c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316455c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdeb8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316453c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316453c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31645c18> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316456d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdb70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316147f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383715c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316147f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Completed Iteration #0
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316202b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316205c0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316145c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316145c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316145c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316144e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316145c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316144e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30feac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30feae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30feab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30feac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30feab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a8d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381ccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381ccf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e38371978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a4e0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f584a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffda90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30eceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30eadb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30eade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30eadc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30eadac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30eadb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead358> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d650ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0ee390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316457f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6865c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316206d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6865c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316206d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6865c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3871eda0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f85f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30eadfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 12
Completed Iteration #11
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06dc8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30eadfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f85f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3165cef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316202b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30eadda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31620e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316202b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc55c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d686a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30eadd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f81d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f81d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e8405beb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383714e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38371898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f9940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d71aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381ccd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d668128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38355588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382cca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31645e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6959e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6959e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3871ea90> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3871e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31645d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0060f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0060f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0060f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6957b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c0b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316452e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 4500
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ead0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38776208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3165c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e97c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383def98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31620d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877ba58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e383deb70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383beef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382217f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382212e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382217f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382217f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382217f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383bebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38645b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38221ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38645c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f9e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38371fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e84043860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e8405bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6954a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38766080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0063c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0aa390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c09a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119048> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38776828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a550> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38655e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38236f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3869f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387263c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 2
Completed Iteration #3
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3838ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e840436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316f81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f4e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38355940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38221d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386454a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38665d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6954a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d695c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e8405b588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383de828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3838a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38686a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3876deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38694d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3876dd30> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386862e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386da6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386862e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c052978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38686128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d735a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0520b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387e9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38694e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0520b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e386949e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4800
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3875c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c128358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6959e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382367b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e381cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c119b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c13bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b86b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3874fc18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0742f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06caecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06c5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383392b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383392b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed07a2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f58b869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38655d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06dec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e84043da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3826fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06dec128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c006b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386453c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fc5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386453c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06dec128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3839f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e387d3978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0230f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0230f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0230f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e383398d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3837bfd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30feacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee86d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f582b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7295f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d7293c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f582b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c0432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8b00> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6f06d52e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3168c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383398d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c1197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3876d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e387d31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386705f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386707b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e38670898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c101fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f080> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d65ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f080> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386705f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386709e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4e0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e387b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382aeef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38236b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c023978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8ac50> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31620f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e382f8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e386704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c003b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d678ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30fead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0765630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e386709e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06cae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3837b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f585c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38247550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee80b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ececc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f583c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ececf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ececc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecec18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ececc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f583c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece8d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ecef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38247668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316bdc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cf98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e31614198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed0735048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c06d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38339a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f585c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d6cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38670e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30feac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3877b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ee85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38726240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd6a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e301350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e301353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e301352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30135828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30135e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30135e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38726240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e516a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30135828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e383552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38323668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38339a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e301356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38670e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f634e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f8a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30eceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30eceeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30eceeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30eceeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e316142b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300957b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30095e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30095668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300957b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300956d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9c02f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300864a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300864a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300956a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300956d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f3c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab320> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ffdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e301356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30135860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30135860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6f06dec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ed06be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30135860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9d68> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e301352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e316147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e301359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e9d729dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e301352e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e301352e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e301352e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300abe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e301352e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086c18> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30064b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300719e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30002390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30002400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30002518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300719e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 22
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 23
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30064b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 24
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300029b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071860> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e30071048> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3162fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30064fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30064fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e30002c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e382f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f58940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30002208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300866d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30002a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300025c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30071358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f585c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30086518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300020b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3162f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30002128> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbccc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbdeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbdea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbdecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbdea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbdef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bf60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e31614c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30f0c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30095208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30002da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e38259588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b358> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30002198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30095be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300640f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300640f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300abf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300abf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30095be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30095be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e30002048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e514a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e514a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e514a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30e514a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b5f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb408d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb525c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb52828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30e514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e38259c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30064978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30f7ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ebd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30086f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba9e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30ece4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbf5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbcce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e300c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30002978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fba96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e30071780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e316147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb678d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb67048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb678d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb9bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbccac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb67e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb67d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb67f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb67f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb67b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb672b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb67d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb672b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb40a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30135780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e30071358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb1d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fbde5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3003bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e300c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb67748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2a978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb67c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e1fac4438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e1fb2af60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 12.007042253521128
initial coverage: 11.7254
time passed (minutes): 60.0546
iterations: 186
number of new inputs: 320
final coverage: 12.007
total coverage increase: 0.28169
