Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'kmn'], random_seed=2, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7f6f60a8af28>, tc2=<function tc2 at 0x7f6f60a9b048>, tc3=<function tc3 at 0x7f6f60a9b158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 25.625
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 12
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 13
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 14
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 15
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 16
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 17
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 18
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 19
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 20
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 21
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 22
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 23
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 24
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 25
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 26
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 27
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 28
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 29
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 30
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 31
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 32
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 33
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 34
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 35
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.10416666666666785 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.10416666666666785 36
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4048> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.2083333333333357 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.2083333333333357 37
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4048> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4ef0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.2083333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.2083333333333357 38
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4630> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d43c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.31250000000000355 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.31250000000000355 39
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d43c8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.31250000000000355 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.31250000000000355 40
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd0b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d43c8> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.4166666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.4166666666666714 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.4166666666666714 41
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d43c8> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.4166666666666714 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.4166666666666714 42
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4ef0> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.4166666666666714 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.4166666666666714 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.4166666666666714 43
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4ef0> 0.10416666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.4166666666666714 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.4166666666666714 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.4166666666666714 44
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4ef0> 0.10416666666666785 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.4166666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.4166666666666714 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.4166666666666714 45
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.5208333333333393 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.5208333333333393 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.5208333333333393 46
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.5208333333333393 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.5208333333333393 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.5208333333333393 47
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4630> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d43c8> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.5208333333333393 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.5208333333333393 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.5208333333333393 48
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #2
root->2->18
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.5208333333333393 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.5208333333333393 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.5208333333333393 49
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.5208333333333393 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.5208333333333393 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.5208333333333393 50
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.10416666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.5208333333333393 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.5208333333333393 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.5208333333333393 51
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.10416666666666785 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.5208333333333393 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.5208333333333393 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.5208333333333393 52
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.10416666666666785 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.5208333333333393 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.5208333333333393 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.5208333333333393 53
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fba58> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.2083333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.6250000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.6250000000000071 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.6250000000000071 54
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbeb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.31250000000000355 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.729166666666675 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.729166666666675 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.729166666666675 55
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36892b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.4166666666666714 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.8333333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.8333333333333428 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.8333333333333428 56
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbeb8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.4166666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.8333333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.8333333333333428 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.8333333333333428 57
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.4166666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.8333333333333428 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.8333333333333428 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.8333333333333428 58
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #3
root->2->18->6
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727128> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd2b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.5208333333333393 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.9375000000000107 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.9375000000000107 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.9375000000000107 59
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727128> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd2b0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.5208333333333393 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.9375000000000107 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.9375000000000107 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.9375000000000107 60
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.5208333333333393 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.9375000000000107 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.9375000000000107 44
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 0.9375000000000107 61
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd2b0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.6250000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.0416666666666785 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.0416666666666785 45
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.0416666666666785 62
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37153c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.4166666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.729166666666675 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.1458333333333464 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.1458333333333464 46
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.1458333333333464 63
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.5208333333333393 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.8333333333333428 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.2500000000000142 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.2500000000000142 47
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.2500000000000142 64
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37153c8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.5208333333333393 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.8333333333333428 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.2500000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.2500000000000142 48
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.2500000000000142 65
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.5208333333333393 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.8333333333333428 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.2500000000000142 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.2500000000000142 49
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.2500000000000142 66
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e10> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.5208333333333393 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.8333333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.2500000000000142 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.2500000000000142 50
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.2500000000000142 67
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37153c8> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.6250000000000071 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.9375000000000107 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.354166666666682 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.354166666666682 51
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.354166666666682 68
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.6250000000000071 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.9375000000000107 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.354166666666682 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.354166666666682 52
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.354166666666682 69
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37153c8> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.6250000000000071 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.9375000000000107 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.354166666666682 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.354166666666682 53
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.354166666666682 70
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37153c8> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.6250000000000071 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.9375000000000107 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.354166666666682 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.354166666666682 54
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.354166666666682 71
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36895f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.729166666666675 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.0416666666666785 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.45833333333335 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.45833333333335 55
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.45833333333335 72
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #4
root->2->18->6->0
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.729166666666675 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.0416666666666785 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.45833333333335 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.45833333333335 56
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.45833333333335 73
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.8333333333333428 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.1458333333333464 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.5625000000000178 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.5625000000000178 57
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.5625000000000178 74
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e10> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.31250000000000355 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.8333333333333428 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.1458333333333464 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.5625000000000178 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.5625000000000178 58
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.5625000000000178 75
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.31250000000000355 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.8333333333333428 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.1458333333333464 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.5625000000000178 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.5625000000000178 59
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.5625000000000178 76
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.31250000000000355 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.8333333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.1458333333333464 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.5625000000000178 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.5625000000000178 60
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.5625000000000178 77
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36895f8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.31250000000000355 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.8333333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.1458333333333464 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.5625000000000178 44
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.5625000000000178 61
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.5625000000000178 78
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.31250000000000355 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.8333333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.1458333333333464 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.5625000000000178 45
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.5625000000000178 62
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.5625000000000178 79
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.31250000000000355 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.8333333333333428 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.1458333333333464 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.5625000000000178 46
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.5625000000000178 63
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.5625000000000178 80
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.31250000000000355 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.8333333333333428 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.1458333333333464 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.5625000000000178 47
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.5625000000000178 64
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.5625000000000178 81
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36895f8> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.31250000000000355 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.8333333333333428 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.1458333333333464 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.5625000000000178 48
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.5625000000000178 65
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.5625000000000178 82
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #5
root->2->18->6->0->3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.4166666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.9375000000000107 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.2500000000000142 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.6666666666666856 49
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.6666666666666856 66
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.6666666666666856 83
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cc0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.5208333333333393 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.0416666666666785 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.354166666666682 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.7708333333333535 50
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.7708333333333535 67
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.7708333333333535 84
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0860> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.5208333333333393 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.0416666666666785 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.354166666666682 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.7708333333333535 51
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.7708333333333535 68
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.7708333333333535 85
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4f28> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0860> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.6250000000000071 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.1458333333333464 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.45833333333335 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.8750000000000213 52
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.8750000000000213 69
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.8750000000000213 86
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0cc0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.5208333333333393 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.729166666666675 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.2500000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.5625000000000178 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 1.9791666666666892 53
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 1.9791666666666892 70
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 1.9791666666666892 87
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.8333333333333428 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.354166666666682 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.6666666666666856 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.083333333333357 54
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.083333333333357 71
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.083333333333357 88
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.6250000000000071 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.8333333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.354166666666682 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.6666666666666856 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.083333333333357 55
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.083333333333357 72
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.083333333333357 89
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661940> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661cf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.729166666666675 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 0.9375000000000107 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.45833333333335 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.7708333333333535 44
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.187500000000025 56
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.187500000000025 73
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.187500000000025 90
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663390> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661860> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.8333333333333428 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.0416666666666785 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.5625000000000178 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.8750000000000213 45
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.2916666666666927 57
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.2916666666666927 74
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.2916666666666927 91
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.8333333333333428 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.0416666666666785 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.5625000000000178 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.8750000000000213 46
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.2916666666666927 58
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.2916666666666927 75
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.2916666666666927 92
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4f28> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0860> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.8333333333333428 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.0416666666666785 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.5625000000000178 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.8750000000000213 47
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.2916666666666927 59
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.2916666666666927 76
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.2916666666666927 93
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661860> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.9375000000000107 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.1458333333333464 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.6666666666666856 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 1.9791666666666892 48
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.3958333333333606 60
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.3958333333333606 77
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.3958333333333606 94
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #6
root->2->18->6->0->3->19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aba8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.0416666666666785 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.2500000000000142 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.7708333333333535 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.083333333333357 49
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.5000000000000284 61
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.5000000000000284 78
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.5000000000000284 95
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.1458333333333464 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.354166666666682 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.8750000000000213 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.187500000000025 50
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.6041666666666963 62
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.6041666666666963 79
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.6041666666666963 96
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36638d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.2500000000000142 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.45833333333335 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 1.9791666666666892 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.2916666666666927 51
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.708333333333364 63
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.708333333333364 80
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.708333333333364 97
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36610f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.354166666666682 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.5625000000000178 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.083333333333357 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.3958333333333606 52
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.812500000000032 64
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.812500000000032 81
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.812500000000032 98
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cc0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.45833333333335 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.6666666666666856 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.187500000000025 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.5000000000000284 53
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.9166666666667 65
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.9166666666667 82
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.9166666666667 99
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aba8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.45833333333335 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.6666666666666856 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.187500000000025 44
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.5000000000000284 54
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 2.9166666666667 66
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 2.9166666666667 83
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 2.9166666666667 100
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.5625000000000178 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.7708333333333535 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.2916666666666927 45
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.6041666666666963 55
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.0208333333333677 67
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.0208333333333677 84
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.0208333333333677 101
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.0416666666666785 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.5625000000000178 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.7708333333333535 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.2916666666666927 46
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.6041666666666963 56
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.0208333333333677 68
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.0208333333333677 85
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.0208333333333677 102
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661cf8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.1458333333333464 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.6666666666666856 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.8750000000000213 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.3958333333333606 47
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.708333333333364 57
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.1250000000000355 69
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.1250000000000355 86
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.1250000000000355 103
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663ba8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.2500000000000142 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.7708333333333535 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.9791666666666892 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.5000000000000284 48
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.812500000000032 58
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.2291666666667034 70
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.2291666666667034 87
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.2291666666667034 104
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.2500000000000142 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.7708333333333535 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 1.9791666666666892 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.5000000000000284 49
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.812500000000032 59
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.2291666666667034 71
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.2291666666667034 88
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.2291666666667034 105
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679a90> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.354166666666682 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.8750000000000213 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.083333333333357 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.6041666666666963 50
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 2.9166666666667 60
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.3333333333333712 72
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.3333333333333712 89
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.3333333333333712 106
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c18> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.45833333333335 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.9791666666666892 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.187500000000025 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.708333333333364 51
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.0208333333333677 61
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.437500000000039 73
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.437500000000039 90
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.437500000000039 107
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #7
root->2->18->6->0->3->19->4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.45833333333335 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.9791666666666892 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.187500000000025 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.708333333333364 52
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.0208333333333677 62
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.437500000000039 74
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.437500000000039 91
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.437500000000039 108
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.4166666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.45833333333335 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 1.9791666666666892 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.187500000000025 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.708333333333364 53
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.0208333333333677 63
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.437500000000039 75
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.437500000000039 92
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.437500000000039 109
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36617f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4be0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.5208333333333393 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.5625000000000178 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.083333333333357 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.2916666666666927 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.812500000000032 54
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.1250000000000355 64
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.541666666666707 76
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.541666666666707 93
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.541666666666707 110
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661cf8> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.5208333333333393 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.5625000000000178 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.083333333333357 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.2916666666666927 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.812500000000032 55
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.1250000000000355 65
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.541666666666707 77
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.541666666666707 94
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.541666666666707 111
Completed Iteration #3
Best Reward: 0.10416666666666785
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661cf8> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.5208333333333393 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.5625000000000178 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.083333333333357 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.2916666666666927 44
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.812500000000032 56
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.1250000000000355 66
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.541666666666707 78
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.541666666666707 95
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.541666666666707 112
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.5208333333333393 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.5625000000000178 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.083333333333357 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.2916666666666927 45
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.812500000000032 57
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.1250000000000355 67
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.541666666666707 79
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.541666666666707 96
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.541666666666707 113
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661cf8> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.5208333333333393 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.5625000000000178 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.083333333333357 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.2916666666666927 46
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.812500000000032 58
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.1250000000000355 68
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.541666666666707 80
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.541666666666707 97
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.541666666666707 114
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c18> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.6250000000000071 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.6666666666666856 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.187500000000025 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.3958333333333606 47
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.9166666666667 59
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.2291666666667034 69
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.645833333333375 81
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.645833333333375 98
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.645833333333375 115
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4be0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.6250000000000071 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.6666666666666856 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.187500000000025 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.3958333333333606 48
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.9166666666667 60
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.2291666666667034 70
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.645833333333375 82
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.645833333333375 99
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.645833333333375 116
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00764e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.6250000000000071 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.6666666666666856 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.187500000000025 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.3958333333333606 49
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.9166666666667 61
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.2291666666667034 71
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.645833333333375 83
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.645833333333375 100
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.645833333333375 117
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c18> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.6250000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.6666666666666856 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.187500000000025 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.3958333333333606 50
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.9166666666667 62
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.2291666666667034 72
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.645833333333375 84
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.645833333333375 101
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.645833333333375 118
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076eb8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c18> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.6250000000000071 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.6666666666666856 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.187500000000025 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.3958333333333606 51
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 2.9166666666667 63
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.2291666666667034 73
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.645833333333375 85
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.645833333333375 102
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.645833333333375 119
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076f28> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.729166666666675 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.7708333333333535 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.2916666666666927 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.5000000000000284 52
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 3.0208333333333677 64
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.3333333333333712 74
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.7500000000000426 86
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.7500000000000426 103
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.7500000000000426 120
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076748> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.729166666666675 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.7708333333333535 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.2916666666666927 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.5000000000000284 53
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 3.0208333333333677 65
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.3333333333333712 75
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.7500000000000426 87
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.7500000000000426 104
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.7500000000000426 121
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094048> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4be0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.8333333333333428 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 1.8750000000000213 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 2.3958333333333606 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689e80> 2.6041666666666963 54
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 3.1250000000000355 66
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 3.437500000000039 76
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 3.8541666666667105 88
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 3.8541666666667105 105
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f11d0> 3.8541666666667105 122
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #8
root->2->18->6->0->3->19->4->11
Best Reward: 0.10416666666666785
iteration: 0
found coverage increase 0.10416666666666785
Current Total Coverage 25.729166666666664
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00320b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00324e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00945f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00324a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00325c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00645c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00645c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1278> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85deff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c6a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00942e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00942e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 400
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032898> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85deff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 25.729166666666664
cluster_index 13
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7f98> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1940> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.1041666666666714 2
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.1041666666666714 3
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1940> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.1041666666666714 4
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.1041666666666714 5
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 6
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.1041666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 7
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 8
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.1041666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 9
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 10
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.1041666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 11
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 12
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1940> 0.1041666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 13
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 14
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 15
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 16
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1940> 0.1041666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.2083333333333428 17
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032a58> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.2083333333333428 7
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.3125000000000142 18
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094278> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094828> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.3125000000000142 8
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.4166666666666856 19
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.3125000000000142 9
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.4166666666666856 20
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7128> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.4166666666666856 10
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.520833333333357 21
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1ef0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.520833333333357 11
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.6250000000000284 22
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.520833333333357 12
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.6250000000000284 23
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79278> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d791d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1ef0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.6250000000000284 13
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.7291666666666998 24
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032b00> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032d68> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7128> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.7291666666666998 14
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.8333333333333712 25
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032e10> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094828> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.8333333333333712 15
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 0.9375000000000426 26
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094160> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7128> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.9375000000000426 16
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.041666666666714 27
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00946d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.9375000000000426 17
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.041666666666714 28
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00946d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.9375000000000426 18
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.041666666666714 29
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.9375000000000426 19
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.041666666666714 30
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 0.9375000000000426 20
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.041666666666714 31
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a6a0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79f60> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.041666666666714 21
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.1458333333333854 32
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.041666666666714 22
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.1458333333333854 33
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.041666666666714 23
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.1458333333333854 34
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #1
root->8
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4a90> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79f60> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.1458333333333854 24
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.2500000000000568 35
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0748> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0860> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.2500000000000568 25
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.3541666666667282 36
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a09e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094828> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.3541666666667282 26
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.4583333333333997 37
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd898> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.4583333333333997 27
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.562500000000071 38
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7198> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0860> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.562500000000071 28
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.6666666666667425 39
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a2e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.6666666666667425 29
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.7708333333334139 40
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a2b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.7708333333334139 30
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.8750000000000853 41
Completed Iteration #19
Best Reward: 0.1041666666666714
coverage_call_count 500
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4dd8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094828> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.8750000000000853 31
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 1.9791666666667567 42
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0390> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 1.9791666666667567 32
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 2.083333333333428 43
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #2
root->8->18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4978> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 2.083333333333428 33
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 2.1875000000000995 44
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddda0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 2.1875000000000995 34
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 2.291666666666771 45
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd6a0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0390> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 2.291666666666771 35
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 2.3958333333334423 46
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbba8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb908> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddda0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 2.3958333333334423 36
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 2.5000000000001137 47
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 2.5000000000001137 37
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 2.604166666666785 48
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689c50> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689748> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4978> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 2.604166666666785 38
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 2.7083333333334565 49
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689240> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 2.7083333333334565 39
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 2.812500000000128 50
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb38> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 2.812500000000128 40
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 2.9166666666667993 51
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1c18> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4dd8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd898> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 2.9166666666667993 41
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.0208333333334707 52
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4b70> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094e80> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.0208333333334707 42
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.125000000000142 53
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094860> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.125000000000142 43
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.2291666666668135 54
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79748> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1ba8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.2291666666668135 44
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.333333333333485 55
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #3
root->8->18->3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032320> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a470> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4b70> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094e80> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.333333333333485 45
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.4375000000001563 56
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689ac8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.4375000000001563 46
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.5416666666668277 57
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a58> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36891d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.5416666666668277 47
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.645833333333499 58
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094e80> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.645833333333499 48
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.7500000000001705 59
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.125000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.7500000000001705 49
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.854166666666842 60
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd320> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd160> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.2291666666668135 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.854166666666842 50
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 3.9583333333335133 61
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 3.9583333333335133 51
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 4.062500000000185 62
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4550> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094e80> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.4375000000001563 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 4.062500000000185 52
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 4.166666666666856 63
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea37271d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4128> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.5416666666668277 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 4.166666666666856 53
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 4.2708333333335275 64
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4a20> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4128> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.645833333333499 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 4.2708333333335275 54
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 4.375000000000199 65
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0eb8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36891d0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.7500000000001705 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 4.375000000000199 55
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 4.47916666666687 66
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36892b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1ba8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.854166666666842 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 4.47916666666687 56
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 4.583333333333542 67
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd438> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7c18> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 3.9583333333335133 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 4.583333333333542 57
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 4.687500000000213 68
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4828> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1ba8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.125000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 4.062500000000185 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 4.687500000000213 58
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 4.791666666666885 69
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c41d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4be0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4550> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094e80> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.2291666666668135 32
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 4.166666666666856 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 4.791666666666885 59
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 4.895833333333556 70
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c46a0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364ad68> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 4.2708333333335275 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 4.895833333333556 60
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.000000000000227 71
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727b00> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.4375000000001563 34
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 4.375000000000199 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.000000000000227 61
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.104166666666899 72
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727278> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727da0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.5416666666668277 35
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 4.47916666666687 44
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.104166666666899 62
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.20833333333357 73
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #4
root->8->18->3->1
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ee48> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.645833333333499 36
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 4.583333333333542 45
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.20833333333357 63
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.312500000000242 74
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e160> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.7500000000001705 37
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 4.687500000000213 46
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.312500000000242 64
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.416666666666913 75
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715a58> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37155f8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727b00> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.854166666666842 38
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 4.791666666666885 47
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.416666666666913 65
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.520833333333584 76
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0320> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032ba8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e160> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 3.9583333333335133 39
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 4.895833333333556 48
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.520833333333584 66
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.625000000000256 77
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689fd0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 4.062500000000185 40
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.000000000000227 49
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.625000000000256 67
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.729166666666927 78
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb390> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 4.166666666666856 41
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.104166666666899 50
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.729166666666927 68
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.833333333333599 79
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e4e0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032ba8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e160> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 4.2708333333335275 42
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.20833333333357 51
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.833333333333599 69
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 5.93750000000027 80
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727d68> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd160> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 4.375000000000199 43
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.312500000000242 52
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 5.93750000000027 70
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.041666666666941 81
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715fd0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd160> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.125000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 4.47916666666687 44
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.416666666666913 53
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.041666666666941 71
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.145833333333613 82
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #5
root->8->18->3->1->2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771be0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.2291666666668135 32
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 4.583333333333542 45
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.520833333333584 54
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.145833333333613 72
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.250000000000284 83
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4dd8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 4.687500000000213 46
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.625000000000256 55
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.250000000000284 73
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.354166666666956 84
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4b38> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d44a8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771be0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.4375000000001563 34
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 4.791666666666885 47
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.729166666666927 56
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.354166666666956 74
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.458333333333627 85
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4860> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f1dd8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd320> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd160> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.5416666666668277 35
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 4.895833333333556 48
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.833333333333599 57
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.458333333333627 75
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.562500000000298 86
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb860> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.645833333333499 36
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.000000000000227 49
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 5.93750000000027 58
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.562500000000298 76
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.66666666666697 87
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddbe0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.7500000000001705 37
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.104166666666899 50
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.041666666666941 59
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.66666666666697 77
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.770833333333641 88
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727978> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37277b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.854166666666842 38
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.20833333333357 51
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.145833333333613 60
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.770833333333641 78
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.875000000000313 89
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e5c0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd160> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 3.9583333333335133 39
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.312500000000242 52
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.250000000000284 61
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.875000000000313 79
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 6.979166666666984 90
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771d30> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 4.062500000000185 40
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.416666666666913 53
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.354166666666956 62
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 6.979166666666984 80
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 7.0833333333336554 91
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771b00> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 4.166666666666856 41
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.520833333333584 54
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.458333333333627 63
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 7.0833333333336554 81
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 7.187500000000327 92
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4fd0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4438> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 4.2708333333335275 42
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.625000000000256 55
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.562500000000298 64
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 7.187500000000327 82
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 7.291666666666998 93
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4240> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e5c0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd160> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 4.375000000000199 43
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.729166666666927 56
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.66666666666697 65
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 7.291666666666998 83
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 7.39583333333367 94
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 4.47916666666687 44
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.833333333333599 57
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.770833333333641 66
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 7.39583333333367 84
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 7.500000000000341 95
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663358> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771e10> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.125000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 4.583333333333542 45
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 5.93750000000027 58
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.875000000000313 67
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 7.500000000000341 85
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 7.6041666666670125 96
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
coverage_call_count 600
Completed Iteration #21
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4c88> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd160> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.2291666666668135 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 4.687500000000213 46
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.041666666666941 59
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 6.979166666666984 68
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 7.6041666666670125 86
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 7.708333333333684 97
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4f60> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4668> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727978> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea37277b8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 4.791666666666885 47
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.145833333333613 60
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 7.0833333333336554 69
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 7.708333333333684 87
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 7.812500000000355 98
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd630> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37277b8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.4375000000001563 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 4.895833333333556 48
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.250000000000284 61
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 7.187500000000327 70
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 7.812500000000355 88
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 7.916666666667027 99
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #6
root->8->18->3->1->2->10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663a58> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.5416666666668277 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.000000000000227 49
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.354166666666956 62
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 7.291666666666998 71
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 7.916666666667027 89
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.020833333333698 100
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663198> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c88> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771d30> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.645833333333499 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.104166666666899 50
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.458333333333627 63
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 7.39583333333367 72
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.020833333333698 90
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.12500000000037 101
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4550> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.7500000000001705 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.20833333333357 51
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.562500000000298 64
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 7.500000000000341 73
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.12500000000037 91
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.22916666666704 102
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cac8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.854166666666842 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.312500000000242 52
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.66666666666697 65
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 7.6041666666670125 74
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.22916666666704 92
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.333333333333712 103
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c780> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c9e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771be0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 3.9583333333335133 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.416666666666913 53
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.770833333333641 66
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 7.708333333333684 75
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.333333333333712 93
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.437500000000384 104
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b38> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4c50> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4dd8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 4.062500000000185 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.520833333333584 54
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.875000000000313 67
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 7.812500000000355 76
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.437500000000384 94
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.541666666667055 105
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663cf8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663390> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4550> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 4.166666666666856 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.625000000000256 55
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 6.979166666666984 68
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 7.916666666667027 77
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.541666666667055 95
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.645833333333727 106
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d45f8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 4.2708333333335275 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.729166666666927 56
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 7.0833333333336554 69
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.020833333333698 78
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.645833333333727 96
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.750000000000398 107
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd390> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727d30> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4550> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.125000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 4.375000000000199 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.833333333333599 57
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 7.187500000000327 70
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.12500000000037 79
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.750000000000398 97
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.85416666666707 108
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #7
root->8->18->3->1->2->10->3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661dd8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.2291666666668135 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 4.47916666666687 44
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 5.93750000000027 58
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 7.291666666666998 71
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.22916666666704 80
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.85416666666707 98
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 8.95833333333374 109
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715898> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661cf8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 4.583333333333542 45
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.041666666666941 59
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 7.39583333333367 72
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.333333333333712 81
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 8.95833333333374 99
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 9.062500000000412 110
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064ac8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d45f8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.4375000000001563 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 4.687500000000213 46
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.145833333333613 60
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 7.500000000000341 73
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.437500000000384 82
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 9.062500000000412 100
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 9.166666666667084 111
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663f98> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661cf8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.5416666666668277 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 4.791666666666885 47
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.250000000000284 61
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 7.6041666666670125 74
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.541666666667055 83
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 9.166666666667084 101
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 9.270833333333755 112
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064d68> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00642e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.645833333333499 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 4.895833333333556 48
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.354166666666956 62
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 7.708333333333684 75
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.645833333333727 84
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 9.270833333333755 102
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 9.375000000000426 113
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea37157b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715518> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.7500000000001705 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 5.000000000000227 49
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.458333333333627 63
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 7.812500000000355 76
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.750000000000398 85
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 9.375000000000426 103
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 9.479166666667098 114
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c18> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.854166666666842 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 5.104166666666899 50
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.562500000000298 64
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 7.916666666667027 77
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.85416666666707 86
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 9.479166666667098 104
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 9.58333333333377 115
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661198> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 3.9583333333335133 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 5.20833333333357 51
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.66666666666697 65
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 8.020833333333698 78
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 8.95833333333374 87
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 9.58333333333377 105
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 9.68750000000044 116
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064160> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727cc0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 4.062500000000185 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 5.312500000000242 52
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.770833333333641 66
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 8.12500000000037 79
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 9.062500000000412 88
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 9.68750000000044 106
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 9.791666666667112 117
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076550> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727cc0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 4.166666666666856 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 5.416666666666913 53
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.875000000000313 67
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 8.22916666666704 80
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 9.166666666667084 89
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 9.791666666667112 107
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 9.895833333333783 118
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076be0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d45f8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 4.2708333333335275 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 5.520833333333584 54
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 6.979166666666984 68
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 8.333333333333712 81
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 9.270833333333755 90
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 9.895833333333783 108
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 10.000000000000455 119
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679ef0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 4.375000000000199 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 5.625000000000256 55
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9b0> 7.0833333333336554 69
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1400> 8.437500000000384 82
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 9.375000000000426 91
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f98> 10.000000000000455 109
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f28> 10.104166666667126 120
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #8
root->8->18->3->1->2->10->3->11
Best Reward: 0.1041666666666714
iteration: 9
found coverage increase 0.1041666666666714
Current Total Coverage 25.833333333333336
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771eb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85deff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36790f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c9b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74317630> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec438> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742eceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742eceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742eceb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743449e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742eceb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743449e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00647f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742479e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b128> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00767b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742575c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742575c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742473c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742572e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00767b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf60> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 3
Completed Iteration #6
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b588> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742479b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f93c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f60f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74165be0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741040f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741168d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741165c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741165c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741168d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d48d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740881d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74317438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c43c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c43c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c43c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742574a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742574a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7f98> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d892e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 1600
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85deffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36631d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36631d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37277b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 22
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ba8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37157f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743444e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00329b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 25.833333333333336
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e85db14a8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.10416666666666785 11
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.10416666666666785 12
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.10416666666666785 13
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.10416666666666785 14
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.10416666666666785 15
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.10416666666666785 16
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.2083333333333357 17
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.2083333333333357 18
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.2083333333333357 19
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.2083333333333357 20
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.2083333333333357 21
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbf28> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.31250000000000355 22
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.31250000000000355 23
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.4166666666666714 24
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0d68> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.5208333333333393 25
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1ac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.6250000000000071 26
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea00325c0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.729166666666675 27
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.729166666666675 28
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0fd0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.8333333333333428 29
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74344518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a80b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddac8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 0.9375000000000107 30
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4128> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.0416666666666785 31
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea37718d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.1458333333333464 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.1458333333333464 32
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea37157f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4128> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.2500000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.2500000000000142 33
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e85defd30> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.354166666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.354166666666682 34
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4da0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.45833333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.45833333333335 35
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.5625000000000178 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.5625000000000178 36
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661c50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.6666666666666856 37
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094a58> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.7708333333333535 38
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.7708333333333535 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.7708333333333535 39
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.8750000000000213 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.8750000000000213 40
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea00942b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 1.9791666666666892 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 1.9791666666666892 41
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aba8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4128> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.1458333333333464 13
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 2.083333333333357 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 2.083333333333357 42
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eb70> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.2500000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 2.187500000000025 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 2.187500000000025 43
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79438> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.354166666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 2.2916666666666927 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 2.2916666666666927 44
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #2
root->2->17
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddda0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00942b0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.45833333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 2.3958333333333606 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 2.3958333333333606 45
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b49e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661630> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.5625000000000178 17
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 2.5000000000000284 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 2.5000000000000284 46
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79780> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 2.6041666666666963 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 2.6041666666666963 47
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 2.708333333333364 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 2.708333333333364 48
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea364acf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 2.812500000000032 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 2.812500000000032 49
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094160> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364add8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094908> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 1.9791666666666892 21
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 2.9166666666667 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 2.9166666666667 50
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.083333333333357 22
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.0208333333333677 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.0208333333333677 51
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7f60> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7128> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.187500000000025 23
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.1250000000000355 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.1250000000000355 52
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7240> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7f98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00942b0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.2916666666666927 24
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.2291666666667034 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.2291666666667034 53
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36890f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689f60> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364acf8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.3958333333333606 25
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.3333333333333712 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.3333333333333712 54
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e85de76d8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.5000000000000284 26
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.437500000000039 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.437500000000039 55
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defd30> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.5000000000000284 27
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.437500000000039 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.437500000000039 56
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4ac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.6041666666666963 28
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.541666666666707 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.541666666666707 57
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #3
root->2->17->0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094c18> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 1.9791666666666892 21
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.708333333333364 29
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.645833333333375 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.645833333333375 58
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79278> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7128> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.083333333333357 22
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.812500000000032 30
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.7500000000000426 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.7500000000000426 59
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74344860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.187500000000025 23
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.9166666666667 31
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.8541666666667105 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.8541666666667105 60
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79278> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7128> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.187500000000025 24
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 2.9166666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.8541666666667105 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.8541666666667105 61
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689160> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.2916666666666927 25
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.0208333333333677 33
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 3.9583333333333783 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 3.9583333333333783 62
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74056128> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689198> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.3958333333333606 26
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.1250000000000355 34
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 4.062500000000046 44
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 4.062500000000046 63
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7320> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7128> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.5000000000000284 27
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.2291666666667034 35
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 4.166666666666714 45
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 4.166666666666714 64
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e742b70f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076f28> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b49e8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661630> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.1458333333333464 13
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.6041666666666963 28
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.3333333333333712 36
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 4.270833333333382 46
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 4.270833333333382 65
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #4
root->2->17->0->29
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.2500000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.708333333333364 29
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.437500000000039 37
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 4.37500000000005 47
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 4.37500000000005 66
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.354166666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.812500000000032 30
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.541666666666707 38
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 4.479166666666718 48
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 4.479166666666718 67
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7c50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.45833333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 2.9166666666667 31
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.645833333333375 39
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 4.583333333333385 49
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 4.583333333333385 68
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.5625000000000178 17
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.0208333333333677 32
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.7500000000000426 40
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 4.687500000000053 50
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 4.687500000000053 69
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.1250000000000355 33
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.8541666666667105 41
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 4.791666666666721 51
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 4.791666666666721 70
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689da0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ac8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.2291666666667034 34
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 3.9583333333333783 42
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 4.895833333333389 52
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 4.895833333333389 71
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74056eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.3333333333333712 35
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 4.062500000000046 43
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.000000000000057 53
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.000000000000057 72
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
coverage_call_count 1900
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74317e10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 1.9791666666666892 21
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.437500000000039 36
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 4.166666666666714 44
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.104166666666725 54
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.104166666666725 73
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74056278> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165208> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79780> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.083333333333357 22
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.541666666666707 37
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 4.270833333333382 45
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.2083333333333925 55
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.2083333333333925 74
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e741655c0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ba8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.187500000000025 23
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.645833333333375 38
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 4.37500000000005 46
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.31250000000006 56
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.31250000000006 75
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74165f60> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165fd0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7c50> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.2916666666666927 24
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.7500000000000426 39
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 4.479166666666718 47
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.416666666666728 57
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.416666666666728 76
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74104f98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.3958333333333606 25
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.8541666666667105 40
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 4.583333333333385 48
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.520833333333396 58
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.520833333333396 77
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7160> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.5000000000000284 26
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 3.9583333333333783 41
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 4.687500000000053 49
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.625000000000064 59
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.625000000000064 78
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771c50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7128> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7160> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.6041666666666963 27
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.062500000000046 42
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 4.791666666666721 50
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.729166666666732 60
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.729166666666732 79
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #5
root->2->17->0->29->0
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36896a0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.7708333333333535 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.708333333333364 28
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.166666666666714 43
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 4.895833333333389 51
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.8333333333334 61
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.8333333333334 80
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e742f98d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.8750000000000213 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.812500000000032 29
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.270833333333382 44
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.000000000000057 52
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.9375000000000675 62
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.9375000000000675 81
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.812500000000032 30
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.270833333333382 45
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.000000000000057 53
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 5.9375000000000675 63
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 5.9375000000000675 82
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74165320> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165cc0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 1.9791666666666892 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 2.9166666666667 31
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.37500000000005 46
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.104166666666725 54
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.041666666666735 64
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.041666666666735 83
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e741049b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104940> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741655c0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ba8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.083333333333357 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.0208333333333677 32
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.479166666666718 47
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.2083333333333925 55
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.145833333333403 65
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.145833333333403 84
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ba8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.187500000000025 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.1250000000000355 33
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.583333333333385 48
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.31250000000006 56
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.250000000000071 66
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.250000000000071 85
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165cc0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.9375000000000107 12
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.187500000000025 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.1250000000000355 34
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.583333333333385 49
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.31250000000006 57
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.250000000000071 67
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.250000000000071 86
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cdd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1b00> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.0416666666666785 13
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.2916666666666927 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.2291666666667034 35
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.687500000000053 50
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.416666666666728 58
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.354166666666739 68
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.354166666666739 87
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ba8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.1458333333333464 14
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.3958333333333606 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.3333333333333712 36
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.791666666666721 51
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.520833333333396 59
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.458333333333407 69
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.458333333333407 88
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74056ac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094dd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056eb8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.2500000000000142 15
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.5000000000000284 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.437500000000039 37
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 4.895833333333389 52
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.625000000000064 60
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.562500000000075 70
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.562500000000075 89
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.354166666666682 16
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.6041666666666963 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.541666666666707 38
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.000000000000057 53
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.729166666666732 61
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.6666666666667425 71
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.6666666666667425 90
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.354166666666682 17
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.6041666666666963 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.541666666666707 39
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.000000000000057 54
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.729166666666732 62
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.6666666666667425 72
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.6666666666667425 91
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #6
root->2->17->0->29->0->6
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1320> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094dd8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056eb8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.45833333333335 18
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.708333333333364 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.645833333333375 40
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.104166666666725 55
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.8333333333334 63
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.77083333333341 73
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.77083333333341 92
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c400> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cd68> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317e10> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.5625000000000178 19
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.812500000000032 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.7500000000000426 41
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.2083333333333925 56
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 5.9375000000000675 64
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.875000000000078 74
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.875000000000078 93
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74247b00> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.6666666666666856 20
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 2.9166666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.8541666666667105 42
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.31250000000006 57
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.041666666666735 65
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 6.979166666666746 75
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 6.979166666666746 94
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247828> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.7708333333333535 21
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.0208333333333677 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 3.9583333333333783 43
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.416666666666728 58
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.145833333333403 66
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.083333333333414 76
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.083333333333414 95
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b400> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.8750000000000213 22
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.1250000000000355 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.062500000000046 44
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.520833333333396 59
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.250000000000071 67
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.187500000000082 77
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.187500000000082 96
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74056358> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddbe0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b400> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 1.9791666666666892 23
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.2291666666667034 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.166666666666714 45
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.625000000000064 60
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.354166666666739 68
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.29166666666675 78
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.29166666666675 97
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74317be0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b080> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.083333333333357 24
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.3333333333333712 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.270833333333382 46
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.729166666666732 61
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.458333333333407 69
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.395833333333417 79
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.395833333333417 98
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #7
root->2->17->0->29->0->6->3
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e7421ba90> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247828> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.187500000000025 25
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.437500000000039 37
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.37500000000005 47
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.8333333333334 62
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.562500000000075 70
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.500000000000085 80
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.500000000000085 99
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.354166666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.187500000000025 26
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.437500000000039 38
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.37500000000005 48
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.8333333333334 63
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.562500000000075 71
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.500000000000085 81
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.500000000000085 100
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74088588> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b080> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.5208333333333393 7
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.45833333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.2916666666666927 27
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.541666666666707 39
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.479166666666718 49
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 5.9375000000000675 64
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.6666666666667425 72
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.604166666666753 82
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.604166666666753 101
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e740883c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b080> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.5625000000000178 17
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.3958333333333606 28
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.645833333333375 40
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.583333333333385 50
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 6.041666666666735 65
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.77083333333341 73
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.708333333333421 83
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.708333333333421 102
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e740445c0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bb38> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.5000000000000284 29
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.7500000000000426 41
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.687500000000053 51
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 6.145833333333403 66
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.875000000000078 74
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.812500000000089 84
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.812500000000089 103
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bb38> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.729166666666675 10
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.6666666666666856 19
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.5000000000000284 30
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.7500000000000426 42
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.687500000000053 52
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 6.145833333333403 67
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.875000000000078 75
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.812500000000089 85
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.812500000000089 104
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74247e80> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104588> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088588> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b080> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.8333333333333428 11
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.7708333333333535 20
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.6041666666666963 31
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.8541666666667105 43
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.791666666666721 53
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 6.250000000000071 68
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 6.979166666666746 76
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 7.916666666666757 86
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 7.916666666666757 105
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74088908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 0.9375000000000107 12
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.8750000000000213 21
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.708333333333364 32
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 3.9583333333333783 44
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 4.895833333333389 54
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 6.354166666666739 69
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 7.083333333333414 77
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 8.020833333333425 87
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 8.020833333333425 106
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cac8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b080> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 1.0416666666666785 13
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 1.9791666666666892 22
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.812500000000032 33
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 4.062500000000046 45
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 5.000000000000057 55
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 6.458333333333407 70
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 7.187500000000082 78
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 8.125000000000092 88
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 8.125000000000092 107
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247828> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 1.1458333333333464 14
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 2.083333333333357 23
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 2.9166666666667 34
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 4.166666666666714 46
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 5.104166666666725 56
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 6.562500000000075 71
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 7.29166666666675 79
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 8.22916666666676 89
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 8.22916666666676 108
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e740442b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bb38> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 1.2500000000000142 15
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 2.187500000000025 24
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 3.0208333333333677 35
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 4.270833333333382 47
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 5.2083333333333925 57
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 6.6666666666667425 72
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 7.395833333333417 80
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 8.333333333333428 90
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 8.333333333333428 109
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7f6e74044f60> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247828> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74165780> 1.354166666666682 16
backprop <src.mcts.MCTS_Node object at 0x7f6e74056be0> 2.2916666666666927 25
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 3.1250000000000355 36
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e588> 4.37500000000005 48
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af98> 5.31250000000006 58
backprop <src.mcts.MCTS_Node object at 0x7f6e74257438> 6.77083333333341 73
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 7.500000000000085 81
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 8.437500000000096 91
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbdd8> 8.437500000000096 110
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #8
root->2->17->0->29->0->6->3->4
Best Reward: 0.10416666666666785
iteration: 53
found coverage increase 0.10416666666666785
Current Total Coverage 25.937500000000004
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7240> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044eb8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740650f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740650f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740657b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740657b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740657b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2100
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5f60> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7f60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c44a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741baeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c44a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74116400> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740885c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740885c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 17
Completed Iteration #18
Best Reward: 0
coverage_call_count 2200
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ada0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5755f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 2300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 25.937500000000004
cluster_index 14
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d860> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51db00> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.1041666666666643 2
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.1041666666666643 3
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.1041666666666643 4
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.1041666666666643 5
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.1041666666666643 6
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca438> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.2083333333333286 7
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.2083333333333286 8
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5335f8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533898> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.3124999999999929 9
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caba8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533a90> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.4166666666666572 10
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533a90> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.4166666666666572 11
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533898> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.4166666666666572 12
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6320> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51db00> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.5208333333333215 13
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.5208333333333215 14
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51db00> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.5208333333333215 15
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6be0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6978> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca438> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.6249999999999858 16
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.7291666666666501 17
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d61d0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.8333333333333144 18
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533a90> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.8333333333333144 19
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533898> 0.1041666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.8333333333333144 20
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.4166666666666572 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.8333333333333144 21
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d470> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.5208333333333215 8
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 0.9374999999999787 22
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f668> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.6249999999999858 9
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.041666666666643 23
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d7b8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.7291666666666501 10
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.1458333333333073 24
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51def0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f358> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dc88> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.8333333333333144 11
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.2499999999999716 25
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d978> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.9374999999999787 12
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.3541666666666359 26
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.9374999999999787 13
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.3541666666666359 27
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533a20> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.041666666666643 14
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.4583333333333002 28
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca470> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca780> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d7b8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.1458333333333073 15
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.5624999999999645 29
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.1458333333333073 16
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.5624999999999645 30
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f358> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dc88> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.2499999999999716 17
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.6666666666666288 31
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6a20> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.3541666666666359 18
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.770833333333293 32
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5d30> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d7b8> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.4583333333333002 19
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.8749999999999574 33
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e741baac8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.5624999999999645 20
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 1.9791666666666217 34
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5580f0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.6666666666666288 21
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.083333333333286 35
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.6666666666666288 22
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.083333333333286 36
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f358> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dc88> 0.2083333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.6666666666666288 23
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.083333333333286 37
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.6666666666666288 24
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.083333333333286 38
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.6666666666666288 25
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.083333333333286 39
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.6666666666666288 26
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.083333333333286 40
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bc18> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee0b8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.770833333333293 27
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.1874999999999503 41
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee358> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.8749999999999574 28
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.2916666666666146 42
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.5208333333333215 8
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.8749999999999574 29
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.2916666666666146 43
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.5208333333333215 9
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.8749999999999574 30
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.2916666666666146 44
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee0b8> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.5208333333333215 10
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.8749999999999574 31
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.2916666666666146 45
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.5208333333333215 11
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.8749999999999574 32
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.2916666666666146 46
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caef0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.6249999999999858 12
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.9791666666666217 33
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.395833333333279 47
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.6249999999999858 13
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 1.9791666666666217 34
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.395833333333279 48
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.7291666666666501 14
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.083333333333286 35
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.499999999999943 49
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.7291666666666501 15
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.083333333333286 36
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.499999999999943 50
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caef0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7e48> 0.3124999999999929 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.7291666666666501 16
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.083333333333286 37
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.499999999999943 51
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d358> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6a90> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bc18> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee0b8> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.8333333333333144 17
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.1874999999999503 38
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.6041666666666075 52
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeb70> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.9374999999999787 18
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.2916666666666146 39
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.7083333333332718 53
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eef28> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eef98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.041666666666643 19
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.395833333333279 40
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.812499999999936 54
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.041666666666643 20
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.395833333333279 41
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.812499999999936 55
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.041666666666643 21
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.395833333333279 42
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.812499999999936 56
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #2
root->0->1
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd710> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.1458333333333073 22
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.499999999999943 43
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 2.9166666666666003 57
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487f60> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.2499999999999716 23
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.6041666666666075 44
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.0208333333332646 58
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489278> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.3541666666666359 24
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.7083333333332718 45
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.124999999999929 59
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4895c0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.7291666666666501 8
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.4583333333333002 25
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.812499999999936 46
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.2291666666665932 60
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.8333333333333144 9
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.5624999999999645 26
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.9166666666666003 47
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.3333333333332575 61
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee358> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.5624999999999645 27
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 2.9166666666666003 48
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.3333333333332575 62
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d400> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.6666666666666288 28
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.0208333333332646 49
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.437499999999922 63
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee320> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.770833333333293 29
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.124999999999929 50
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.541666666666586 64
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487f60> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.041666666666643 13
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.770833333333293 30
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.124999999999929 51
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.541666666666586 65
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d400> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.041666666666643 14
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.770833333333293 31
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.124999999999929 52
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.541666666666586 66
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e10> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.1458333333333073 15
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.8749999999999574 32
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.2291666666665932 53
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.6458333333332504 67
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4892b0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eee48> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6a20> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.2499999999999716 16
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 1.9791666666666217 33
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.3333333333332575 54
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.7499999999999147 68
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489898> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.3541666666666359 17
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.083333333333286 34
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.437499999999922 55
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.854166666666579 69
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab0f0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.4583333333333002 18
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.1874999999999503 35
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.541666666666586 56
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 3.9583333333332433 70
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab4a8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.5624999999999645 19
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.2916666666666146 36
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.6458333333332504 57
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.062499999999908 71
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #3
root->0->1->6
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.5624999999999645 20
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.2916666666666146 37
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.6458333333332504 58
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.062499999999908 72
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7588> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7198> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab0f0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.6666666666666288 21
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.395833333333279 38
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.7499999999999147 59
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.166666666666572 73
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.770833333333293 22
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.499999999999943 39
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.854166666666579 60
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.270833333333236 74
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d9b0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.8749999999999574 23
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.6041666666666075 40
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.9583333333332433 61
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.3749999999999005 75
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.6249999999999858 9
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.8749999999999574 24
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.6041666666666075 41
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 3.9583333333332433 62
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.3749999999999005 76
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4897f0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.7291666666666501 10
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.9791666666666217 25
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.7083333333332718 42
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.062499999999908 63
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.479166666666565 77
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.7291666666666501 11
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.9791666666666217 26
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.7083333333332718 43
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.062499999999908 64
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.479166666666565 78
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489390> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.7291666666666501 12
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.9791666666666217 27
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.7083333333332718 44
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.062499999999908 65
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.479166666666565 79
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489390> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.7291666666666501 13
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 1.9791666666666217 28
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.7083333333332718 45
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.062499999999908 66
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.479166666666565 80
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab160> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487668> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.8333333333333144 14
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.083333333333286 29
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.812499999999936 46
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.166666666666572 67
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.583333333333229 81
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4879b0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.9374999999999787 15
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.1874999999999503 30
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 2.9166666666666003 47
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.270833333333236 68
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.687499999999893 82
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7208> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487668> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.041666666666643 16
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.2916666666666146 31
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.0208333333332646 48
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.3749999999999005 69
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.791666666666558 83
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b76a0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489390> 0.2083333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.1458333333333073 17
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.395833333333279 32
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.124999999999929 49
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.479166666666565 70
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.895833333333222 84
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7b00> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4879b0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.2499999999999716 18
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.499999999999943 33
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.2291666666665932 50
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.583333333333229 71
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 4.999999999999886 85
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7f28> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7da0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab0f0> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.3541666666666359 19
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.6041666666666075 34
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.3333333333332575 51
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.687499999999893 72
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.104166666666551 86
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.3541666666666359 20
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.6041666666666075 35
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.3333333333332575 52
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.687499999999893 73
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.104166666666551 87
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abf60> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abcc0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.7291666666666501 8
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.4583333333333002 21
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.7083333333332718 36
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.437499999999922 53
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.791666666666558 74
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.208333333333215 88
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.8333333333333144 9
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.5624999999999645 22
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.812499999999936 37
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.541666666666586 54
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.895833333333222 75
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.312499999999879 89
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #4
root->0->1->6->1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d9b0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.5624999999999645 23
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.812499999999936 38
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.541666666666586 55
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.895833333333222 76
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.312499999999879 90
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7c50> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.6666666666666288 24
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 2.9166666666666003 39
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.6458333333332504 56
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 4.999999999999886 77
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.4166666666665435 91
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4871d0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab898> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.770833333333293 25
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.0208333333332646 40
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.7499999999999147 57
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.104166666666551 78
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.520833333333208 92
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.041666666666643 13
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.770833333333293 26
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.0208333333332646 41
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.7499999999999147 58
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.104166666666551 79
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.520833333333208 93
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454ef0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.1458333333333073 14
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.8749999999999574 27
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.124999999999929 42
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.854166666666579 59
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.208333333333215 80
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.624999999999872 94
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454eb8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.2499999999999716 15
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.9791666666666217 28
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.2291666666665932 43
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.9583333333332433 60
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.312499999999879 81
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.729166666666536 95
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.2499999999999716 16
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 1.9791666666666217 29
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.2291666666665932 44
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 3.9583333333332433 61
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.312499999999879 82
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.729166666666536 96
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463780> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.3541666666666359 17
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.083333333333286 30
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.3333333333332575 45
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.062499999999908 62
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.4166666666665435 83
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.833333333333201 97
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.3541666666666359 18
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.083333333333286 31
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.3333333333332575 46
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.062499999999908 63
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.4166666666665435 84
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.833333333333201 98
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab4e0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d320> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454eb8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.4583333333333002 19
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.1874999999999503 32
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.437499999999922 47
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.166666666666572 64
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.520833333333208 85
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 5.937499999999865 99
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487278> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.5624999999999645 20
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.2916666666666146 33
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.541666666666586 48
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.270833333333236 65
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.624999999999872 86
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.041666666666529 100
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7198> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab0f0> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.5624999999999645 21
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.2916666666666146 34
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.541666666666586 49
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.270833333333236 66
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.624999999999872 87
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.041666666666529 101
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #5
root->0->1->6->1->0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894a8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.6666666666666288 22
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.395833333333279 35
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.6458333333332504 50
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.3749999999999005 67
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.729166666666536 88
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.145833333333194 102
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4636a0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.770833333333293 23
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.499999999999943 36
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.7499999999999147 51
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.479166666666565 68
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.833333333333201 89
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.249999999999858 103
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463358> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.8749999999999574 24
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.6041666666666075 37
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.854166666666579 52
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.583333333333229 69
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.937499999999865 90
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.354166666666522 104
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.8749999999999574 25
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.6041666666666075 38
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.854166666666579 53
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.583333333333229 70
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 5.937499999999865 91
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.354166666666522 105
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4726a0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472400> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 1.9791666666666217 26
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.7083333333332718 39
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 3.9583333333332433 54
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.687499999999893 71
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.041666666666529 92
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.4583333333331865 106
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7a58> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.083333333333286 27
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.812499999999936 40
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.062499999999908 55
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.791666666666558 72
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.145833333333194 93
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.562499999999851 107
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472400> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.8333333333333144 11
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.083333333333286 28
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.812499999999936 41
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.062499999999908 56
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.791666666666558 73
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.145833333333194 94
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.562499999999851 108
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487f28> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dcf8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4871d0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab898> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 0.9374999999999787 12
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.1874999999999503 29
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 2.9166666666666003 42
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.166666666666572 57
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.895833333333222 74
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.249999999999858 95
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.666666666666515 109
Completed Iteration #10
Best Reward: 0.1041666666666643
coverage_call_count 2500
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab1d0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dcf8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4871d0> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab898> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.041666666666643 13
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.2916666666666146 30
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.0208333333332646 43
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.270833333333236 58
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 4.999999999999886 75
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.354166666666522 96
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.770833333333179 110
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489048> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489908> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.1458333333333073 14
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.395833333333279 31
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.124999999999929 44
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.3749999999999005 59
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.104166666666551 76
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.4583333333331865 97
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.874999999999844 111
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472d68> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.2499999999999716 15
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.499999999999943 32
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.2291666666665932 45
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.479166666666565 60
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.208333333333215 77
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.562499999999851 98
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.979166666666508 112
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7a58> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.2499999999999716 16
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.499999999999943 33
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.2291666666665932 46
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.479166666666565 61
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.208333333333215 78
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.562499999999851 99
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 6.979166666666508 113
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ef0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab898> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.3541666666666359 17
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.6041666666666075 34
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.3333333333332575 47
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.583333333333229 62
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.312499999999879 79
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.666666666666515 100
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.083333333333172 114
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.3541666666666359 18
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.6041666666666075 35
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.3333333333332575 48
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.583333333333229 63
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.312499999999879 80
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.666666666666515 101
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.083333333333172 115
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.4583333333333002 19
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.7083333333332718 36
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.437499999999922 49
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.687499999999893 64
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.4166666666665435 81
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.770833333333179 102
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.187499999999837 116
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c940> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463860> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.5624999999999645 20
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.812499999999936 37
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.541666666666586 50
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.791666666666558 65
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.520833333333208 82
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.874999999999844 103
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.291666666666501 117
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47ccc0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.6666666666666288 21
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.9166666666666003 38
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.6458333333332504 51
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.895833333333222 66
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.624999999999872 83
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.979166666666508 104
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.395833333333165 118
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.6666666666666288 22
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 2.9166666666666003 39
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.6458333333332504 52
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.895833333333222 67
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.624999999999872 84
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 6.979166666666508 105
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.395833333333165 119
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 0.7291666666666501 8
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.770833333333293 23
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.0208333333332646 40
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.7499999999999147 53
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 4.999999999999886 68
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.729166666666536 85
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 7.083333333333172 106
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.4999999999998295 120
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #6
root->0->1->6->1->0->0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 0.8333333333333144 9
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.8749999999999574 24
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.124999999999929 41
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.854166666666579 54
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 5.104166666666551 69
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.833333333333201 86
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 7.187499999999837 107
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.604166666666494 121
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4722e8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472710> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 0.9374999999999787 10
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 1.9791666666666217 25
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.2291666666665932 42
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 3.9583333333332433 55
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 5.208333333333215 70
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 5.937499999999865 87
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 7.291666666666501 108
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.708333333333158 122
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7c18> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c2e8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.041666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.083333333333286 26
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.3333333333332575 43
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.062499999999908 56
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 5.312499999999879 71
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.041666666666529 88
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 7.395833333333165 109
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.812499999999822 123
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c438> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c4a8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472f98> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.1458333333333073 12
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.1874999999999503 27
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.437499999999922 44
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.166666666666572 57
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 5.4166666666665435 72
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.145833333333194 89
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 7.4999999999998295 110
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 7.916666666666487 124
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cfd0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.2499999999999716 13
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.2916666666666146 28
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.541666666666586 45
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.270833333333236 58
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 5.520833333333208 73
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.249999999999858 90
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 7.604166666666494 111
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.020833333333151 125
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc4a8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc2e8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4636a0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.3541666666666359 14
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.395833333333279 29
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.6458333333332504 46
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.3749999999999005 59
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 5.624999999999872 74
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.354166666666522 91
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 7.708333333333158 112
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.124999999999815 126
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc940> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.4583333333333002 15
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.499999999999943 30
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.7499999999999147 47
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.479166666666565 60
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 5.729166666666536 75
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.4583333333331865 92
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 7.812499999999822 113
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.22916666666648 127
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcf60> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.5624999999999645 16
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.6041666666666075 31
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.854166666666579 48
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.583333333333229 61
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 5.833333333333201 76
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.562499999999851 93
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 7.916666666666487 114
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.333333333333144 128
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454c50> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.6666666666666288 17
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.7083333333332718 32
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 3.9583333333332433 49
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.687499999999893 62
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 5.937499999999865 77
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.666666666666515 94
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.020833333333151 115
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.437499999999808 129
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472438> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.770833333333293 18
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.812499999999936 33
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.062499999999908 50
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.791666666666558 63
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.041666666666529 78
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.770833333333179 95
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.124999999999815 116
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.541666666666472 130
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47ccc0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.770833333333293 19
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.812499999999936 34
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.062499999999908 51
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.791666666666558 64
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.041666666666529 79
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.770833333333179 96
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.124999999999815 117
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.541666666666472 131
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc400> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcc50> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc940> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.8749999999999574 20
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 2.9166666666666003 35
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.166666666666572 52
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.895833333333222 65
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.145833333333194 80
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.874999999999844 97
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.22916666666648 118
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.645833333333137 132
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47ce48> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 1.9791666666666217 21
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.0208333333332646 36
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.270833333333236 53
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 4.999999999999886 66
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.249999999999858 81
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 6.979166666666508 98
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.333333333333144 119
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.749999999999801 133
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6278> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e62e8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472d68> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 2.083333333333286 22
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.124999999999929 37
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.3749999999999005 54
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 5.104166666666551 67
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.354166666666522 82
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 7.083333333333172 99
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.437499999999808 120
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.854166666666465 134
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6cc0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 2.1874999999999503 23
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.2291666666665932 38
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.479166666666565 55
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 5.208333333333215 68
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.4583333333331865 83
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 7.187499999999837 100
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.541666666666472 121
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 8.95833333333313 135
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #7
root->0->1->6->1->0->0->6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6c88> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9160> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4722e8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472710> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 2.2916666666666146 24
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.3333333333332575 39
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.583333333333229 56
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 5.312499999999879 69
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.562499999999851 84
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 7.291666666666501 101
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.645833333333137 122
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.062499999999794 136
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587f94a8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9240> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 2.395833333333279 25
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.437499999999922 40
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.687499999999893 57
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 5.4166666666665435 70
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.666666666666515 85
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 7.395833333333165 102
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.749999999999801 123
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.166666666666458 137
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463438> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c2e8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 2.499999999999943 26
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.541666666666586 41
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.791666666666558 58
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 5.520833333333208 71
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.770833333333179 86
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 7.4999999999998295 103
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.854166666666465 124
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.270833333333123 138
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6898> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6908> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 0.7291666666666501 8
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 2.6041666666666075 27
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.6458333333332504 42
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.895833333333222 59
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 5.624999999999872 72
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.874999999999844 87
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 7.604166666666494 104
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 8.95833333333313 125
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.374999999999787 139
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6748> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c2e8> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 0.8333333333333144 9
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 2.7083333333332718 28
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.7499999999999147 43
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 4.999999999999886 60
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 5.729166666666536 73
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 6.979166666666508 88
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 7.708333333333158 105
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 9.062499999999794 126
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.479166666666451 140
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472780> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6908> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 0.9374999999999787 10
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 2.812499999999936 29
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.854166666666579 44
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 5.104166666666551 61
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 5.833333333333201 74
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 7.083333333333172 89
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 7.812499999999822 106
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 9.166666666666458 127
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.583333333333115 141
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47ce80> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c2e8> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 1.041666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 2.9166666666666003 30
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 3.9583333333332433 45
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 5.208333333333215 62
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 5.937499999999865 75
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 7.187499999999837 90
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 7.916666666666487 107
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 9.270833333333123 128
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.68749999999978 142
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9550> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4630b8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 1.1458333333333073 12
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 3.0208333333332646 31
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 4.062499999999908 46
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 5.312499999999879 63
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 6.041666666666529 76
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 7.291666666666501 91
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 8.020833333333151 108
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 9.374999999999787 129
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.791666666666444 143
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9be0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9a20> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6748> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c2e8> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 1.2499999999999716 13
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 3.124999999999929 32
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 4.166666666666572 47
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 5.4166666666665435 64
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 6.145833333333194 77
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 7.395833333333165 92
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 8.124999999999815 109
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 9.479166666666451 130
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.895833333333108 144
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7f6e58795b38> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795ba8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463048> 1.3541666666666359 14
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463518> 3.2291666666665932 33
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489780> 4.270833333333236 48
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 5.520833333333208 65
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 6.249999999999858 78
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6748> 7.4999999999998295 93
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 8.22916666666648 110
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 9.583333333333115 131
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d4e0> 9.999999999999773 145
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #8
root->0->1->6->1->0->0->6->14
Best Reward: 0.1041666666666643
iteration: 68
found coverage increase 0.1041666666666643
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc208> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 2600
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 6
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 7
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 8
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 9
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2710> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58771b70> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4878d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4878d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4878d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4878d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 2700
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36796d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36796d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36796d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4876d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4876d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4876d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 2800
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4878d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6cc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5587f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5752b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4aba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4aba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 2900
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740657b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740650b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba4e0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c2e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740757f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740757f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740757f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740757f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b710> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3000
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741656a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741656a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743177b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743177b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743175c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74247ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741656a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741656a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 12
Completed Iteration #23
Best Reward: 0
coverage_call_count 3100
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00940f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d799e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00945c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00945c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00945c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00940f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740759b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5750b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742472b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741bada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 14
Completed Iteration #20
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742472b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741bada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742472b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1470> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ee48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58771d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85deffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85deffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 3300
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85defba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064978> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00642b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb128> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743449e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740884e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743449e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740444a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740444a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74088208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36636a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742576a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743440b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743440b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587640f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743440b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4543c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587427f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587649b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b20b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587b20b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 3600
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc358> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58764860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00642b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74065ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587095c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587095c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9470> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4729e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4729e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 11
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c75f8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587096d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c198> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525644a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525164a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525167f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525166a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525164a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d06d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4729e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee550> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74344320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516160> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eeef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 19
Completed Iteration #22
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795e48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249df60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dc18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b79e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740563c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587426a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740563c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740563c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740563c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740563c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587426a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58742cf8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740440b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740442b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740446a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740442b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85deffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740446a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85deffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740442b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740446a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85deffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74044828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742578d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 4200
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740441d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89588> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c72b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c72b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c72b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74088dd8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37270f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37276d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37275c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37276d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b41d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4721d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58742128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00948d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00948d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740564e0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743179e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741168d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741168d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4896d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741baeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee6a0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489c88> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58742b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 4500
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85def278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533860> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58764358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740560b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5332b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd30> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4877b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587716d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689a90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525166d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587717b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525166d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 4700
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587710f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587710f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58764c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4875c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c88> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74344278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e525646d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587717b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 12
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f91d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 19
Completed Iteration #22
Best Reward: 0
coverage_call_count 4900
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cfd0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74116ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e743447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587959b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587959b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795860> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 5100
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a54e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587957b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587957b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516176a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516286d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e51617128> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516289e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc27b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516280b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516289e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516280b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516280b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516289e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516667b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd0f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd0f0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f996a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f849b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f996a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 10
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 11
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92b0> 0.0 12
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f628d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f628d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa77f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe99e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f841d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 3
Completed Iteration #4
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f266a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee72e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b9b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e990b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e999e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e990b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e994e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e994e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e999e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587957b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e569e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e567b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f052e8> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 5700
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e144a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e144a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e144a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e144a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0ac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0add8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e360f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e360f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e360f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e360f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e365f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e149b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e149b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 12
Completed Iteration #19
Best Reward: 0
coverage_call_count 5800
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36128> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509efdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36c88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaeef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2160> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0acc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0acc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e995c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509420b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 8
Completed Iteration #15
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e10> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea364a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea364aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741f5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b710> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d66a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e567f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e743449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2278> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74116dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb25c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f624a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f999e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74165518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741655f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509558d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509558d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2860> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58795470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf2b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58795828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7421b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fc2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50955278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e563c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a5583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 6200
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4caa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74065978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742f98d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1438> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f94e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516bd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74165518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587f94e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52564198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f99ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f62ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516e8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587099e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587092b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587092b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e563c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e52516cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741a7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524c2160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e587715f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e525164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525160f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5164f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525160f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50955668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a472cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5164fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52564668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58709240> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab2e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a533a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e56f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a558278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5096bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c46a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a463e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a575ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4894e0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e52516a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ab0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e525164e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb2208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587096d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ed1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740c4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5096b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741049e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741046a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741046a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a454748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741046a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36ddb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74104828> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 6500
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85e0cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00767b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74104b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36b4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea00767b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a51d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a47c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74317240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5257f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36fbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e52516dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0076c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58771ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58764588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58709588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487b38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85defbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742577b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74088eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7426fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85def898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e740446a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3661ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37f14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e74056860> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e741bad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea37718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74056d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7426f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d79588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742ec668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3771fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea00949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea36d4160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3689908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74075588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74247128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74044fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7413ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74044fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3663198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abdd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509422b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5247a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e740c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3727a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4eea58> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7412a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea004cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5256c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0064438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74317668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea36c4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e58771518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea37718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0032f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e50eb23c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516962b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e5c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3679128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 15
Completed Iteration #14
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a489b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7427ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e587b22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ea58> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742b7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e587dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74056d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4ee048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e741d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e58709588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5246e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dc88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50942fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea3715dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa76a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85db1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea0094518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516661d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74247c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e146d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e146d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e146d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f05c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e7413c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe92e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e85de77f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4b7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 8
Completed Iteration #10
Best Reward: 0
coverage_call_count 7000
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85d89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85e1e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7427eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516283c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516283c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509875c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51666e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516174e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50e362b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509efdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509efef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516177f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509efef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509efdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f3bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7429b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a4abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509870b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e516170f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e998d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e998d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5241d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51666748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e997f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e501171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501170f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e501176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501174e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e501265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e501267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6ea377e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50126a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e99898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74257048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a7c7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e501170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e85de7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50117470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ceb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e524d0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50987278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5099eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5013ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e501262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5013ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f6e501176a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ecfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec9e8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5a487e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5240bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5099eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5013ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e742477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f26e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e500952b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50987278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51617f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50eaef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50eae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50117eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7240> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500496a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500496a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500952e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500fec18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500566d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500676d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500676d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50056cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f84f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e509e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51617f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500496a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e516967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 7400
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500678d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500678d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500038d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500035c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50026be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500038d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500eca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500034e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500eca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500038d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5013a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500038d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500eca90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e10> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 14
coverage_call_count 7500
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50f844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50056a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50ee7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50049048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e509e2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50056550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 15
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335bbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bbba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 4
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335bba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e7411fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5097cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6ea36a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bbba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6f28> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50942198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fa7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50fe9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33595748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50067080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6cc0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e501176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500036d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e50003f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335146d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5249d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e500ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335143c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33528a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5243a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50067b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500036d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500038d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50003ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e14b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e500036d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e33514b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33480080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33480278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33480908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e74075588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e5003b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33480cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33595630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334dda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335bbef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50095128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51696e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50026d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33595278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50026e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50e36978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3354eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33528b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33480518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33480e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33480ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f11d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334ddf60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3354ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50056550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50003c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3357ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33480c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 17
Completed Iteration #16
Best Reward: 0
coverage_call_count 7800
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334dd588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334425f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e335e27f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e334800b8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33464240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334429b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33464630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33464d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33464dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33464eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334643c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3347c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3347c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3347c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33464ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334643c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33464198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334649b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3347c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334647b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33464780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334643c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33464e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3347c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3347c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334649b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33464320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 26.041666666666668
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33464748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e334b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33528b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33514320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e51628198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e3357cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33464668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e50049358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e334b1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e33480780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e3344ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f6e335e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e50095128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f6e33442f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 26.041666666666668
initial coverage: 25.625
time passed (minutes): 60.1558
iterations: 276
number of new inputs: 256
final coverage: 26.0417
total coverage increase: 0.416667
