Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'nbc'], random_seed=3, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7f7e31847f28>, tc2=<function tc2 at 0x7f7e31858048>, tc3=<function tc3 at 0x7f7e31858158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 7.82443
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580704e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580704e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580705c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580705c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580705c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580705c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580618d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580332b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 11
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 12
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580336d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcb38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c50b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ce80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486238d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486238d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486238d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486238d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486238d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483acd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483acf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483acf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca58> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486234a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9518> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483082b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483082b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d6c053860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483350b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483080b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd23c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d9405b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe04e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483784a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483aca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483786a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483169e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483acf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483786a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483acf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483781d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483162b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580331d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580707f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ace10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580704e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483ace10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483acd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c57f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d482088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9400> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d94089828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d94089828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d482087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f7b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eebe0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d482086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d94089828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ef98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fab38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac18> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ee80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9390> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480872e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480874a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 1000
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087278> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480994e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480994e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f77b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b470> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480462b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480550f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480555f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046550> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046b70> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d482086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d94089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407b92b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f76a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407860b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407860b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407868d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f358> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 1300
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f5f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480558d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480558d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480558d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f5f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480550f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480550f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d482088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d58033b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48208860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d482084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d482084a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d6c053860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 1500
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480559b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480559b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48055470> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483354e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe48> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58033cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483f93c8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e160> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48035908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076afd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48335710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483089e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480876d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480876d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a240> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 20
Completed Iteration #21
Best Reward: 0
coverage_call_count 1800
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407caa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407caba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe07b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a7b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b128> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480352e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480675f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480675f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481facc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481faf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481facc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481faf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481faf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480462e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481faf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481faf98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407866a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d3569af28> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356567f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356567f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cda0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc438> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d35656390> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34beec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34beec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48046da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34beec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a550> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b546a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b544e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b421d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b423c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34beee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34beeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fb00> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356567f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356567f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b549b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb06d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91588> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91668> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b239b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 2500
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b549b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 8
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 9
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 10
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b230b8> 0.0 11
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a919b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a919b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b630> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580338d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b541d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34beed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b544e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34beed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48378b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54390> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 2600
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48335be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48067940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407aefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48099668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48099320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aefd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aefd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407aefd0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4811bb70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a92b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34beeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a92b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34beeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a048> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a90b8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a918d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a918d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a485f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 17
Completed Iteration #20
Best Reward: 0
coverage_call_count 2700
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a918d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a918d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a485f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407cab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48308860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407cacf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58033908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48335a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48067630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bee4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91dd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812aa90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 2800
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7f28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5ba7ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48316668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48087048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4811b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4077f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48378b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48355550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4863aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dffd0b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480676a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d94089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4807aeb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d482084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d94089710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4807add8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4807a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480f7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a485f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48355ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48308dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d580707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48208978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34beed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48623b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d407ca860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d480557b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b664e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d406fb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b66e80> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fe0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4812ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48055fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d480879e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4076a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be09e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4863a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be04a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be02b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356427b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48208dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d48035518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48087d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d58070828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b543c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d580617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48623710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be07b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d35642c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483bdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4813edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a819b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a819b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4070f7f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d480469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48046358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0f98> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 3200
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3569a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48316470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d48035d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4816eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356420b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d356420b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481faa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35656ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d35656da0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a4b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d58070828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dffd0b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35656f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4816e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4079c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483ac898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a91160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 3300
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee5f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34189dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34189710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34189ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34189d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34189710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee1d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34189be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34189da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34189940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341898d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341898d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34189240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34189630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34189940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d341af080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d356420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483f9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34189e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7dffd0b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4814b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bcc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1b00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341afdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d57fd21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d407b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d4815a208> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341afb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341afc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341afc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341afc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341afc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4815ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d40786358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4865c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d35642e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5800a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b9f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341aff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341049b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341049b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34104dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34104048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 13
Completed Iteration #20
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a1d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b42cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481bdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d40786518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a81a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341894e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d35642e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34a918d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d486235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341afe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340afa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340afc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340afe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340be5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340be358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340510f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340be5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340bee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d5801f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340bedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340510f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340bedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34be0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340510f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340affd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afcf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4070fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341afba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340afc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f240> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340afa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341afb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34075860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340effd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341aff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341aff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b1d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34a6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401bba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34134630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34104c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34075940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340323c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34134908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d34032048> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ffd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ffeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d481fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d4822eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ffeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff7b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340323c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341341d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34ad71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d341341d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3401b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d340af278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340efda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34032ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b23e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7499e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340beda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34051be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d341aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3400d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34075320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34051898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3410f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7ff198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d080> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34bb0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7495c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7153c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34032630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a1d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7155f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7297f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766d68> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f766390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7efa90> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f6c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f6c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f78d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7296d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f75a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f6c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f6c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f6c90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f6c90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f6c90f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f715748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 4000
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d483c5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749048> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7299e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73f588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34b54ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f73fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f729198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7494a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d3416ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340cfba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aeddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d340ef198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d3416f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d340cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f7494a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7d34aedf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7d34aed710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7d2f749b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 7.8244274809160315
initial coverage: 7.82443
time passed (minutes): 60.2963
iterations: 157
number of new inputs: 0
final coverage: 7.82443
total coverage increase: 0
