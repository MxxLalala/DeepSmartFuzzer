Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'kmn'], random_seed=1, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7fe8aaf68f28>, tc2=<function tc2 at 0x7fe8aaf79048>, tc3=<function tc3 at 0x7fe8aaf79158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 11.7254
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe830667668> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667470> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.03521126760563398 2
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.03521126760563398 3
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.03521126760563398 4
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe830667860> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.10563380281690193 5
Completed Iteration #3
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.10563380281690193 6
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667860> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.10563380281690193 7
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.10563380281690193 8
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe830674978> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.1408450704225359 9
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667470> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.1408450704225359 10
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.1408450704225359 11
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.1408450704225359 12
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667470> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.1408450704225359 13
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce5c0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667c18> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.21126760563380387 14
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667470> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.21126760563380387 15
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.21126760563380387 16
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce9e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.24647887323943785 17
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667470> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.24647887323943785 18
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8057de080> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cefd0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667860> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.21126760563380387 6
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.3169014084507058 19
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.3169014084507058 20
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe830667198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.24647887323943785 7
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.3521126760563398 21
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.3521126760563398 22
Completed Iteration #23
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667c18> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.3521126760563398 23
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.3521126760563398 24
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #0
root
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe830674710> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674240> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce9e8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.2816901408450718 8
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.38732394366197376 25
Completed Iteration #3
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.38732394366197376 26
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.38732394366197376 27
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce9b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.3169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.42253521126760774 28
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.3169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.42253521126760774 29
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.3169014084507058 13
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.42253521126760774 30
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667860> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.3169014084507058 14
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.42253521126760774 31
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057deb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674978> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.3169014084507058 15
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.42253521126760774 32
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ded68> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674978> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.4577464788732417 33
Completed Iteration #23
Best Reward: 0.07042253521126796
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6710> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f62e8> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4577464788732417 17
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5633802816901436 34
Completed Iteration #24
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6ac8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667198> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 18
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 35
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #1
root->7
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 19
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 36
Completed Iteration #0
Best Reward: 0.10563380281690193
Completed Iteration #1
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 37
Completed Iteration #2
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 21
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 38
Completed Iteration #3
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 22
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 39
Completed Iteration #4
Best Reward: 0.10563380281690193
Completed Iteration #5
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057812b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 23
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 40
Completed Iteration #6
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 24
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 41
Completed Iteration #7
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f62e8> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 25
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 42
Completed Iteration #8
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 26
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 43
Completed Iteration #9
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.4929577464788757 27
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.5985915492957776 44
Completed Iteration #10
Best Reward: 0.10563380281690193
Completed Iteration #11
Best Reward: 0.10563380281690193
Completed Iteration #12
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057deeb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057812b0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.5281690140845097 28
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.6338028169014116 45
Completed Iteration #13
Best Reward: 0.10563380281690193
Completed Iteration #14
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f62e8> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.5281690140845097 29
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.6338028169014116 46
Completed Iteration #15
Best Reward: 0.10563380281690193
Completed Iteration #16
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8057815f8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6c88> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.5985915492957776 30
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.7042253521126796 47
Completed Iteration #17
Best Reward: 0.10563380281690193
Completed Iteration #18
Best Reward: 0.10563380281690193
Completed Iteration #19
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe805781588> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.2816901408450718 16
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.6690140845070456 31
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.7746478873239475 48
Completed Iteration #20
Best Reward: 0.10563380281690193
Completed Iteration #21
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805781be0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.3169014084507058 17
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.7042253521126796 32
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.8098591549295815 49
Completed Iteration #22
Best Reward: 0.10563380281690193
Completed Iteration #23
Best Reward: 0.10563380281690193
Completed Iteration #24
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6c88> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.3169014084507058 18
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.7042253521126796 33
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.8098591549295815 50
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #2
root->7->0
Best Reward: 0.10563380281690193
Completed Iteration #0
Best Reward: 0.10563380281690193
Completed Iteration #1
Best Reward: 0.10563380281690193
Completed Iteration #2
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.3169014084507058 19
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.7042253521126796 34
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.8098591549295815 51
Completed Iteration #3
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.1760563380281699 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.38732394366197376 20
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.7746478873239475 35
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.8802816901408494 52
Completed Iteration #4
Best Reward: 0.10563380281690193
Completed Iteration #5
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5e80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.21126760563380387 6
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.42253521126760774 21
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.8098591549295815 36
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.9154929577464834 53
Completed Iteration #6
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac390> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.24647887323943785 7
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.4577464788732417 22
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.8450704225352155 37
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.9507042253521174 54
Completed Iteration #7
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.24647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.4577464788732417 23
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.8450704225352155 38
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.9507042253521174 55
Completed Iteration #8
Best Reward: 0.10563380281690193
Completed Iteration #9
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe830667438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830658e48> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac588> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.4929577464788757 24
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.8802816901408494 39
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.9859154929577514 56
Completed Iteration #10
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.4929577464788757 25
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.8802816901408494 40
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.9859154929577514 57
Completed Iteration #11
Best Reward: 0.10563380281690193
Completed Iteration #12
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781588> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.2816901408450718 11
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.4929577464788757 26
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.8802816901408494 41
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 0.9859154929577514 58
Completed Iteration #13
Best Reward: 0.10563380281690193
Completed Iteration #14
Best Reward: 0.10563380281690193
Completed Iteration #15
Best Reward: 0.10563380281690193
Completed Iteration #16
Best Reward: 0.10563380281690193
Completed Iteration #17
Best Reward: 0.10563380281690193
Completed Iteration #18
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5cf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac390> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.3169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5281690140845097 27
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9154929577464834 42
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0211267605633854 59
Completed Iteration #19
Best Reward: 0.10563380281690193
Completed Iteration #20
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.3169014084507058 13
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5281690140845097 28
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9154929577464834 43
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0211267605633854 60
Completed Iteration #21
Best Reward: 0.10563380281690193
Completed Iteration #22
Best Reward: 0.10563380281690193
Completed Iteration #23
Best Reward: 0.10563380281690193
Completed Iteration #24
Best Reward: 0.10563380281690193
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #3
root->7->0->7
Best Reward: 0.10563380281690193
Completed Iteration #0
Best Reward: 0.10563380281690193
Completed Iteration #1
Best Reward: 0.10563380281690193
Completed Iteration #2
Best Reward: 0.10563380281690193
Completed Iteration #3
Best Reward: 0.10563380281690193
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.3169014084507058 14
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5281690140845097 29
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9154929577464834 44
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0211267605633854 61
Completed Iteration #4
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.3169014084507058 15
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5281690140845097 30
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9154929577464834 45
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0211267605633854 62
Completed Iteration #5
Best Reward: 0.10563380281690193
Completed Iteration #6
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805750438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac8d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5633802816901436 31
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9507042253521174 46
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0563380281690193 63
Completed Iteration #7
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.3521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5633802816901436 32
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9507042253521174 47
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0563380281690193 64
Completed Iteration #8
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.3521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5633802816901436 33
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9507042253521174 48
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0563380281690193 65
Completed Iteration #9
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac8d0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.3521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5633802816901436 34
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9507042253521174 49
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0563380281690193 66
Completed Iteration #10
Best Reward: 0.10563380281690193
Completed Iteration #11
Best Reward: 0.10563380281690193
Completed Iteration #12
Best Reward: 0.10563380281690193
Completed Iteration #13
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac8d0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.3521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5633802816901436 35
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9507042253521174 50
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0563380281690193 67
Completed Iteration #14
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.38732394366197376 21
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.5985915492957776 36
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 0.9859154929577514 51
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.0915492957746533 68
Completed Iteration #15
Best Reward: 0.10563380281690193
Completed Iteration #16
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057dea58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6eb8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.42253521126760774 22
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.6338028169014116 37
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.0211267605633854 52
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.1267605633802873 69
Completed Iteration #17
Best Reward: 0.10563380281690193
Completed Iteration #18
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe805781e48> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac8d0> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.24647887323943785 12
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.4929577464788757 23
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.7042253521126796 38
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.0915492957746533 53
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.1971830985915553 70
Completed Iteration #19
Best Reward: 0.10563380281690193
Completed Iteration #20
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.3521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.5985915492957776 24
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.8098591549295815 39
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.1971830985915553 54
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.3028169014084572 71
Completed Iteration #21
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7fe805750198> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac9e8> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.4577464788732417 14
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.7042253521126796 25
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.9154929577464834 40
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.3028169014084572 55
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.4084507042253591 72
Completed Iteration #22
Best Reward: 0.10563380281690193
Completed Iteration #23
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe805750ba8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057812e8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.5281690140845097 15
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.7746478873239475 26
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 0.9859154929577514 41
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.3732394366197251 56
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.478873239436627 73
Completed Iteration #24
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805750518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac9e8> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.5633802816901436 16
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.8098591549295815 27
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.0211267605633854 42
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.4084507042253591 57
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.514084507042261 74
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #4
root->7->0->7->14
Best Reward: 0.10563380281690193
Completed Iteration #0
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5be0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.21126760563380387 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.6338028169014116 17
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.8802816901408494 28
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.0915492957746533 43
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.478873239436627 58
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.584507042253529 75
Completed Iteration #1
Best Reward: 0.10563380281690193
Completed Iteration #2
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.21126760563380387 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.6338028169014116 18
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.8802816901408494 29
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.0915492957746533 44
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.478873239436627 59
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.584507042253529 76
Completed Iteration #3
Best Reward: 0.10563380281690193
Completed Iteration #4
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.21126760563380387 6
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.6338028169014116 19
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.8802816901408494 30
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.0915492957746533 45
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.478873239436627 60
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.584507042253529 77
Completed Iteration #5
Best Reward: 0.10563380281690193
Completed Iteration #6
Best Reward: 0.10563380281690193
Completed Iteration #7
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057accf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.21126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.6338028169014116 20
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.8802816901408494 31
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.0915492957746533 46
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.478873239436627 61
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.584507042253529 78
Completed Iteration #8
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805777438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.24647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.6690140845070456 21
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.9154929577464834 32
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.1267605633802873 47
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.514084507042261 62
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.619718309859163 79
Completed Iteration #9
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057777f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.7042253521126796 22
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.9507042253521174 33
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.1619718309859213 48
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.549295774647895 63
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.654929577464797 80
Completed Iteration #10
Best Reward: 0.10563380281690193
Completed Iteration #11
Best Reward: 0.10563380281690193
Completed Iteration #12
Best Reward: 0.10563380281690193
Completed Iteration #13
Best Reward: 0.10563380281690193
Completed Iteration #14
Best Reward: 0.10563380281690193
Completed Iteration #15
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.7042253521126796 23
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.9507042253521174 34
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.1619718309859213 49
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.549295774647895 64
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.654929577464797 81
Completed Iteration #16
Best Reward: 0.10563380281690193
Completed Iteration #17
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.2816901408450718 11
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.7042253521126796 24
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.9507042253521174 35
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.1619718309859213 50
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.549295774647895 65
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.654929577464797 82
Completed Iteration #18
Best Reward: 0.10563380281690193
Completed Iteration #19
Best Reward: 0.10563380281690193
Completed Iteration #20
Best Reward: 0.10563380281690193
Completed Iteration #21
Best Reward: 0.10563380281690193
Completed Iteration #22
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057a55f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.3169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.7394366197183135 25
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.9859154929577514 36
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.1971830985915553 51
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.584507042253529 66
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.690140845070431 83
Completed Iteration #23
Best Reward: 0.10563380281690193
Completed Iteration #24
Best Reward: 0.10563380281690193
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #5
root->7->0->7->14->4
Best Reward: 0.10563380281690193
Completed Iteration #0
Best Reward: 0.10563380281690193
Completed Iteration #1
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.3169014084507058 13
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.7394366197183135 26
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.9859154929577514 37
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.1971830985915553 52
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.584507042253529 67
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.690140845070431 84
Completed Iteration #2
Best Reward: 0.10563380281690193
Completed Iteration #3
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7fe80575cda0> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.21126760563380387 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.42253521126760774 14
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.8450704225352155 27
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.0915492957746533 38
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.3028169014084572 53
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.690140845070431 68
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.7957746478873329 85
Completed Iteration #4
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805777da0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777e80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.24647887323943785 6
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.4577464788732417 15
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.8802816901408494 28
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.1267605633802873 39
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.3380281690140912 54
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.725352112676065 69
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.8309859154929669 86
Completed Iteration #5
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805708358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cda0> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.2816901408450718 7
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.4929577464788757 16
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.9154929577464834 29
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.1619718309859213 40
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.3732394366197251 55
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.760563380281699 70
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.8661971830986008 87
Completed Iteration #6
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777e80> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.2816901408450718 8
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.4929577464788757 17
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.9154929577464834 30
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.1619718309859213 41
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.3732394366197251 56
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.760563380281699 71
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.8661971830986008 88
Completed Iteration #7
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777e80> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.4929577464788757 18
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.9154929577464834 31
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.1619718309859213 42
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.3732394366197251 57
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.760563380281699 72
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.8661971830986008 89
Completed Iteration #8
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.4929577464788757 19
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.9154929577464834 32
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.1619718309859213 43
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.3732394366197251 58
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.760563380281699 73
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.8661971830986008 90
Completed Iteration #9
Best Reward: 0.10563380281690193
Completed Iteration #10
Best Reward: 0.10563380281690193
Completed Iteration #11
Best Reward: 0.10563380281690193
Completed Iteration #12
Best Reward: 0.10563380281690193
Completed Iteration #13
Best Reward: 0.10563380281690193
Completed Iteration #14
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.2816901408450718 11
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.4929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.9154929577464834 33
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.1619718309859213 44
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.3732394366197251 59
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.760563380281699 74
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.8661971830986008 91
Completed Iteration #15
Best Reward: 0.10563380281690193
Completed Iteration #16
Best Reward: 0.10563380281690193
Completed Iteration #17
Best Reward: 0.10563380281690193
Completed Iteration #18
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7fe805708748> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777f60> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.38732394366197376 12
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.5985915492957776 21
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.0211267605633854 34
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.2676056338028232 45
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.478873239436627 60
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.8661971830986008 75
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 1.9718309859155028 92
Completed Iteration #19
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe805781978> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.21126760563380387 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.4577464788732417 13
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.6690140845070456 22
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.0915492957746533 35
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.3380281690140912 46
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.549295774647895 61
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.9366197183098688 76
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.0422535211267707 93
Completed Iteration #20
Best Reward: 0.10563380281690193
Completed Iteration #21
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777f60> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.4577464788732417 14
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.6690140845070456 23
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.0915492957746533 36
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.3380281690140912 47
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.549295774647895 62
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 1.9366197183098688 77
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.0422535211267707 94
Completed Iteration #22
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe805708e48> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777f60> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.5281690140845097 15
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.7394366197183135 24
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.1619718309859213 37
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.4084507042253591 48
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.619718309859163 63
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.0070422535211367 78
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.1126760563380387 95
Completed Iteration #23
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777f60> 0.1760563380281699 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.5281690140845097 16
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.7394366197183135 25
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.1619718309859213 38
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.4084507042253591 49
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.619718309859163 64
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.0070422535211367 79
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.1126760563380387 96
Completed Iteration #24
Best Reward: 0.10563380281690193
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #6
root->7->0->7->14->4->0
Best Reward: 0.10563380281690193
Completed Iteration #0
Best Reward: 0.10563380281690193
Completed Iteration #1
Best Reward: 0.10563380281690193
Completed Iteration #2
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.24647887323943785 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.5633802816901436 17
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.7746478873239475 26
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.1971830985915553 39
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.443661971830993 50
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.654929577464797 65
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.0422535211267707 80
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.1478873239436727 97
Completed Iteration #3
Best Reward: 0.10563380281690193
Completed Iteration #4
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe80570a518> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.3169014084507058 6
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.6338028169014116 18
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.8450704225352155 27
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.2676056338028232 40
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.514084507042261 51
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.725352112676065 66
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.1126760563380387 81
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.2183098591549406 98
Completed Iteration #5
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.42253521126760774 7
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.7394366197183135 19
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 0.9507042253521174 28
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.3732394366197251 41
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.619718309859163 52
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.8309859154929669 67
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.2183098591549406 82
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.3239436619718425 99
Completed Iteration #6
Best Reward: 0.10563380281690193
Completed Iteration #7
Best Reward: 0.10563380281690193
Completed Iteration #8
Best Reward: 0.10563380281690193
Completed Iteration #9
Best Reward: 0.10563380281690193
Completed Iteration #10
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe805750860> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.4929577464788757 8
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.8098591549295815 20
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.0211267605633854 29
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.443661971830993 42
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.690140845070431 53
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.9014084507042348 68
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.2887323943662086 83
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.3943661971831105 100
Completed Iteration #11
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781898> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cda0> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.5281690140845097 9
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.8450704225352155 21
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.0563380281690193 30
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.478873239436627 43
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.725352112676065 54
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.9366197183098688 69
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.3239436619718425 84
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.4295774647887445 101
Completed Iteration #12
Best Reward: 0.10563380281690193
Completed Iteration #13
Best Reward: 0.10563380281690193
Completed Iteration #14
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe80570a5c0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.5633802816901436 10
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.8802816901408494 22
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.0915492957746533 31
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.514084507042261 44
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.760563380281699 55
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 1.9718309859155028 70
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.3591549295774765 85
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.4647887323943785 102
Completed Iteration #15
Best Reward: 0.10563380281690193
Completed Iteration #16
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8057082e8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.6338028169014116 11
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.9507042253521174 23
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.1619718309859213 32
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.584507042253529 45
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.8309859154929669 56
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.0422535211267707 71
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.4295774647887445 86
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.5352112676056464 103
Completed Iteration #17
Best Reward: 0.10563380281690193
Completed Iteration #18
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7fe8057087b8> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.7394366197183135 12
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.0563380281690193 24
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.2676056338028232 33
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.690140845070431 46
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 1.9366197183098688 57
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.1478873239436727 72
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.5352112676056464 87
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.6408450704225483 104
Completed Iteration #19
Best Reward: 0.10563380281690193
Completed Iteration #20
Best Reward: 0.10563380281690193
Completed Iteration #21
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8057294e0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729358> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cda0> 0.24647887323943785 5
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.8098591549295815 13
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.1267605633802873 25
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.3380281690140912 34
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.760563380281699 47
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.0070422535211367 58
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.2183098591549406 73
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.6056338028169144 88
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.7112676056338163 105
Completed Iteration #22
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe805729c88> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729908> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057082e8> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.8802816901408494 14
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.1971830985915553 26
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.4084507042253591 35
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.8309859154929669 48
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.0774647887324047 59
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.2887323943662086 74
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.6760563380281823 89
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.7816901408450843 106
Completed Iteration #23
Best Reward: 0.10563380281690193
Completed Iteration #24
Best Reward: 0.10563380281690193
Reward: 0.10563380281690193
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.10563380281690193 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.9859154929577514 15
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.3028169014084572 27
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.514084507042261 36
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 1.9366197183098688 49
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.1830985915493066 60
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.3943661971831105 75
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.7816901408450843 90
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.887323943661986 107
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #7
root->7->0->7->14->4->0->6
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8056be390> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be1d0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.1760563380281699 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.0563380281690193 16
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.3732394366197251 28
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.584507042253529 37
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.0070422535211367 50
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.2535211267605746 61
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.4647887323943785 76
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.852112676056352 91
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.957746478873254 108
Completed Iteration #0
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.0563380281690193 17
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.3732394366197251 29
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.584507042253529 38
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.0070422535211367 51
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.2535211267605746 62
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.4647887323943785 77
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.852112676056352 92
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.957746478873254 109
Completed Iteration #1
Best Reward: 0.10563380281690193
Completed Iteration #2
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057291d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.1760563380281699 5
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.0563380281690193 18
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.3732394366197251 30
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.584507042253529 39
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.0070422535211367 52
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.2535211267605746 63
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.4647887323943785 78
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.852112676056352 93
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.957746478873254 110
Completed Iteration #3
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805729eb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.21126760563380387 6
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.0915492957746533 19
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.4084507042253591 31
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.619718309859163 40
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.0422535211267707 53
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.2887323943662086 64
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.5000000000000124 79
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.887323943661986 94
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 2.992957746478888 111
Completed Iteration #4
Best Reward: 0.10563380281690193
Completed Iteration #5
Best Reward: 0.10563380281690193
Completed Iteration #6
Best Reward: 0.10563380281690193
Completed Iteration #7
Best Reward: 0.10563380281690193
Completed Iteration #8
Best Reward: 0.10563380281690193
Completed Iteration #9
Best Reward: 0.10563380281690193
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe80570a048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be6d8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.24647887323943785 7
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.1267605633802873 20
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.443661971830993 32
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.654929577464797 41
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.0774647887324047 54
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.3239436619718425 65
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.5352112676056464 80
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.92253521126762 95
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 3.028169014084522 112
Completed Iteration #10
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8056be048> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.3169014084507058 8
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.1971830985915553 21
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.514084507042261 33
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.725352112676065 42
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.1478873239436727 55
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.3943661971831105 66
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.6056338028169144 81
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.992957746478888 96
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 3.09859154929579 113
Completed Iteration #11
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be048> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.3169014084507058 9
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.1971830985915553 22
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.514084507042261 34
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.725352112676065 43
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.1478873239436727 56
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.3943661971831105 67
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.6056338028169144 82
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.992957746478888 97
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 3.09859154929579 114
Completed Iteration #12
Best Reward: 0.10563380281690193
Completed Iteration #13
Best Reward: 0.10563380281690193
coverage_call_count 200
Completed Iteration #14
Best Reward: 0.10563380281690193
Completed Iteration #15
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be6d8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.3169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.1971830985915553 23
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.514084507042261 35
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.725352112676065 44
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.1478873239436727 57
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.3943661971831105 68
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.6056338028169144 83
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 2.992957746478888 98
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 3.09859154929579 115
Completed Iteration #16
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7400> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cd30> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.38732394366197376 11
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.2676056338028232 24
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.584507042253529 36
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.7957746478873329 45
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.2183098591549406 58
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.4647887323943785 69
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.6760563380281823 84
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 3.063380281690156 99
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 3.169014084507058 116
Completed Iteration #17
Best Reward: 0.10563380281690193
Completed Iteration #18
Best Reward: 0.10563380281690193
Completed Iteration #19
Best Reward: 0.10563380281690193
Completed Iteration #20
Best Reward: 0.10563380281690193
Completed Iteration #21
Best Reward: 0.10563380281690193
Completed Iteration #22
Best Reward: 0.10563380281690193
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7e10> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc160> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.4577464788732417 12
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.3380281690140912 25
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.654929577464797 37
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.8661971830986008 46
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.2887323943662086 59
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.5352112676056464 70
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.7464788732394503 85
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 3.133802816901424 100
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 3.239436619718326 117
Completed Iteration #23
Best Reward: 0.10563380281690193
Completed Iteration #24
Best Reward: 0.10563380281690193
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057297b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc160> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.4577464788732417 13
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 1.3380281690140912 26
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 1.654929577464797 38
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5d30> 1.8661971830986008 47
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 2.2887323943662086 60
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 2.5352112676056464 71
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceba8> 2.7464788732394503 86
backprop <src.mcts.MCTS_Node object at 0x7fe830667780> 3.133802816901424 101
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5b00> 3.239436619718326 118
Completed Iteration #25
Best Reward: 0.10563380281690193
Completed MCTS Level/Depth: #8
root->7->0->7->14->4->0->6->1
Best Reward: 0.10563380281690193
iteration: 0
found coverage increase 0.10563380281690193
Current Total Coverage 11.830985915492958
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056beeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d75f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d75f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 11.830985915492958
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcf98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 11.830985915492958
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 11.830985915492958
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056492e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056492e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe805663048> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4be0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0352112676056322 15
Completed Iteration #15
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663048> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4be0> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0352112676056322 16
Completed Iteration #16
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056498d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0352112676056322 17
Completed Iteration #17
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 18
Completed Iteration #18
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4be0> 0.0352112676056322 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 19
Completed Iteration #19
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056497f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056492e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 20
Completed Iteration #20
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 21
Completed Iteration #21
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 22
Completed Iteration #22
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 23
Completed Iteration #23
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 24
Completed Iteration #24
Best Reward: 0.0352112676056322
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #0
root
Best Reward: 0.0352112676056322
Completed Iteration #0
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.0352112676056322 4
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 25
Completed Iteration #1
Best Reward: 0.0352112676056322
Completed Iteration #2
Best Reward: 0.0352112676056322
Completed Iteration #3
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.0352112676056322 5
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 26
Completed Iteration #4
Best Reward: 0.0352112676056322
Completed Iteration #5
Best Reward: 0.0352112676056322
Completed Iteration #6
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.0352112676056322 6
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 27
Completed Iteration #7
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.0352112676056322 7
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.0704225352112644 28
Completed Iteration #8
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80575c048> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b1d0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.0704225352112644 8
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.1056338028168966 29
Completed Iteration #9
Best Reward: 0.0352112676056322
Completed Iteration #10
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80570a400> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.1056338028168966 9
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.1408450704225288 30
Completed Iteration #11
Best Reward: 0.0352112676056322
Completed Iteration #12
Best Reward: 0.0352112676056322
Completed Iteration #13
Best Reward: 0.0352112676056322
Completed Iteration #14
Best Reward: 0.0352112676056322
Completed Iteration #15
Best Reward: 0.0352112676056322
Completed Iteration #16
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.1056338028168966 10
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.1408450704225288 31
Completed Iteration #17
Best Reward: 0.0352112676056322
Completed Iteration #18
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.1056338028168966 11
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.1408450704225288 32
Completed Iteration #19
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.1056338028168966 12
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.1408450704225288 33
Completed Iteration #20
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80568bb00> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.1408450704225288 13
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.176056338028161 34
Completed Iteration #21
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.1408450704225288 14
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.176056338028161 35
Completed Iteration #22
Best Reward: 0.0352112676056322
Completed Iteration #23
Best Reward: 0.0352112676056322
Completed Iteration #24
Best Reward: 0.0352112676056322
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #1
root->7
Best Reward: 0.0352112676056322
Completed Iteration #0
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe805663320> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.1056338028168966 4
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.176056338028161 15
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.2112676056337932 36
Completed Iteration #1
Best Reward: 0.0352112676056322
Completed Iteration #2
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe805663b00> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b1d0> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.1408450704225288 5
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.2112676056337932 16
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.2464788732394254 37
Completed Iteration #3
Best Reward: 0.0352112676056322
Completed Iteration #4
Best Reward: 0.0352112676056322
Completed Iteration #5
Best Reward: 0.0352112676056322
Completed Iteration #6
Best Reward: 0.0352112676056322
Completed Iteration #7
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.1408450704225288 6
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.2112676056337932 17
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.2464788732394254 38
Completed Iteration #8
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80410b710> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b390> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.176056338028161 7
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.2464788732394254 18
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.2816901408450576 39
Completed Iteration #9
Best Reward: 0.0352112676056322
Completed Iteration #10
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd30> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bb00> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.2112676056337932 8
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.2816901408450576 19
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.3169014084506898 40
Completed Iteration #11
Best Reward: 0.0352112676056322
Completed Iteration #12
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80410bb38> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649ba8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.2464788732394254 9
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.3169014084506898 20
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.352112676056322 41
Completed Iteration #13
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.2464788732394254 10
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.3169014084506898 21
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.352112676056322 42
Completed Iteration #14
Best Reward: 0.0352112676056322
Completed Iteration #15
Best Reward: 0.0352112676056322
Completed Iteration #16
Best Reward: 0.0352112676056322
Completed Iteration #17
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b390> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.2464788732394254 11
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.3169014084506898 22
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.352112676056322 43
Completed Iteration #18
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe804113860> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.2816901408450576 12
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.352112676056322 23
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.3873239436619542 44
Completed Iteration #19
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b1d0> 0.0704225352112644 4
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.2816901408450576 13
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.352112676056322 24
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.3873239436619542 45
Completed Iteration #20
Best Reward: 0.0352112676056322
Completed Iteration #21
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.2816901408450576 14
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.352112676056322 25
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.3873239436619542 46
Completed Iteration #22
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b1d0> 0.0704225352112644 5
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.2816901408450576 15
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.352112676056322 26
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.3873239436619542 47
Completed Iteration #23
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bb00> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.2816901408450576 16
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.352112676056322 27
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.3873239436619542 48
Completed Iteration #24
Best Reward: 0.0352112676056322
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #2
root->7->10
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4b38> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.1056338028168966 4
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.3169014084506898 17
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.3873239436619542 28
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.4225352112675864 49
Completed Iteration #0
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcc88> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.1408450704225288 5
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.352112676056322 18
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.4225352112675864 29
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.4577464788732186 50
Completed Iteration #1
Best Reward: 0.0352112676056322
Completed Iteration #2
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe805663ef0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.176056338028161 6
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.3873239436619542 19
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.4577464788732186 30
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.4929577464788508 51
Completed Iteration #3
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041132b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4b38> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.176056338028161 7
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.3873239436619542 20
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.4577464788732186 31
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.4929577464788508 52
Completed Iteration #4
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.176056338028161 8
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.3873239436619542 21
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.4577464788732186 32
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.4929577464788508 53
Completed Iteration #5
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056dceb8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.2112676056337932 9
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.4225352112675864 22
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.4929577464788508 33
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.528169014084483 54
Completed Iteration #6
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe804113748> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113710> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcc88> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.2464788732394254 10
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.4577464788732186 23
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.528169014084483 34
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.5633802816901152 55
Completed Iteration #7
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80410b898> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.2816901408450576 11
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.4929577464788508 24
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.5633802816901152 35
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.5985915492957474 56
Completed Iteration #8
Best Reward: 0.0352112676056322
Completed Iteration #9
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80410beb8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.3169014084506898 12
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.528169014084483 25
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.5985915492957474 36
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.6338028169013796 57
Completed Iteration #10
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.3169014084506898 13
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.528169014084483 26
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.5985915492957474 37
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.6338028169013796 58
Completed Iteration #11
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.352112676056322 14
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.5633802816901152 27
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.6338028169013796 38
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.6690140845070118 59
Completed Iteration #12
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80410b4e0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.3873239436619542 15
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.5985915492957474 28
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.6690140845070118 39
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.704225352112644 60
Completed Iteration #13
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8041185f8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.4225352112675864 16
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.6338028169013796 29
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.704225352112644 40
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.7394366197182762 61
Completed Iteration #14
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe804118c50> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.4577464788732186 17
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.6690140845070118 30
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.7394366197182762 41
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.7746478873239084 62
Completed Iteration #15
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80575ca90> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.4929577464788508 18
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.704225352112644 31
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.7746478873239084 42
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.8098591549295406 63
Completed Iteration #16
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.4929577464788508 19
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.704225352112644 32
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.7746478873239084 43
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.8098591549295406 64
Completed Iteration #17
Best Reward: 0.0352112676056322
Completed Iteration #18
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe805663f98> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.528169014084483 20
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.7394366197182762 33
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.8098591549295406 44
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.8450704225351728 65
Completed Iteration #19
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056a55f8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4b38> 0.0704225352112644 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.5633802816901152 21
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.7746478873239084 34
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.8450704225351728 45
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.880281690140805 66
Completed Iteration #20
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113860> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.5633802816901152 22
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.7746478873239084 35
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.8450704225351728 46
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.880281690140805 67
Completed Iteration #21
Best Reward: 0.0352112676056322
Completed Iteration #22
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.5985915492957474 23
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.8098591549295406 36
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.880281690140805 47
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.9154929577464372 68
Completed Iteration #23
Best Reward: 0.0352112676056322
Completed Iteration #24
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8041182e8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.6338028169013796 24
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.8450704225351728 37
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9154929577464372 48
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.9507042253520694 69
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #3
root->7->10->0
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.0704225352112644 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.6338028169013796 25
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.8450704225351728 38
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9154929577464372 49
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.9507042253520694 70
Completed Iteration #0
Best Reward: 0.0352112676056322
Completed Iteration #1
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.0704225352112644 5
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.6338028169013796 26
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.8450704225351728 39
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9154929577464372 50
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.9507042253520694 71
Completed Iteration #2
Best Reward: 0.0352112676056322
Completed Iteration #3
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe804131128> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.1056338028168966 6
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.6690140845070118 27
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.880281690140805 40
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9507042253520694 51
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.9859154929577016 72
Completed Iteration #4
Best Reward: 0.0352112676056322
Completed Iteration #5
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.1056338028168966 7
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.6690140845070118 28
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.880281690140805 41
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9507042253520694 52
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.9859154929577016 73
Completed Iteration #6
Best Reward: 0.0352112676056322
Completed Iteration #7
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.1056338028168966 8
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.6690140845070118 29
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.880281690140805 42
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9507042253520694 53
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.9859154929577016 74
Completed Iteration #8
Best Reward: 0.0352112676056322
Completed Iteration #9
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.1056338028168966 9
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.6690140845070118 30
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.880281690140805 43
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9507042253520694 54
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 0.9859154929577016 75
Completed Iteration #10
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7400> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131a20> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.1408450704225288 10
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.704225352112644 31
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9154929577464372 44
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9859154929577016 55
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.0211267605633338 76
Completed Iteration #11
Best Reward: 0.0352112676056322
Completed Iteration #12
Best Reward: 0.0352112676056322
coverage_call_count 400
Completed Iteration #13
Best Reward: 0.0352112676056322
Completed Iteration #14
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0704225352112644 4
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.1408450704225288 11
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.704225352112644 32
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9154929577464372 45
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9859154929577016 56
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.0211267605633338 77
Completed Iteration #15
Best Reward: 0.0352112676056322
Completed Iteration #16
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.1408450704225288 12
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.704225352112644 33
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9154929577464372 46
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9859154929577016 57
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.0211267605633338 78
Completed Iteration #17
Best Reward: 0.0352112676056322
Completed Iteration #18
Best Reward: 0.0352112676056322
Completed Iteration #19
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.1408450704225288 13
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.704225352112644 34
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9154929577464372 47
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.9859154929577016 58
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.0211267605633338 79
Completed Iteration #20
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5b70> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131240> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 14
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 35
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 48
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 59
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 80
Completed Iteration #21
Best Reward: 0.0352112676056322
Completed Iteration #22
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 15
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 36
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 49
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 60
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 81
Completed Iteration #23
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 16
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 37
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 50
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 61
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 82
Completed Iteration #24
Best Reward: 0.0352112676056322
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #4
root->7->10->0->1
Best Reward: 0.0352112676056322
Completed Iteration #0
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0704225352112644 5
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 17
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 38
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 51
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 62
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 83
Completed Iteration #1
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0704225352112644 6
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 18
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 39
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 52
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 63
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 84
Completed Iteration #2
Best Reward: 0.0352112676056322
Completed Iteration #3
Best Reward: 0.0352112676056322
Completed Iteration #4
Best Reward: 0.0352112676056322
Completed Iteration #5
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0704225352112644 7
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 19
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 40
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 53
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 64
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 85
Completed Iteration #6
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0704225352112644 8
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 20
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 41
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 54
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 65
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 86
Completed Iteration #7
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0704225352112644 9
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 21
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 42
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 55
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 66
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 87
Completed Iteration #8
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0704225352112644 10
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 22
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 43
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 56
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 67
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 88
Completed Iteration #9
Best Reward: 0.0352112676056322
Completed Iteration #10
Best Reward: 0.0352112676056322
Completed Iteration #11
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8794a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056633c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.0704225352112644 11
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.176056338028161 23
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7394366197182762 44
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9507042253520694 57
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0211267605633338 68
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.056338028168966 89
Completed Iteration #12
Best Reward: 0.0352112676056322
Completed Iteration #13
Best Reward: 0.0352112676056322
Completed Iteration #14
Best Reward: 0.0352112676056322
Completed Iteration #15
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe805649978> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.1056338028168966 12
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.2112676056337932 24
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.7746478873239084 45
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.9859154929577016 58
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.056338028168966 69
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.0915492957745982 90
Completed Iteration #16
Best Reward: 0.0352112676056322
Completed Iteration #17
Best Reward: 0.0352112676056322
Completed Iteration #18
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.1408450704225288 13
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.2464788732394254 25
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.8098591549295406 46
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.0211267605633338 59
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.0915492957745982 70
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.1267605633802305 91
Completed Iteration #19
Best Reward: 0.0352112676056322
Completed Iteration #20
Best Reward: 0.0352112676056322
Completed Iteration #21
Best Reward: 0.0352112676056322
Completed Iteration #22
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8978> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4e80> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.176056338028161 14
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.2816901408450576 26
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.8450704225351728 47
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.056338028168966 60
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.1267605633802305 71
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.1619718309858627 92
Completed Iteration #23
Best Reward: 0.0352112676056322
Completed Iteration #24
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838642f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575ca90> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.176056338028161 15
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.2816901408450576 27
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.8450704225351728 48
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.056338028168966 61
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.1267605633802305 72
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.1619718309858627 93
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #5
root->7->10->0->1->8
Best Reward: 0.0352112676056322
Completed Iteration #0
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcf60> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4e80> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.1056338028168966 4
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.2112676056337932 16
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.3169014084506898 28
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.880281690140805 49
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.0915492957745982 62
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.1619718309858627 73
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.1971830985914949 94
Completed Iteration #1
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.1056338028168966 5
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.2112676056337932 17
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.3169014084506898 29
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.880281690140805 50
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.0915492957745982 63
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.1619718309858627 74
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.1971830985914949 95
Completed Iteration #2
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc470> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.1408450704225288 6
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.2464788732394254 18
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.352112676056322 30
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.9154929577464372 51
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.1267605633802305 64
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.1971830985914949 75
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.232394366197127 96
Completed Iteration #3
Best Reward: 0.0352112676056322
Completed Iteration #4
Best Reward: 0.0352112676056322
Completed Iteration #5
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.1408450704225288 7
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.2464788732394254 19
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.352112676056322 31
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.9154929577464372 52
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.1267605633802305 65
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.1971830985914949 76
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.232394366197127 97
Completed Iteration #6
Best Reward: 0.0352112676056322
Completed Iteration #7
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8041182b0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.176056338028161 8
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.2816901408450576 20
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.3873239436619542 32
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.9507042253520694 53
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.1619718309858627 66
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.232394366197127 77
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.2676056338027593 98
Completed Iteration #8
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe804131470> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.1056338028168966 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.2112676056337932 9
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.3169014084506898 21
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.4225352112675864 33
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.9859154929577016 54
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.1971830985914949 67
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.2676056338027593 78
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.3028169014083915 99
Completed Iteration #9
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.2112676056337932 10
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.3169014084506898 22
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.4225352112675864 34
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.9859154929577016 55
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.1971830985914949 68
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.2676056338027593 79
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.3028169014083915 100
Completed Iteration #10
Best Reward: 0.0352112676056322
Completed Iteration #11
Best Reward: 0.0352112676056322
Completed Iteration #12
Best Reward: 0.0352112676056322
Completed Iteration #13
Best Reward: 0.0352112676056322
Completed Iteration #14
Best Reward: 0.0352112676056322
Completed Iteration #15
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcb00> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8d68> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.2464788732394254 11
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.352112676056322 23
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.4577464788732186 35
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.0211267605633338 56
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.232394366197127 69
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.3028169014083915 80
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.3380281690140237 101
Completed Iteration #16
Best Reward: 0.0352112676056322
Completed Iteration #17
Best Reward: 0.0352112676056322
Completed Iteration #18
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.2464788732394254 12
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.352112676056322 24
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.4577464788732186 36
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.0211267605633338 57
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.232394366197127 70
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.3028169014083915 81
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.3380281690140237 102
Completed Iteration #19
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041139e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.2464788732394254 13
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.352112676056322 25
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.4577464788732186 37
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.0211267605633338 58
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.232394366197127 71
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.3028169014083915 82
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.3380281690140237 103
Completed Iteration #20
Best Reward: 0.0352112676056322
Completed Iteration #21
Best Reward: 0.0352112676056322
Completed Iteration #22
Best Reward: 0.0352112676056322
Completed Iteration #23
Best Reward: 0.0352112676056322
Completed Iteration #24
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8d68> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.2464788732394254 14
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.352112676056322 26
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.4577464788732186 38
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.0211267605633338 59
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.232394366197127 72
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.3028169014083915 83
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.3380281690140237 104
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #6
root->7->10->0->1->8->1
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8041315c0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.1408450704225288 5
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.2816901408450576 15
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.3873239436619542 27
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.4929577464788508 39
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.056338028168966 60
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.2676056338027593 73
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.3380281690140237 84
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.3732394366196559 105
Completed Iteration #0
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.176056338028161 6
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.3169014084506898 16
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.4225352112675864 28
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.528169014084483 40
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.0915492957745982 61
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.3028169014083915 74
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.3732394366196559 85
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.408450704225288 106
Completed Iteration #1
Best Reward: 0.0352112676056322
Completed Iteration #2
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.176056338028161 7
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.3169014084506898 17
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.4225352112675864 29
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.528169014084483 41
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.0915492957745982 62
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.3028169014083915 75
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.3732394366196559 86
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.408450704225288 107
Completed Iteration #3
Best Reward: 0.0352112676056322
Completed Iteration #4
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcc50> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.2112676056337932 8
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.352112676056322 18
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.4577464788732186 30
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.5633802816901152 42
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.1267605633802305 63
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.3380281690140237 76
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.408450704225288 87
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.4436619718309203 108
Completed Iteration #5
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc6a0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.2464788732394254 9
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.3873239436619542 19
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.4929577464788508 31
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.5985915492957474 43
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.1619718309858627 64
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.3732394366196559 77
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.4436619718309203 88
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.4788732394365525 109
Completed Iteration #6
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe838185160> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.2816901408450576 10
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.4225352112675864 20
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.528169014084483 32
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.6338028169013796 44
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.1971830985914949 65
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.408450704225288 78
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.4788732394365525 89
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.5140845070421847 110
Completed Iteration #7
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.2816901408450576 11
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.4225352112675864 21
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.528169014084483 33
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.6338028169013796 45
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.1971830985914949 66
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.408450704225288 79
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.4788732394365525 90
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.5140845070421847 111
Completed Iteration #8
Best Reward: 0.0352112676056322
Completed Iteration #9
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.2816901408450576 12
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.4225352112675864 22
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.528169014084483 34
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.6338028169013796 46
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.1971830985914949 67
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.408450704225288 80
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.4788732394365525 91
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.5140845070421847 112
Completed Iteration #10
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315c0> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.2816901408450576 13
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.4225352112675864 23
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.528169014084483 35
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.6338028169013796 47
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.1971830985914949 68
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.408450704225288 81
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.4788732394365525 92
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.5140845070421847 113
Completed Iteration #11
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe804131978> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.3169014084506898 14
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.4577464788732186 24
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.5633802816901152 36
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.6690140845070118 48
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.232394366197127 69
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.4436619718309203 82
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.5140845070421847 93
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.5492957746478169 114
Completed Iteration #12
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe804118390> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5898> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcc50> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.352112676056322 15
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.4929577464788508 25
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.5985915492957474 37
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.704225352112644 49
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.2676056338027593 70
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.4788732394365525 83
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.5492957746478169 94
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.584507042253449 115
Completed Iteration #13
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc6a0> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.352112676056322 16
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.4929577464788508 26
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.5985915492957474 38
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.704225352112644 50
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.2676056338027593 71
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.4788732394365525 84
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.5492957746478169 95
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.584507042253449 116
Completed Iteration #14
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcc50> 0.0704225352112644 4
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.352112676056322 17
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.4929577464788508 27
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.5985915492957474 39
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.704225352112644 51
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.2676056338027593 72
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.4788732394365525 85
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.5492957746478169 96
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.584507042253449 117
Completed Iteration #15
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc6a0> 0.0352112676056322 4
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.352112676056322 18
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.4929577464788508 28
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.5985915492957474 40
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.704225352112644 52
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.2676056338027593 73
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.4788732394365525 86
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.5492957746478169 97
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.584507042253449 118
Completed Iteration #16
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c88> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.3873239436619542 19
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.528169014084483 29
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.6338028169013796 41
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.7394366197182762 53
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.3028169014083915 74
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.5140845070421847 87
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.584507042253449 98
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.6197183098590813 119
Completed Iteration #17
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8e48> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.4225352112675864 20
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.5633802816901152 30
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.6690140845070118 42
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.7746478873239084 54
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.3380281690140237 75
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.5492957746478169 88
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.6197183098590813 99
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.6549295774647135 120
Completed Iteration #18
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80568be80> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410be80> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131470> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.4577464788732186 21
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.5985915492957474 31
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.704225352112644 43
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.8098591549295406 55
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.3732394366196559 76
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.584507042253449 89
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.6549295774647135 100
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.6901408450703457 121
Completed Iteration #19
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe804131780> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.4929577464788508 22
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.6338028169013796 32
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.7394366197182762 44
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.8450704225351728 56
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.408450704225288 77
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.6197183098590813 90
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.6901408450703457 101
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.7253521126759779 122
Completed Iteration #20
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185160> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.4929577464788508 23
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.6338028169013796 33
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.7394366197182762 45
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.8450704225351728 57
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.408450704225288 78
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.6197183098590813 91
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.6901408450703457 102
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.7253521126759779 123
Completed Iteration #21
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc438> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc0b8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.528169014084483 24
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.6690140845070118 34
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.7746478873239084 46
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.880281690140805 58
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.4436619718309203 79
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.6549295774647135 92
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.7253521126759779 103
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.76056338028161 124
Completed Iteration #22
Best Reward: 0.0352112676056322
Completed Iteration #23
Best Reward: 0.0352112676056322
Completed Iteration #24
Best Reward: 0.0352112676056322
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #7
root->7->10->0->1->8->1->0
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.0704225352112644 4
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.528169014084483 25
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.6690140845070118 35
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.7746478873239084 47
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.880281690140805 59
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.4436619718309203 80
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.6549295774647135 93
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.7253521126759779 104
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.76056338028161 125
Completed Iteration #0
Best Reward: 0.0352112676056322
Completed Iteration #1
Best Reward: 0.0352112676056322
Completed Iteration #2
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc0b8> 0.0352112676056322 3
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.0704225352112644 5
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.528169014084483 26
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.6690140845070118 36
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.7746478873239084 48
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.880281690140805 60
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.4436619718309203 81
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.6549295774647135 94
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.7253521126759779 105
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.76056338028161 126
Completed Iteration #3
Best Reward: 0.0352112676056322
Completed Iteration #4
Best Reward: 0.0352112676056322
Completed Iteration #5
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab00> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc0b8> 0.0704225352112644 4
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.1056338028168966 6
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.5633802816901152 27
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.704225352112644 37
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.8098591549295406 49
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.9154929577464372 61
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.4788732394365525 82
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.6901408450703457 95
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.76056338028161 106
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.7957746478872423 127
Completed Iteration #6
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8057295c0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc5f8> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.1408450704225288 7
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.5985915492957474 28
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.7394366197182762 38
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.8450704225351728 50
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.9507042253520694 62
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.5140845070421847 83
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.7253521126759779 96
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.7957746478872423 107
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.8309859154928745 128
Completed Iteration #7
Best Reward: 0.0352112676056322
Completed Iteration #8
Best Reward: 0.0352112676056322
Completed Iteration #9
Best Reward: 0.0352112676056322
Completed Iteration #10
Best Reward: 0.0352112676056322
Completed Iteration #11
Best Reward: 0.0352112676056322
Completed Iteration #12
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7e48> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.176056338028161 8
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.6338028169013796 29
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.7746478873239084 39
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.880281690140805 51
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 0.9859154929577016 63
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.5492957746478169 84
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.76056338028161 97
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.8309859154928745 108
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.8661971830985067 129
Completed Iteration #13
Best Reward: 0.0352112676056322
Reward: 0.0352112676056322
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc240> 0.0352112676056322 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0704225352112644 3
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.2112676056337932 9
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.6690140845070118 30
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.8098591549295406 40
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.9154929577464372 52
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 1.0211267605633338 64
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.584507042253449 85
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.7957746478872423 98
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.8661971830985067 109
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.9014084507041389 130
Completed Iteration #14
Best Reward: 0.0352112676056322
Completed Iteration #15
Best Reward: 0.0352112676056322
Completed Iteration #16
Best Reward: 0.0352112676056322
Completed Iteration #17
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.2112676056337932 10
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.6690140845070118 31
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.8098591549295406 41
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.9154929577464372 53
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 1.0211267605633338 65
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.584507042253449 86
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.7957746478872423 99
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.8661971830985067 110
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.9014084507041389 131
Completed Iteration #18
Best Reward: 0.0352112676056322
coverage_call_count 500
Completed Iteration #19
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc0b8> 0.0704225352112644 5
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.2112676056337932 11
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.6690140845070118 32
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.8098591549295406 42
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.9154929577464372 54
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 1.0211267605633338 66
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.584507042253449 87
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.7957746478872423 100
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.8661971830985067 111
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.9014084507041389 132
Completed Iteration #20
Best Reward: 0.0352112676056322
Completed Iteration #21
Best Reward: 0.0352112676056322
Completed Iteration #22
Best Reward: 0.0352112676056322
Completed Iteration #23
Best Reward: 0.0352112676056322
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663978> 0.2112676056337932 12
backprop <src.mcts.MCTS_Node object at 0x7fe804113080> 0.6690140845070118 33
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.8098591549295406 43
backprop <src.mcts.MCTS_Node object at 0x7fe804118c88> 0.9154929577464372 55
backprop <src.mcts.MCTS_Node object at 0x7fe804118630> 1.0211267605633338 67
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 1.584507042253449 88
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 1.7957746478872423 101
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 1.8661971830985067 112
backprop <src.mcts.MCTS_Node object at 0x7fe80568be48> 1.9014084507041389 133
Completed Iteration #24
Best Reward: 0.0352112676056322
Completed Iteration #25
Best Reward: 0.0352112676056322
Completed MCTS Level/Depth: #8
root->7->10->0->1->8->1->0->5
Best Reward: 0.0352112676056322
iteration: 4
found coverage increase 0.0352112676056322
Current Total Coverage 11.86619718309859
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 4
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 5
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 6
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 7
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 8
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 9
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 10
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 11
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057299e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 12
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838185208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 13
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 14
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 15
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 16
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 17
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 18
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 19
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 20
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 21
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 22
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 23
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 24
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 25
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 26
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 27
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 28
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 29
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 30
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 31
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 32
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057299e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 33
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838185128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 34
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 35
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 24
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 36
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.03521126760563398 25
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.03521126760563398 37
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805777080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.07042253521126796 26
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.07042253521126796 38
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.10563380281690193 27
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.10563380281690193 39
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.10563380281690193 28
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.10563380281690193 40
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057299b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.10563380281690193 29
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.10563380281690193 41
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057080f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.10563380281690193 30
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.10563380281690193 42
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.10563380281690193 31
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.10563380281690193 43
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.10563380281690193 32
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.10563380281690193 44
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.10563380281690193 33
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.10563380281690193 45
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #2
root->2->18
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805781828> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.1408450704225359 15
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.1408450704225359 34
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.1408450704225359 46
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057816d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.1760563380281699 16
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.1760563380281699 35
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.1760563380281699 47
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5908> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.21126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.21126760563380387 36
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.21126760563380387 48
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.21126760563380387 37
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.21126760563380387 49
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830658f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.1760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.21126760563380387 19
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.21126760563380387 38
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.21126760563380387 50
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe80575c470> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729f98> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.21126760563380387 9
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.24647887323943785 20
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.24647887323943785 39
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.24647887323943785 51
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057506d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.24647887323943785 10
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.2816901408450718 21
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.2816901408450718 40
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.2816901408450718 52
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805781160> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.2816901408450718 11
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.3169014084507058 22
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.3169014084507058 41
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.3169014084507058 53
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac7b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acac8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781160> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.3169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.3521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.3521126760563398 42
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.3521126760563398 54
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.3521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.38732394366197376 24
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.38732394366197376 43
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.38732394366197376 55
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #3
root->2->18->6
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
coverage_call_count 600
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.3521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.38732394366197376 25
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.38732394366197376 44
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.38732394366197376 56
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.3521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.38732394366197376 26
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.38732394366197376 45
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.38732394366197376 57
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.38732394366197376 27
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.38732394366197376 46
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.38732394366197376 58
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.3521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.38732394366197376 28
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.38732394366197376 47
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.38732394366197376 59
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.3521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.38732394366197376 29
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.38732394366197376 48
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.38732394366197376 60
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.38732394366197376 19
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.42253521126760774 30
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.42253521126760774 49
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.42253521126760774 61
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe805781e80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057817f0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.42253521126760774 20
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4577464788732417 31
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4577464788732417 50
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4577464788732417 62
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.42253521126760774 21
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4577464788732417 32
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4577464788732417 51
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4577464788732417 63
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.42253521126760774 22
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4577464788732417 33
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4577464788732417 52
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4577464788732417 64
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.42253521126760774 23
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4577464788732417 34
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4577464788732417 53
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4577464788732417 65
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #4
root->2->18->6->0
Best Reward: 0.03521126760563398
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.42253521126760774 24
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4577464788732417 35
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4577464788732417 54
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4577464788732417 66
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1408450704225359 15
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.42253521126760774 25
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4577464788732417 36
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4577464788732417 55
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4577464788732417 67
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1408450704225359 16
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.42253521126760774 26
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4577464788732417 37
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4577464788732417 56
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4577464788732417 68
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1408450704225359 17
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.42253521126760774 27
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4577464788732417 38
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4577464788732417 57
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4577464788732417 69
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 18
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 28
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 39
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 58
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 70
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce048> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 19
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 29
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 40
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 59
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 71
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 20
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 30
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 41
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 60
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 72
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 21
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 31
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 42
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 61
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 73
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 22
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 32
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 43
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 62
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 74
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 12
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 23
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 33
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 44
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 63
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 75
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 13
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 24
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 34
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 45
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 64
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 76
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #5
root->2->18->6->0->1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 14
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 25
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 35
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 46
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 65
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 77
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 15
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 26
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 36
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 47
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 66
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 78
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 16
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 27
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 37
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 48
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 67
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 79
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 17
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 28
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 38
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 49
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 68
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 80
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.03521126760563398 7
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.07042253521126796 18
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.1760563380281699 29
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4577464788732417 39
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.4929577464788757 50
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.4929577464788757 69
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.4929577464788757 81
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8386652b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674f28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.10563380281690193 19
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.21126760563380387 30
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4929577464788757 40
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.5281690140845097 51
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.5281690140845097 70
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.5281690140845097 82
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.10563380281690193 20
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.21126760563380387 31
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4929577464788757 41
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.5281690140845097 52
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.5281690140845097 71
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.5281690140845097 83
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.10563380281690193 21
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.21126760563380387 32
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4929577464788757 42
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.5281690140845097 53
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.5281690140845097 72
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.5281690140845097 84
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.07042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.10563380281690193 22
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.21126760563380387 33
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.4929577464788757 43
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.5281690140845097 54
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.5281690140845097 73
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.5281690140845097 85
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce898> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.1408450704225359 23
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.24647887323943785 34
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.5281690140845097 44
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.5633802816901436 55
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.5633802816901436 74
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.5633802816901436 86
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.1408450704225359 24
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.24647887323943785 35
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.5281690140845097 45
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.5633802816901436 56
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.5633802816901436 75
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.5633802816901436 87
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe830674a58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.1760563380281699 25
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.2816901408450718 36
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.5633802816901436 46
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.5985915492957776 57
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.5985915492957776 76
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.5985915492957776 88
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #6
root->2->18->6->0->1->12
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe830667048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.21126760563380387 26
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.3169014084507058 37
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.5985915492957776 47
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.6338028169014116 58
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.6338028169014116 77
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.6338028169014116 89
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8386659b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.24647887323943785 27
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.3521126760563398 38
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.6338028169014116 48
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.6690140845070456 59
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.6690140845070456 78
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.6690140845070456 90
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe838665b38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665898> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a58> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.24647887323943785 17
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.2816901408450718 28
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.38732394366197376 39
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.6690140845070456 49
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.7042253521126796 60
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.7042253521126796 79
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.7042253521126796 91
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8701729e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.21126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.2816901408450718 18
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.3169014084507058 29
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.42253521126760774 40
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.7042253521126796 50
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.7394366197183135 61
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.7394366197183135 80
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.7394366197183135 92
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.24647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.3169014084507058 19
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.3521126760563398 30
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.4577464788732417 41
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.7394366197183135 51
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.7746478873239475 62
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.7746478873239475 81
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.7746478873239475 93
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386659b0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.24647887323943785 9
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.3169014084507058 20
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.3521126760563398 31
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.4577464788732417 42
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.7394366197183135 52
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.7746478873239475 63
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.7746478873239475 82
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.7746478873239475 94
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a58> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.24647887323943785 10
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.3169014084507058 21
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.3521126760563398 32
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.4577464788732417 43
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.7394366197183135 53
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.7746478873239475 64
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.7746478873239475 83
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.7746478873239475 95
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe870172a58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.2816901408450718 11
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.3521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.38732394366197376 33
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.4929577464788757 44
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.7746478873239475 54
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.8098591549295815 65
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.8098591549295815 84
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.8098591549295815 96
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665898> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674a58> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.2816901408450718 12
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.3521126760563398 23
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.38732394366197376 34
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.4929577464788757 45
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.7746478873239475 55
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.8098591549295815 66
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.8098591549295815 85
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.8098591549295815 97
Completed Iteration #16
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8306746d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.3169014084507058 13
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.38732394366197376 24
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.42253521126760774 35
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5281690140845097 46
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8098591549295815 56
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.8450704225352155 67
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.8450704225352155 86
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.8450704225352155 98
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.3521126760563398 14
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.42253521126760774 25
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4577464788732417 36
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5633802816901436 47
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8450704225352155 57
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.8802816901408494 68
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.8802816901408494 87
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.8802816901408494 99
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe870172a58> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.3521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.42253521126760774 26
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4577464788732417 37
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5633802816901436 48
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8450704225352155 58
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.8802816901408494 69
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.8802816901408494 88
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.8802816901408494 100
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386659b0> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.42253521126760774 27
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4577464788732417 38
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5633802816901436 49
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8450704225352155 59
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.8802816901408494 70
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.8802816901408494 89
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.8802816901408494 101
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #7
root->2->18->6->0->1->12->6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7860> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.3521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.42253521126760774 28
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4577464788732417 39
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5633802816901436 50
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8450704225352155 60
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.8802816901408494 71
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.8802816901408494 90
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.8802816901408494 102
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe8306679e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781208> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7860> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.38732394366197376 18
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.4577464788732417 29
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4929577464788757 40
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5985915492957776 51
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8802816901408494 61
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.9154929577464834 72
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.9154929577464834 91
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.9154929577464834 103
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7860> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.38732394366197376 19
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.4577464788732417 30
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4929577464788757 41
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5985915492957776 52
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8802816901408494 62
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.9154929577464834 73
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.9154929577464834 92
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.9154929577464834 104
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
coverage_call_count 700
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7860> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.38732394366197376 20
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.4577464788732417 31
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4929577464788757 42
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5985915492957776 53
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8802816901408494 63
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.9154929577464834 74
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.9154929577464834 93
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.9154929577464834 105
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Completed Iteration #12
Best Reward: 0.03521126760563398
Completed Iteration #13
Best Reward: 0.03521126760563398
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7860> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.38732394366197376 21
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.4577464788732417 32
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4929577464788757 43
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5985915492957776 54
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8802816901408494 64
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.9154929577464834 75
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.9154929577464834 94
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.9154929577464834 106
Completed Iteration #20
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8701726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7860> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.38732394366197376 22
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.4577464788732417 33
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4929577464788757 44
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5985915492957776 55
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8802816901408494 65
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.9154929577464834 76
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.9154929577464834 95
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.9154929577464834 107
Completed Iteration #21
Best Reward: 0.03521126760563398
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7860> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.38732394366197376 23
backprop <src.mcts.MCTS_Node object at 0x7fe8057de0b8> 0.4577464788732417 34
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6358> 0.4929577464788757 45
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.5985915492957776 56
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.8802816901408494 66
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.9154929577464834 77
backprop <src.mcts.MCTS_Node object at 0x7fe80410bfd0> 0.9154929577464834 96
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.9154929577464834 108
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #8
root->2->18->6->0->1->12->6->1
Best Reward: 0.03521126760563398
iteration: 5
found coverage increase 0.03521126760563398
Current Total Coverage 11.901408450704224
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0458d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0630b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0630b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 11.901408450704224
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f4e0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.03521126760563398 6
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.03521126760563398 7
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f978> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.07042253521126796 8
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1408450704225359 9
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1408450704225359 10
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1408450704225359 11
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1408450704225359 12
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05ba20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1760563380281699 13
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05ba20> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1760563380281699 14
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1760563380281699 15
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05ba20> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1760563380281699 16
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #0
root
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1760563380281699 17
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.1760563380281699 18
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bf60> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 19
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 20
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 21
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 22
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 23
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 24
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 25
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 26
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 27
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.10563380281690193 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.21126760563380387 28
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027e80> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.1408450704225359 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.24647887323943785 29
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.1408450704225359 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.24647887323943785 30
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.1408450704225359 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.24647887323943785 31
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06779b0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027828> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.1760563380281699 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.2816901408450718 32
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.1760563380281699 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.2816901408450718 33
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677470> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06770b8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bf60> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 34
Completed Iteration #23
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 35
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 36
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 37
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
coverage_call_count 800
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 38
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 39
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c06774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 40
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 41
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 42
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 43
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 44
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.07042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.24647887323943785 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.3521126760563398 45
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe8057810b8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.3169014084507058 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.42253521126760774 46
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.3169014084507058 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.42253521126760774 47
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05be10> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.21126760563380387 14
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.38732394366197376 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.4929577464788757 48
Completed Iteration #23
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.38732394366197376 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.4929577464788757 49
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.38732394366197376 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.4929577464788757 50
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #2
root->0->12
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b6a0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.21126760563380387 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.2816901408450718 17
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.4577464788732417 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.5633802816901436 51
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7c068be48> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.24647887323943785 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.3169014084507058 18
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.4929577464788757 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.5985915492957776 52
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.24647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.3169014084507058 19
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.4929577464788757 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.5985915492957776 53
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b6a0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.24647887323943785 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.3169014084507058 20
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.4929577464788757 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.5985915492957776 54
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.3169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.38732394366197376 21
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.5633802816901436 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.6690140845070456 55
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.3169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.38732394366197376 22
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.5633802816901436 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.6690140845070456 56
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057810b8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.3169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.38732394366197376 23
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.5633802816901436 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.6690140845070456 57
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.3169014084507058 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.38732394366197376 24
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.5633802816901436 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.6690140845070456 58
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0451d0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b780> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b6a0> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.38732394366197376 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.4577464788732417 25
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.6338028169014116 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.7394366197183135 59
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b550> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.4577464788732417 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.5281690140845097 26
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.7042253521126796 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.8098591549295815 60
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #3
root->0->12->6
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.4577464788732417 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.5281690140845097 27
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.7042253521126796 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.8098591549295815 61
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.4929577464788757 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.5633802816901436 28
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.7394366197183135 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.8450704225352155 62
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb00> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.4929577464788757 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.5633802816901436 29
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.7394366197183135 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.8450704225352155 63
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e390> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068be80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.5281690140845097 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.5985915492957776 30
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.7746478873239475 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.8802816901408494 64
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb00> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.5281690140845097 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.5985915492957776 31
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.7746478873239475 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.8802816901408494 65
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e3c8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb00> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.1760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.5633802816901436 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.6338028169014116 32
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.8098591549295815 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.9154929577464834 66
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.1760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.5633802816901436 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.6338028169014116 33
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.8098591549295815 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.9154929577464834 67
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068be80> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.5633802816901436 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.6338028169014116 34
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.8098591549295815 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.9154929577464834 68
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.5633802816901436 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.6338028169014116 35
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.8098591549295815 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.9154929577464834 69
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.5633802816901436 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.6338028169014116 36
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.8098591549295815 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.9154929577464834 70
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ecc0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.24647887323943785 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.6338028169014116 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.7042253521126796 37
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.8802816901408494 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.9859154929577514 71
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #4
root->0->12->6->1
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.24647887323943785 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.6338028169014116 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.7042253521126796 38
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.8802816901408494 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.9859154929577514 72
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.6338028169014116 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.7042253521126796 39
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.8802816901408494 61
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.9859154929577514 73
Completed Iteration #3
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.24647887323943785 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.6338028169014116 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.7042253521126796 40
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.8802816901408494 62
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.9859154929577514 74
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b278> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.3169014084507058 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.7042253521126796 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.7746478873239475 41
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.9507042253521174 63
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.0563380281690193 75
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bb00> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bc18> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e978> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.1760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.3521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.7394366197183135 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.8098591549295815 42
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.9859154929577514 64
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.0915492957746533 76
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e630> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.21126760563380387 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.38732394366197376 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.7746478873239475 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.8450704225352155 43
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.0211267605633854 65
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.1267605633802873 77
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.21126760563380387 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.38732394366197376 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.7746478873239475 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.8450704225352155 44
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.0211267605633854 66
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.1267605633802873 78
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.38732394366197376 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.7746478873239475 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.8450704225352155 45
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.0211267605633854 67
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.1267605633802873 79
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.38732394366197376 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.7746478873239475 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.8450704225352155 46
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.0211267605633854 68
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.1267605633802873 80
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.38732394366197376 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.7746478873239475 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.8450704225352155 47
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.0211267605633854 69
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.1267605633802873 81
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.21126760563380387 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.38732394366197376 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.7746478873239475 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.8450704225352155 48
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.0211267605633854 70
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.1267605633802873 82
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.2816901408450718 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.4577464788732417 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.8450704225352155 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.9154929577464834 49
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.0915492957746533 71
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.1971830985915553 83
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063c18> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5281690140845097 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9154929577464834 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 0.9859154929577514 50
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.1619718309859213 72
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.2676056338028232 84
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bf28> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 51
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 73
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 85
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #5
root->0->12->6->1->8
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 52
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 74
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 86
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 53
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 75
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 87
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 54
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 76
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 88
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 55
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 77
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 89
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 56
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 78
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 90
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 23
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 57
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 79
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 91
Completed Iteration #8
Best Reward: 0.07042253521126796
coverage_call_count 900
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 24
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 58
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 80
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 92
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 25
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 59
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 81
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 93
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 26
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 60
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 82
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 94
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 27
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 61
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 83
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 95
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.07042253521126796 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.42253521126760774 28
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.5985915492957776 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 0.9859154929577514 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.0563380281690193 62
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.2323943661971892 84
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.3380281690140912 96
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 29
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 63
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 85
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 97
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 30
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 64
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 86
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 98
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 31
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 65
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 87
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 99
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 32
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 66
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 88
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 100
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 33
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 67
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 89
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 101
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #6
root->0->12->6->1->8->0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.07042253521126796 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 34
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 68
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 90
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 102
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.07042253521126796 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 35
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 69
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 91
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 103
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.07042253521126796 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 36
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 70
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 92
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 104
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.07042253521126796 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 37
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 71
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 93
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 105
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.07042253521126796 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.1408450704225359 23
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.4929577464788757 38
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.6690140845070456 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.0563380281690193 61
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1267605633802873 72
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3028169014084572 94
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.4084507042253591 106
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da160> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.21126760563380387 24
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.5633802816901436 39
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.7394366197183135 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.1267605633802873 62
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.1971830985915553 73
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.3732394366197251 95
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.478873239436627 107
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.1760563380281699 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.24647887323943785 25
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.5985915492957776 40
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.7746478873239475 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.1619718309859213 63
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.2323943661971892 74
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.4084507042253591 96
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.514084507042261 108
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #7
root->0->12->6->1->8->0->8
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.1760563380281699 13
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.24647887323943785 26
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.5985915492957776 41
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.7746478873239475 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.1619718309859213 64
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.2323943661971892 75
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.4084507042253591 97
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.514084507042261 109
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.1760563380281699 14
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.24647887323943785 27
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.5985915492957776 42
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.7746478873239475 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.1619718309859213 65
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.2323943661971892 76
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.4084507042253591 98
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.514084507042261 110
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.1760563380281699 15
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.24647887323943785 28
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.5985915492957776 43
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.7746478873239475 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.1619718309859213 66
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.2323943661971892 77
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.4084507042253591 99
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.514084507042261 111
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7c064be48> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.24647887323943785 16
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.3169014084507058 29
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.6690140845070456 44
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.8450704225352155 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.2323943661971892 67
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.3028169014084572 78
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.478873239436627 100
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.584507042253529 112
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.24647887323943785 17
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.3169014084507058 30
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.6690140845070456 45
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.8450704225352155 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.2323943661971892 68
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.3028169014084572 79
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.478873239436627 101
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.584507042253529 113
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d358> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.3169014084507058 18
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.7394366197183135 46
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.9154929577464834 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.3028169014084572 69
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.3732394366197251 80
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.549295774647895 102
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.654929577464797 114
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d8d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.24647887323943785 9
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.3521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.42253521126760774 32
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.7746478873239475 47
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.9507042253521174 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.3380281690140912 70
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.4084507042253591 81
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.584507042253529 103
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.690140845070431 115
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.24647887323943785 10
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.3521126760563398 20
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.42253521126760774 33
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.7746478873239475 48
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.9507042253521174 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.3380281690140912 71
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.4084507042253591 82
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.584507042253529 104
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.690140845070431 116
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.24647887323943785 11
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.3521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.42253521126760774 34
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.7746478873239475 49
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.9507042253521174 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.3380281690140912 72
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.4084507042253591 83
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.584507042253529 105
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.690140845070431 117
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.24647887323943785 12
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.3521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c88> 0.42253521126760774 35
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.7746478873239475 50
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.9507042253521174 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b0b8> 1.3380281690140912 73
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06feb8> 1.4084507042253591 84
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 1.584507042253529 106
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 1.690140845070431 118
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #8
root->0->12->6->1->8->0->8->0
Best Reward: 0.07042253521126796
iteration: 7
found coverage increase 0.07042253521126796
Current Total Coverage 11.971830985915492
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77de48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 11.971830985915492
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7471d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747b00> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea20> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.035211267605635754 9
Completed Iteration #9
Best Reward: 0.035211267605635754
coverage_call_count 1000
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747d30> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.07042253521127151 10
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7479b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.07042253521127151 11
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea20> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.07042253521127151 12
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea20> 0.035211267605635754 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.07042253521127151 13
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77da20> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.10563380281690726 14
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.10563380281690726 15
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.10563380281690726 16
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.10563380281690726 17
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.10563380281690726 18
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.10563380281690726 19
Completed Iteration #21
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751320> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea20> 0.07042253521127151 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.14084507042254302 20
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7518d0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747940> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.17605633802817877 21
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #0
root
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.07042253521127151 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.17605633802817877 22
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7513c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.07042253521127151 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.17605633802817877 23
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.07042253521127151 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.17605633802817877 24
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f470> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.10563380281690726 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.21126760563381453 25
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77da20> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.10563380281690726 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.21126760563381453 26
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.10563380281690726 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.21126760563381453 27
Completed Iteration #5
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.10563380281690726 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.21126760563381453 28
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fb00> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.14084507042254302 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.24647887323945028 29
Completed Iteration #7
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.14084507042254302 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.24647887323945028 30
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.14084507042254302 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.24647887323945028 31
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.14084507042254302 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.24647887323945028 32
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.17605633802817877 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.28169014084508603 33
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.17605633802817877 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.28169014084508603 34
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.17605633802817877 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.28169014084508603 35
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bf98> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.21126760563381453 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.3169014084507218 36
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.21126760563381453 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.3169014084507218 37
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777588> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.24647887323945028 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.35211267605635754 38
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0710> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751d30> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.28169014084508603 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.3873239436619933 39
Completed Iteration #21
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.28169014084508603 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.3873239436619933 40
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7513c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.28169014084508603 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.3873239436619933 41
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.28169014084508603 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.3873239436619933 42
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #1
root->0
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f4a8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.3169014084507218 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.42253521126762905 43
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.14084507042254302 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.35211267605635754 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.4577464788732648 44
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.14084507042254302 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.35211267605635754 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.4577464788732648 45
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.14084507042254302 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.35211267605635754 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.4577464788732648 46
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.14084507042254302 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.35211267605635754 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.4577464788732648 47
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.14084507042254302 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.35211267605635754 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.4577464788732648 48
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.14084507042254302 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.35211267605635754 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.4577464788732648 49
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.14084507042254302 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.35211267605635754 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.4577464788732648 50
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713240> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713048> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.17605633802817877 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.3873239436619933 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.49295774647890056 51
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713198> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777cc0> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.21126760563381453 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.42253521126762905 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.5281690140845363 52
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.035211267605635754 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.21126760563381453 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.42253521126762905 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.5281690140845363 53
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713d30> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f978> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.24647887323945028 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.4577464788732648 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.5633802816901721 54
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777630> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.28169014084508603 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.49295774647890056 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.5985915492958078 55
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #2
root->0->17
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b860> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.14084507042254302 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.3169014084507218 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.5281690140845363 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.6338028169014436 56
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7470f0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.17605633802817877 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.35211267605635754 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.5633802816901721 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.6690140845070793 57
Completed Iteration #3
Best Reward: 0.035211267605635754
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713780> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.21126760563381453 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.3873239436619933 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.5985915492958078 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.7042253521127151 58
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f4a8> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.21126760563381453 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.3873239436619933 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.5985915492958078 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.7042253521127151 59
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777630> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.21126760563381453 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.3873239436619933 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.5985915492958078 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.7042253521127151 60
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bc50> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.24647887323945028 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.42253521126762905 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.6338028169014436 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.7394366197183508 61
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751b38> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f160> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.28169014084508603 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.4577464788732648 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.6690140845070793 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.7746478873239866 62
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.3169014084507218 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.49295774647890056 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.7042253521127151 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.8098591549296223 63
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720ef0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720e10> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f4a8> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.35211267605635754 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.5281690140845363 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.7394366197183508 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.8450704225352581 64
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd278> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.3873239436619933 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.5633802816901721 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.7746478873239866 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.8802816901408939 65
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bc50> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.3873239436619933 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.5633802816901721 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.7746478873239866 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.8802816901408939 66
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #3
root->0->17->0
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.3873239436619933 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.5633802816901721 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.7746478873239866 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.8802816901408939 67
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.07042253521127151 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.3873239436619933 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.5633802816901721 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.7746478873239866 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.8802816901408939 68
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c63c8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f160> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.10563380281690726 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.42253521126762905 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.5985915492958078 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.8098591549296223 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.9154929577465296 69
Completed Iteration #3
Best Reward: 0.035211267605635754
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.10563380281690726 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.42253521126762905 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.5985915492958078 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.8098591549296223 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.9154929577465296 70
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.10563380281690726 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.42253521126762905 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.5985915492958078 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.8098591549296223 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.9154929577465296 71
Completed Iteration #10
Best Reward: 0.035211267605635754
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.10563380281690726 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.42253521126762905 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.5985915492958078 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.8098591549296223 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.9154929577465296 72
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7134e0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797ba8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.14084507042254302 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.4577464788732648 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.6338028169014436 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.8450704225352581 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.9507042253521654 73
Completed Iteration #12
Best Reward: 0.035211267605635754
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.14084507042254302 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.4577464788732648 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.6338028169014436 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.8450704225352581 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.9507042253521654 74
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f160> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.14084507042254302 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.4577464788732648 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.6338028169014436 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.8450704225352581 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.9507042253521654 75
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6278> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f160> 0.10563380281690726 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.17605633802817877 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.49295774647890056 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.6690140845070793 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.8802816901408939 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 0.9859154929578011 76
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.21126760563381453 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.5281690140845363 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.7042253521127151 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.9154929577465296 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.0211267605634369 77
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751b38> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f160> 0.10563380281690726 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.21126760563381453 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.5281690140845363 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.7042253521127151 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.9154929577465296 61
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.0211267605634369 78
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.21126760563381453 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.5281690140845363 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.7042253521127151 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.9154929577465296 62
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.0211267605634369 79
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #4
root->0->17->0->12
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d85c0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.24647887323945028 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.5633802816901721 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.7394366197183508 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.9507042253521654 63
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.0563380281690726 80
Completed Iteration #0
Best Reward: 0.035211267605635754
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d89b0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.28169014084508603 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.5985915492958078 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.7746478873239866 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.9859154929578011 64
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.0915492957747084 81
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.10563380281690726 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.28169014084508603 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.5985915492958078 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.7746478873239866 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.9859154929578011 65
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.0915492957747084 82
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720860> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.14084507042254302 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.3169014084507218 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.6338028169014436 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.8098591549296223 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.0211267605634369 66
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.1267605633803441 83
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d89b0> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.14084507042254302 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.3169014084507218 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.6338028169014436 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.8098591549296223 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.0211267605634369 67
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.1267605633803441 84
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.17605633802817877 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.35211267605635754 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.6690140845070793 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.8450704225352581 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.0563380281690726 68
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.16197183098598 85
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.17605633802817877 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.35211267605635754 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.6690140845070793 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.8450704225352581 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.0563380281690726 69
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.16197183098598 86
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00b8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e48> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.07042253521127151 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.21126760563381453 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.3873239436619933 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.7042253521127151 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.8802816901408939 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.0915492957747084 70
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.1971830985916156 87
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f04e0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.24647887323945028 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.42253521126762905 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.7394366197183508 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.9154929577465296 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.1267605633803441 71
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.2323943661972514 88
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0940> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.28169014084508603 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.4577464788732648 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.7746478873239866 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.9507042253521654 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.16197183098598 72
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.2676056338028872 89
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #5
root->0->17->0->12->0
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.28169014084508603 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.4577464788732648 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.7746478873239866 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.9507042253521654 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.16197183098598 73
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.2676056338028872 90
Completed Iteration #0
Best Reward: 0.035211267605635754
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.28169014084508603 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.4577464788732648 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.7746478873239866 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.9507042253521654 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.16197183098598 74
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.2676056338028872 91
Completed Iteration #2
Best Reward: 0.035211267605635754
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.035211267605635754 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.28169014084508603 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.4577464788732648 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.7746478873239866 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.9507042253521654 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.16197183098598 75
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.2676056338028872 92
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777438> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777eb8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.07042253521127151 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.3169014084507218 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.49295774647890056 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.8098591549296223 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.9859154929578011 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.1971830985916156 76
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.302816901408523 93
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777438> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777eb8> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.07042253521127151 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.3169014084507218 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.49295774647890056 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.8098591549296223 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.9859154929578011 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.1971830985916156 77
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.302816901408523 94
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.07042253521127151 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.3169014084507218 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.49295774647890056 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.8098591549296223 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.9859154929578011 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.1971830985916156 78
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.302816901408523 95
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.07042253521127151 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.3169014084507218 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.49295774647890056 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.8098591549296223 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.9859154929578011 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.1971830985916156 79
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.302816901408523 96
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8c50> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777eb8> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.10563380281690726 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.35211267605635754 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.5281690140845363 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.8450704225352581 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.0211267605634369 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.2323943661972514 80
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.3380281690141587 97
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.10563380281690726 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.35211267605635754 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.5281690140845363 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.8450704225352581 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.0211267605634369 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.2323943661972514 81
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.3380281690141587 98
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777eb8> 0.07042253521127151 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.10563380281690726 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.35211267605635754 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.5281690140845363 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.8450704225352581 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.0211267605634369 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.2323943661972514 82
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.3380281690141587 99
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6954e0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6955f8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.14084507042254302 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.3873239436619933 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.5633802816901721 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.8802816901408939 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.0563380281690726 61
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.2676056338028872 83
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.3732394366197944 100
Completed Iteration #21
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695a90> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.17605633802817877 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.42253521126762905 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.5985915492958078 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.9154929577465296 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.0915492957747084 62
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.302816901408523 84
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.4084507042254302 101
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #6
root->0->17->0->12->0->10
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.21126760563381453 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.4577464788732648 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.6338028169014436 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.9507042253521654 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.1267605633803441 63
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.3380281690141587 85
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.443661971831066 102
Completed Iteration #0
Best Reward: 0.035211267605635754
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cfd0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.24647887323945028 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.49295774647890056 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.6690140845070793 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.9859154929578011 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.16197183098598 64
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.3732394366197944 86
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.4788732394367017 103
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cac8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.14084507042254302 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.28169014084508603 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.5281690140845363 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.7042253521127151 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.0211267605634369 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.1971830985916156 65
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.4084507042254302 87
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.5140845070423374 104
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c160> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.17605633802817877 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.3169014084507218 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.5633802816901721 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.7394366197183508 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.0563380281690726 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.2323943661972514 66
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.443661971831066 88
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.5492957746479732 105
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695208> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.21126760563381453 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.35211267605635754 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.5985915492958078 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.7746478873239866 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.0915492957747084 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.2676056338028872 67
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.4788732394367017 89
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.584507042253609 106
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695ef0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695ba8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695a90> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.24647887323945028 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.3873239436619933 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.6338028169014436 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.8098591549296223 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.1267605633803441 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.302816901408523 68
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.5140845070423374 90
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.6197183098592447 107
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695a90> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.24647887323945028 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.3873239436619933 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.6338028169014436 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.8098591549296223 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.1267605633803441 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.302816901408523 69
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.5140845070423374 91
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.6197183098592447 108
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cac8> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.24647887323945028 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.3873239436619933 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.6338028169014436 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.8098591549296223 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.1267605633803441 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.302816901408523 70
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.5140845070423374 92
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.6197183098592447 109
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d358> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d128> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.28169014084508603 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.42253521126762905 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.6690140845070793 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.8450704225352581 47
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.16197183098598 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.3380281690141587 71
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.5492957746479732 93
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.6549295774648805 110
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #7
root->0->17->0->12->0->10->0
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8278> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.3169014084507218 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.4577464788732648 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7042253521127151 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.8802816901408939 48
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.1971830985916156 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.3732394366197944 72
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.584507042253609 94
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.6901408450705162 111
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.10563380281690726 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.3169014084507218 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.4577464788732648 25
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7042253521127151 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.8802816901408939 49
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.1971830985916156 61
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.3732394366197944 73
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.584507042253609 95
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.6901408450705162 112
Completed Iteration #3
Best Reward: 0.035211267605635754
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.10563380281690726 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.3169014084507218 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.4577464788732648 26
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7042253521127151 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.8802816901408939 50
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.1971830985916156 62
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.3732394366197944 74
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.584507042253609 96
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.6901408450705162 113
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cd30> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.14084507042254302 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.35211267605635754 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.49295774647890056 27
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7394366197183508 37
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.9154929577465296 51
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.2323943661972514 63
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.4084507042254302 75
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.6197183098592447 97
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.725352112676152 114
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.14084507042254302 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.35211267605635754 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.49295774647890056 28
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7394366197183508 38
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.9154929577465296 52
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.2323943661972514 64
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.4084507042254302 76
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.6197183098592447 98
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.725352112676152 115
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.14084507042254302 9
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.35211267605635754 17
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.49295774647890056 29
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7394366197183508 39
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.9154929577465296 53
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.2323943661972514 65
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.4084507042254302 77
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.6197183098592447 99
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.725352112676152 116
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d978> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d518> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.17605633802817877 10
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.3873239436619933 18
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.5281690140845363 30
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7746478873239866 40
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.9507042253521654 54
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.2676056338028872 66
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.443661971831066 78
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.6549295774648805 100
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.7605633802817877 117
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.07042253521127151 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.17605633802817877 11
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.3873239436619933 19
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.5281690140845363 31
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7746478873239866 41
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.9507042253521654 55
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.2676056338028872 67
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.443661971831066 79
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.6549295774648805 101
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.7605633802817877 118
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.07042253521127151 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.17605633802817877 12
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.3873239436619933 20
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.5281690140845363 32
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7746478873239866 42
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.9507042253521654 56
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.2676056338028872 68
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.443661971831066 80
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.6549295774648805 102
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.7605633802817877 119
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.07042253521127151 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.17605633802817877 13
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.3873239436619933 21
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.5281690140845363 33
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7746478873239866 43
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.9507042253521654 57
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.2676056338028872 69
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.443661971831066 81
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.6549295774648805 103
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.7605633802817877 120
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.17605633802817877 14
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.3873239436619933 22
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.5281690140845363 34
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.7746478873239866 44
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.9507042253521654 58
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.2676056338028872 70
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.443661971831066 82
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.6549295774648805 104
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.7605633802817877 121
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d84e0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695cf8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.21126760563381453 15
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.42253521126762905 23
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.5633802816901721 35
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.8098591549296223 45
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 0.9859154929578011 59
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.302816901408523 71
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.4788732394367017 83
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.6901408450705162 105
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.7957746478874235 122
Completed Iteration #18
Best Reward: 0.035211267605635754
coverage_call_count 1200
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae828> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d128> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0c18> 0.24647887323945028 16
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0fd0> 0.4577464788732648 24
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d88d0> 0.5985915492958078 36
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.8450704225352581 46
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ffd0> 1.0211267605634369 60
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 1.3380281690141587 72
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 1.5140845070423374 84
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 1.725352112676152 106
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797fd0> 1.8309859154930592 123
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #8
root->0->17->0->12->0->10->0->21
Best Reward: 0.035211267605635754
iteration: 9
found coverage increase 0.035211267605635754
Current Total Coverage 12.007042253521128
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6512e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 1300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1934e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1934e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b54a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1465c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 1400
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1932b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1932b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1465c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1464e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1204e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7204e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7132b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7132e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7132e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 22
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7207b8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7479b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7479b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7515f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7515f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7479b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7515f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7134e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 4
Completed Iteration #5
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7135f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7135f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7135f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797320> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7472e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7472e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777710> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d080> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7972b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b3c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 13
Completed Iteration #20
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c06772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7514a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06779e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0630b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c06770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0630b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c06777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 10
Completed Iteration #16
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8701727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8701726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0455f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8701726a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0455f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0455f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386654e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8701726a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe870172668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe870172668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306742b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe870172a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306742b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe870172a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cec88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057accf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cec88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830658e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f66a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f66a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830658e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5208> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306672b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f69e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057aca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c06774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0450b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe83818cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0450b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838185128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0450b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306744e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041312e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041312e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041316a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c06777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041316a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041316a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041310f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8794421d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838185080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386a2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bb38> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041183c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041183c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041183c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe830667630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041185c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570acf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80570a550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057087b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80575c160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057776d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 2400
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057776d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057296a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057de710> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057777f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057def60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057dedd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056becf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057506d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057506d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056bee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057501d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057506d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 3
Completed Iteration #4
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056491d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056491d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6669b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1935c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe87942ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838185128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838642fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838185208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838642fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06777b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06777b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06777b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0454e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06778d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0272b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f320> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0459b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8794c6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c06771d0> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838185198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381852e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570aa58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7204a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe87942ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe870172908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830658fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410b358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe870172908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe870172908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bb38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0459e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7974e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797dd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77def0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1200b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1200b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1203c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f62e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120b70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056bec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713128> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713128> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6667b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805777048> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6663c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057774e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838642f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057774e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838642f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057774e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057774e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057774e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f03c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8386a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057aca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6516a0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7135f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041319e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830658f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041310b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804131d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe830674a90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057decf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057decf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057decf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea58> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0518> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057292b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ceb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1634a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe805729710> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056494e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ceb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1639e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80568b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057cea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3c88> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146898> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057292b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d69b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c1d0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c1d0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b97f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955691d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b97b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b97b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955698d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 17
Completed Iteration #18
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955698d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955215f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554cd30> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955275c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795521cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955210f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521278> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d66a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d66a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 10
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955273c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 3900
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea390> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eabe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954eabe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955210b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955210b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955210b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955219e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaeb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954563c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 4000
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954653c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954655f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954565f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954653c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c860> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954560f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954560f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954316a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954316a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd65c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd65c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431be0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd65c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795431be0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794decac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794decf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794deccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d834a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd69e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd69e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6160> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794decf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794decf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794decd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794decc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794db3668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8307d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 22
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3668> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe794db3b00> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794deccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794decc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794decc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da78d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da78d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aed30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe80570a748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80570a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056496d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805781c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805649128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805663278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805781940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c062e1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306742e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830674cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a5c0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79555a4e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041182b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041182b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041182b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da78d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804118b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804118278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057081d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386656d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac695978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386656d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe804113470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386656d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8386656d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306743c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306743c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795521b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79555a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306675c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dec358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056be080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8056be588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac75f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6bdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830667ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306674e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306674e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7516a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0455f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795521400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe870172780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805663748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838665198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac713748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794da7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1200f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057f6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1200f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe87942ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1ebef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe87942ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe838185128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7daa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7517f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe838185048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bf28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8381fcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804113390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8040c75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c066b0f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80568bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8306676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe804131c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac777358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec045978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805708208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe830674e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80410bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7974e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795521710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76b4a8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6664a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc01eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8c97d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1632e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1632e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c06770f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac10d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac163668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056b4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c063eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac751b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac797a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec0639b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0272b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dec7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7dc0274e0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057776a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80410b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a34a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057776a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057776a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80570a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6515f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c860> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8056d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8040c7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8056d70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac120048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6c6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794da74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac720668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 4800
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec063630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac76bcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe830667ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805777160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac666710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8041315f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac7f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954561d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe795456198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c0677d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955f6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe8057cecc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954562e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954562e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d833c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954562e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec05b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954565c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c068b1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6514e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac63da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954562e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954a73c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d833c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954565c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146588> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac77df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805708908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805777860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a32e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795489550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac6d8438> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954650f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954650f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954650b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795569f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954650b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465710> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c062edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac193e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7dc027be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac67c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8306674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c064b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ec06fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac747b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79555a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954897b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79558a4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d83198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954f6cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955692b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955690f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954659b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805649470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955690f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954657b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955690f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac146908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8041181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7c069ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc01d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7c069e1d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795489550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955279b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955279b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79558a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955279b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe80575cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575c710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795527898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 5100
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057de240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795527908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac1460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79547c198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954316a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795431828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bc88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795456f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7954316d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac651320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7438> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe8057def28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955276a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955276a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794db33c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955d6fd0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7946317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7946310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794db39b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7946315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7946317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7946316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946317b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe794631e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc86d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc86d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954eadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631e10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955270b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8f98> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d496a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d83668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13bda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d496a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d496a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795431f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe795527b70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe7946310f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795527f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fc50> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805750780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe795465470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79547c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554ce80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794631390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe7955e7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79554ce80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe79554c6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805729748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe80575ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 15
Completed Iteration #22
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a128> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff170b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe805729748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59128> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dd6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d49b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794db3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff179b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe805750d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb668> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feccb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed94a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feccb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feeec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feccb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff9ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feee908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78feeecf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795569940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795527668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7955e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff174e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff174e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d49668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78feeeba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fea96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea96a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea96a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feafba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feafdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe492b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feafc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaff60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe8057dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7954657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794631b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffc8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff175c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe79547c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feeec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea97f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794d496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff6ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feafcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feccdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffdbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fed96a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe163c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 18
Completed Iteration #16
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d492e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 22
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 23
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe794d492e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe163c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08550> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fecc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff8f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2db70> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe7ac13b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795489128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe794dc0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff59c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe795465e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2da20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe79554ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78feaf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff7dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78feafcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ffb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2da20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78ff594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fed9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe16ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2da20> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08160> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 12.007042253521128
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 2
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 3
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe2d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78f9ef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe08320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fea95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fea9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78f9ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78f9ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78f9ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78f9ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78f9ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe5f588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78f9ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78ff17da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78fe3cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe78f9efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe78f9ef358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe78fe49c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 12.007042253521128
initial coverage: 11.7254
time passed (minutes): 60.0732
iterations: 188
number of new inputs: 320
final coverage: 12.007
total coverage increase: 0.28169
