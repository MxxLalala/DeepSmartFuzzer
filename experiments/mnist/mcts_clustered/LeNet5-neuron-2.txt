Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'neuron'], random_seed=2, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7f720b8c1f28>, tc2=<function tc2 at 0x7f720b8d2048>, tc3=<function tc3 at 0x7f720b8d2158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 66.7939
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71941bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e978> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7414a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 66.79389312977099
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7676a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c767da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.3816793893129784 9
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.3816793893129784 10
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767da0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.3816793893129784 11
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7677b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.3816793893129784 12
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7676a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.3816793893129784 13
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.3816793893129784 14
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.3816793893129784 15
Completed Iteration #19
Best Reward: 0.3816793893129784
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.3816793893129784 16
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.3816793893129784 17
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c70f5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7039b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767da0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.7633587786259568 18
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7675f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.7633587786259568 19
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.7633587786259568 20
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.7633587786259568 8
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.7633587786259568 21
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.7633587786259568 9
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.7633587786259568 22
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.7633587786259568 10
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 0.7633587786259568 23
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7039b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767da0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.1450381679389352 11
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.1450381679389352 24
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.1450381679389352 12
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.1450381679389352 25
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.1450381679389352 13
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.1450381679389352 26
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.1450381679389352 14
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.1450381679389352 27
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.1450381679389352 15
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.1450381679389352 28
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.1450381679389352 16
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.1450381679389352 29
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.1450381679389352 17
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.1450381679389352 30
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.1450381679389352 18
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.1450381679389352 31
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.5267175572519136 19
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.5267175572519136 32
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.5267175572519136 20
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.5267175572519136 33
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0eb8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7039b0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c767da0> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.5267175572519136 21
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.5267175572519136 34
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c703400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767da0> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 1.908396946564892 22
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 1.908396946564892 35
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 2.2900763358778704 23
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 2.2900763358778704 36
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 2.2900763358778704 24
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 2.2900763358778704 37
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703400> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703470> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767da0> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 2.2900763358778704 25
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 2.2900763358778704 38
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 2.671755725190849 26
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 2.671755725190849 39
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.053435114503827 27
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.053435114503827 40
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.053435114503827 28
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.053435114503827 41
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.053435114503827 29
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.053435114503827 42
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c70fc18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.4351145038168056 30
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.4351145038168056 43
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.908396946564892 10
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.4351145038168056 31
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.4351145038168056 44
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.908396946564892 11
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.4351145038168056 32
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.4351145038168056 45
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.908396946564892 12
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.4351145038168056 33
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.4351145038168056 46
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.908396946564892 13
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.4351145038168056 34
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.4351145038168056 47
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.908396946564892 14
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.4351145038168056 35
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.4351145038168056 48
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.908396946564892 15
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.4351145038168056 36
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.4351145038168056 49
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 1.908396946564892 16
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.4351145038168056 37
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.4351145038168056 50
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c70fba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 2.2900763358778704 17
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.816793893129784 38
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.816793893129784 51
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 2.2900763358778704 18
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.816793893129784 39
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.816793893129784 52
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 2.2900763358778704 19
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.816793893129784 40
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.816793893129784 53
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4a8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 2.2900763358778704 20
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.816793893129784 41
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.816793893129784 54
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 2.2900763358778704 13
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 2.2900763358778704 21
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 3.816793893129784 42
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 3.816793893129784 55
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4a8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 2.671755725190849 22
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 4.198473282442762 43
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 4.198473282442762 56
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c72cba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703e80> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 3.053435114503827 23
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 4.580152671755741 44
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 4.580152671755741 57
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 3.053435114503827 24
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 4.580152671755741 45
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 4.580152671755741 58
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->2->0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 3.053435114503827 17
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 3.053435114503827 25
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 4.580152671755741 46
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 4.580152671755741 59
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 3.053435114503827 18
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 3.053435114503827 26
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 4.580152671755741 47
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 4.580152671755741 60
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 3.4351145038168056 19
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 3.4351145038168056 27
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 4.961832061068719 48
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 4.961832061068719 61
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 3.4351145038168056 20
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 3.4351145038168056 28
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 4.961832061068719 49
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 4.961832061068719 62
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 3.4351145038168056 21
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 3.4351145038168056 29
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 4.961832061068719 50
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 4.961832061068719 63
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7672b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7828> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 3.816793893129784 22
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 3.816793893129784 30
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 5.343511450381698 51
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 5.343511450381698 64
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 3.816793893129784 23
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 3.816793893129784 31
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 5.343511450381698 52
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 5.343511450381698 65
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c72cef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4a8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.198473282442762 24
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.198473282442762 32
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 5.725190839694676 53
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 5.725190839694676 66
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.198473282442762 25
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.198473282442762 33
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 5.725190839694676 54
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 5.725190839694676 67
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7978> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703e80> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.580152671755741 26
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.580152671755741 34
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 6.106870229007654 55
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 6.106870229007654 68
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.580152671755741 27
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.580152671755741 35
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 6.106870229007654 56
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 6.106870229007654 69
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.580152671755741 28
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.580152671755741 36
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 6.106870229007654 57
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 6.106870229007654 70
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c438> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4a8> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.580152671755741 29
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.580152671755741 37
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 6.106870229007654 58
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 6.106870229007654 71
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.580152671755741 30
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.580152671755741 38
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 6.106870229007654 59
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 6.106870229007654 72
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->2->0->2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbb70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703e80> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.961832061068719 31
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.961832061068719 39
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 6.488549618320633 60
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 6.488549618320633 73
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fba8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7828> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.961832061068719 32
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.961832061068719 40
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 6.488549618320633 61
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 6.488549618320633 74
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7672b0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7828> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 4.961832061068719 33
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 4.961832061068719 41
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 6.488549618320633 62
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 6.488549618320633 75
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 5.343511450381698 34
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 5.343511450381698 42
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 6.870229007633611 63
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 6.870229007633611 76
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c79eb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb358> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7978> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c703e80> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 5.725190839694676 35
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 5.725190839694676 43
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 7.25190839694659 64
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 7.25190839694659 77
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7828> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 6.106870229007654 36
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 6.106870229007654 44
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 7.633587786259568 65
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 7.633587786259568 78
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72cba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703e80> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 6.488549618320633 37
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 6.488549618320633 45
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 8.015267175572546 66
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 8.015267175572546 79
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbb00> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c72cba8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c703e80> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 6.488549618320633 38
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 6.488549618320633 46
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 8.015267175572546 67
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 8.015267175572546 80
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703e80> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 6.488549618320633 39
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 6.488549618320633 47
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 8.015267175572546 68
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 8.015267175572546 81
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb6d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 6.870229007633611 40
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 6.870229007633611 48
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 8.396946564885525 69
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 8.396946564885525 82
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c741438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 7.25190839694659 41
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 7.25190839694659 49
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 8.778625954198503 70
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 8.778625954198503 83
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 7.633587786259568 42
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 7.633587786259568 50
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 9.160305343511482 71
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 9.160305343511482 84
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
coverage_call_count 200
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c67f748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fba8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7828> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 8.015267175572546 51
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 9.54198473282446 72
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 9.54198473282446 85
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7672b0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7828> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 7.25190839694659 24
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 8.396946564885525 44
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 8.396946564885525 52
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 9.923664122137438 73
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 9.923664122137438 86
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->2->0->2->19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70ff60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741438> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 7.633587786259568 25
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 8.778625954198503 45
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 8.778625954198503 53
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 10.305343511450417 74
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 10.305343511450417 87
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb6d8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 8.015267175572546 26
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 9.160305343511482 46
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 9.160305343511482 54
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 10.687022900763395 75
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 10.687022900763395 88
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 9.54198473282446 47
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 9.54198473282446 55
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 11.068702290076374 76
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 11.068702290076374 89
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c703ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70ff60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741438> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 8.778625954198503 28
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 9.923664122137438 48
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 9.923664122137438 56
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 11.450381679389352 77
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 11.450381679389352 90
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 8.778625954198503 29
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 9.923664122137438 49
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 9.923664122137438 57
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 11.450381679389352 78
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 11.450381679389352 91
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c67fda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fb38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6668> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb6d8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 9.160305343511482 30
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 10.305343511450417 50
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 10.305343511450417 58
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 11.83206106870233 79
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 11.83206106870233 92
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 9.160305343511482 31
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 10.305343511450417 51
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 10.305343511450417 59
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 11.83206106870233 80
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 11.83206106870233 93
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c68a748> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb6d8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 9.54198473282446 32
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 10.687022900763395 52
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 10.687022900763395 60
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 12.213740458015309 81
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 12.213740458015309 94
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c68aba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 9.923664122137438 33
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 11.068702290076374 53
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 11.068702290076374 61
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 12.595419847328287 82
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 12.595419847328287 95
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c68ac18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a7f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2438> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb6d8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 10.305343511450417 34
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 11.450381679389352 54
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 11.450381679389352 62
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 12.977099236641266 83
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 12.977099236641266 96
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6925c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68aba8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 10.687022900763395 35
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 11.83206106870233 55
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 11.83206106870233 63
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 13.358778625954244 84
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 13.358778625954244 97
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c72c400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 11.068702290076374 36
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 12.213740458015309 56
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 12.213740458015309 64
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 13.740458015267222 85
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 13.740458015267222 98
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7417b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692048> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c68aba8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 11.450381679389352 37
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 12.595419847328287 57
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 12.595419847328287 65
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 14.1221374045802 86
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 14.1221374045802 99
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c67f898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb2b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 11.83206106870233 38
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 12.977099236641266 58
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 12.977099236641266 66
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 14.50381679389318 87
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 14.50381679389318 100
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2dd8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 7.25190839694659 23
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 11.83206106870233 39
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 12.977099236641266 59
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 12.977099236641266 67
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 14.50381679389318 88
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 14.50381679389318 101
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->2->0->2->19->5
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6d60f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 7.633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 12.213740458015309 40
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 13.358778625954244 60
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 13.358778625954244 68
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 14.885496183206158 89
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 14.885496183206158 102
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c692dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 8.015267175572546 25
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 12.595419847328287 41
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 13.740458015267222 61
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 13.740458015267222 69
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 15.267175572519136 90
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 15.267175572519136 103
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c692780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a80f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c400> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 8.396946564885525 26
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 12.977099236641266 42
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 14.1221374045802 62
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 14.1221374045802 70
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 15.648854961832114 91
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 15.648854961832114 104
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c68aa58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 8.778625954198503 27
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 13.358778625954244 43
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 14.50381679389318 63
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 14.50381679389318 71
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 16.030534351145093 92
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 16.030534351145093 105
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 9.160305343511482 28
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 13.740458015267222 44
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 14.885496183206158 64
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 14.885496183206158 72
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 16.41221374045807 93
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 16.41221374045807 106
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c741d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 9.54198473282446 29
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 14.1221374045802 45
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 15.267175572519136 65
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 15.267175572519136 73
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 16.79389312977105 94
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 16.79389312977105 107
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e28d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 14.50381679389318 46
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 15.648854961832114 66
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 15.648854961832114 74
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 17.175572519084028 95
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 17.175572519084028 108
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c67f4a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 14.885496183206158 47
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 16.030534351145093 67
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 16.030534351145093 75
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 17.557251908397006 96
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 17.557251908397006 109
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e22b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692dd8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 10.687022900763395 32
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 15.267175572519136 48
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 16.41221374045807 68
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 16.41221374045807 76
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 17.938931297709985 97
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 17.938931297709985 110
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c68a5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 11.068702290076374 33
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 15.648854961832114 49
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 16.79389312977105 69
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 16.79389312977105 77
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 18.320610687022963 98
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 18.320610687022963 111
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68aa58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 11.450381679389352 34
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 16.030534351145093 50
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 17.175572519084028 70
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 17.175572519084028 78
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 18.70229007633594 99
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 18.70229007633594 112
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c63f4a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8f28> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8ac8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c68aa58> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 11.83206106870233 35
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 16.41221374045807 51
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 17.557251908397006 71
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 17.557251908397006 79
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 19.08396946564892 100
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 19.08396946564892 113
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->2->0->2->19->5->2
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c63ff60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 16.79389312977105 52
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 17.938931297709985 72
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 17.938931297709985 80
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 19.4656488549619 101
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 19.4656488549619 114
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c64a710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 12.595419847328287 37
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 17.175572519084028 53
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 18.320610687022963 73
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 18.320610687022963 81
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 19.847328244274877 102
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 19.847328244274877 115
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fc18> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 12.977099236641266 38
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 17.557251908397006 54
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 18.70229007633594 74
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 18.70229007633594 82
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 20.229007633587855 103
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 20.229007633587855 116
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c63f160> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 13.358778625954244 39
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 17.938931297709985 55
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 19.08396946564892 75
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 19.08396946564892 83
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 20.610687022900834 104
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 20.610687022900834 117
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c67fc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 13.740458015267222 40
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 18.320610687022963 56
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 19.4656488549619 76
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 19.4656488549619 84
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 20.992366412213812 105
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 20.992366412213812 118
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c63fa58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fbe0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d60f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 14.1221374045802 41
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 18.70229007633594 57
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 19.847328244274877 77
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 19.847328244274877 85
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 21.37404580152679 106
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 21.37404580152679 119
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 14.50381679389318 42
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 19.08396946564892 58
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 20.229007633587855 78
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 20.229007633587855 86
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 21.75572519083977 107
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 21.75572519083977 120
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c68aa20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aeb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7c18> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 14.885496183206158 43
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 19.4656488549619 59
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 20.610687022900834 79
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 20.610687022900834 87
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 22.137404580152747 108
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 22.137404580152747 121
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c665828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 15.267175572519136 44
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 19.847328244274877 60
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 20.992366412213812 80
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 20.992366412213812 88
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 22.519083969465726 109
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 22.519083969465726 122
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->2->0->2->19->5->2->3
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c665e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 15.648854961832114 45
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 20.229007633587855 61
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 21.37404580152679 81
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 21.37404580152679 89
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 22.900763358778704 110
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 22.900763358778704 123
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6652e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6657f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e28d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 16.030534351145093 46
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 20.610687022900834 62
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 21.75572519083977 82
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 21.75572519083977 90
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 23.282442748091682 111
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 23.282442748091682 124
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c64ad68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ab00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665e10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 16.41221374045807 47
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 20.992366412213812 63
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 22.137404580152747 83
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 22.137404580152747 91
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 23.66412213740466 112
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 23.66412213740466 125
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c63fba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f3c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665e10> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 11.068702290076374 30
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 16.79389312977105 48
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 21.37404580152679 64
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 22.519083969465726 84
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 22.519083969465726 92
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 24.04580152671764 113
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 24.04580152671764 126
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 8.778625954198503 25
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 11.068702290076374 31
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 16.79389312977105 49
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 21.37404580152679 65
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 22.519083969465726 85
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 22.519083969465726 93
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 24.04580152671764 114
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 24.04580152671764 127
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e22e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 9.160305343511482 26
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 11.450381679389352 32
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 17.175572519084028 50
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 21.75572519083977 66
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 22.900763358778704 86
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 22.900763358778704 94
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 24.427480916030618 115
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 24.427480916030618 128
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741d68> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 9.54198473282446 27
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 11.83206106870233 33
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 17.557251908397006 51
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 22.137404580152747 67
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 23.282442748091682 87
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 23.282442748091682 95
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 24.809160305343596 116
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 24.809160305343596 129
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c671780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 9.923664122137438 28
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 12.213740458015309 34
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 17.938931297709985 52
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 22.519083969465726 68
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 23.66412213740466 88
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 23.66412213740466 96
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 25.190839694656574 117
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 25.190839694656574 130
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e22e8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8128> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 9.923664122137438 29
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 12.213740458015309 35
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 17.938931297709985 53
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 22.519083969465726 69
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 23.66412213740466 89
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 23.66412213740466 97
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 25.190839694656574 118
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 25.190839694656574 131
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 12.213740458015309 36
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 17.938931297709985 54
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 22.519083969465726 70
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 23.66412213740466 90
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 23.66412213740466 98
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 25.190839694656574 119
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 25.190839694656574 132
Completed Iteration #21
Best Reward: 0.3816793893129784
coverage_call_count 300
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a82e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741d68> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a58> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f717c70f048> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7f717c77fef0> 12.595419847328287 37
backprop <src.mcts.MCTS_Node object at 0x7f717c741400> 18.320610687022963 55
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 22.900763358778704 71
backprop <src.mcts.MCTS_Node object at 0x7f717c753cc0> 24.04580152671764 91
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 24.04580152671764 99
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 25.572519083969553 120
backprop <src.mcts.MCTS_Node object at 0x7f717c767588> 25.572519083969553 133
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->2->0->2->19->5->2->3->13
Best Reward: 0.3816793893129784
iteration: 3
found coverage increase 0.3816793893129784
Current Total Coverage 67.17557251908397
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6714e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c671400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6710f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 67.17557251908397
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6656d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6656d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716df8bac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.3816793893129784 24
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.3816793893129784 6
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.3816793893129784 25
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.3816793893129784 7
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.3816793893129784 26
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.3816793893129784 8
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.3816793893129784 27
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.3816793893129784 9
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.3816793893129784 28
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716df997f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 10
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 29
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 11
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 30
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 12
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 31
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 13
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 32
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 14
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 33
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 15
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 34
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71d7bd20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 16
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 35
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 8
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 17
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 36
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 9
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 18
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 37
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 10
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 19
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 38
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 11
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 20
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 39
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 12
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 40
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 13
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 41
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 14
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 23
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 42
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 15
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 24
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 43
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.7633587786259568 16
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 0.7633587786259568 25
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.7633587786259568 44
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7194070080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 1.1450381679389352 17
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 1.1450381679389352 26
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 1.1450381679389352 45
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c64a710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8bac8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 1.5267175572519136 18
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 1.5267175572519136 27
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 1.5267175572519136 46
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 1.908396946564892 19
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 1.908396946564892 28
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 1.908396946564892 47
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6926a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 2.2900763358778704 20
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 2.2900763358778704 29
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 2.2900763358778704 48
Completed Iteration #21
Best Reward: 0.3816793893129784
coverage_call_count 400
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716dfee2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee9b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7194070080> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 2.671755725190849 21
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 2.671755725190849 30
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 2.671755725190849 49
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->4->29
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 2.671755725190849 22
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 2.671755725190849 31
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 2.671755725190849 50
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 2.671755725190849 23
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 2.671755725190849 32
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 2.671755725190849 51
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8bac8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 2.2900763358778704 13
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 2.671755725190849 24
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 2.671755725190849 33
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 2.671755725190849 52
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5be0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df997f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 3.053435114503827 25
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 3.053435114503827 34
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 3.053435114503827 53
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 3.4351145038168056 26
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 3.4351145038168056 35
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 3.4351145038168056 54
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c692908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aac8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8bac8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 3.816793893129784 27
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 3.816793893129784 36
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 3.816793893129784 55
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 3.816793893129784 28
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 3.816793893129784 37
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 3.816793893129784 56
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df992e8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 4.198473282442762 29
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 4.198473282442762 38
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 4.198473282442762 57
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c68ae48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5f28> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c692780> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716df992e8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 4.580152671755741 30
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 4.580152671755741 39
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 4.580152671755741 58
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 4.580152671755741 31
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 4.580152671755741 40
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 4.580152671755741 59
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.580152671755741 21
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 4.961832061068719 32
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 4.961832061068719 41
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 4.961832061068719 60
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.580152671755741 22
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 4.961832061068719 33
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 4.961832061068719 42
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 4.961832061068719 61
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.961832061068719 23
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 5.343511450381698 34
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 5.343511450381698 43
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 5.343511450381698 62
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->4->29->3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 5.343511450381698 35
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 5.343511450381698 44
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 5.343511450381698 63
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c692898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7194070198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.343511450381698 25
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 5.725190839694676 36
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 5.725190839694676 45
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 5.725190839694676 64
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c68a9b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.725190839694676 26
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 6.106870229007654 37
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 6.106870229007654 46
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 6.106870229007654 65
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a588> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.725190839694676 27
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 6.106870229007654 38
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 6.106870229007654 47
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 6.106870229007654 66
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c67fda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 6.106870229007654 28
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 6.488549618320633 39
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 6.488549618320633 48
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 6.488549618320633 67
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 6.488549618320633 29
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 6.870229007633611 40
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 6.870229007633611 49
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 6.870229007633611 68
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 3.053435114503827 11
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 6.870229007633611 30
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 7.25190839694659 41
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 7.25190839694659 50
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 7.25190839694659 69
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->4->29->3->14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c72c710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 7.25190839694659 31
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 7.633587786259568 42
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 7.633587786259568 51
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 7.633587786259568 70
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 7.633587786259568 32
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 8.015267175572546 52
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 8.015267175572546 71
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bba20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 8.015267175572546 33
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 8.396946564885525 44
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 8.396946564885525 53
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 8.396946564885525 72
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 8.396946564885525 34
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 8.778625954198503 45
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 8.778625954198503 54
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 8.778625954198503 73
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 8.396946564885525 35
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 8.778625954198503 46
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 8.778625954198503 55
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 8.778625954198503 74
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c665550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 8.778625954198503 36
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 9.160305343511482 47
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 9.160305343511482 56
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 9.160305343511482 75
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac18> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 8.778625954198503 37
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 9.160305343511482 48
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 9.160305343511482 57
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 9.160305343511482 76
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c72cb70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac18> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 9.160305343511482 38
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 9.54198473282446 49
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 9.54198473282446 58
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 9.54198473282446 77
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c0b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb198> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6bba20> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 9.54198473282446 39
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 9.923664122137438 50
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 9.923664122137438 59
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 9.923664122137438 78
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c710> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 5.725190839694676 21
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 9.54198473282446 40
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 9.923664122137438 51
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 9.923664122137438 60
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 9.923664122137438 79
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac18> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 6.106870229007654 22
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 9.923664122137438 41
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 10.305343511450417 52
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 10.305343511450417 61
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 10.305343511450417 80
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c665630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 6.488549618320633 23
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 10.305343511450417 42
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 10.687022900763395 53
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 10.687022900763395 62
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 10.687022900763395 81
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692f60> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c72c710> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 6.488549618320633 24
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 10.305343511450417 43
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 10.687022900763395 54
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 10.687022900763395 63
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 10.687022900763395 82
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb1d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 6.870229007633611 25
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 10.687022900763395 44
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 11.068702290076374 55
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 11.068702290076374 64
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 11.068702290076374 83
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c67f278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 7.25190839694659 26
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 11.068702290076374 45
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 11.450381679389352 56
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 11.450381679389352 65
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 11.450381679389352 84
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 7.633587786259568 27
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 11.450381679389352 46
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 11.83206106870233 57
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 11.83206106870233 66
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 11.83206106870233 85
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->4->29->3->14->5
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f278> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 8.015267175572546 28
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 11.83206106870233 47
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 12.213740458015309 58
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 12.213740458015309 67
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 12.213740458015309 86
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c665c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692898> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f7194070198> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 8.396946564885525 29
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 12.213740458015309 48
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 12.595419847328287 59
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 12.595419847328287 68
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 12.595419847328287 87
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f278> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 7.25190839694659 24
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 8.778625954198503 30
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 12.595419847328287 49
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 12.977099236641266 60
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 12.977099236641266 69
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 12.977099236641266 88
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 7.633587786259568 25
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 9.160305343511482 31
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 12.977099236641266 50
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 13.358778625954244 61
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 13.358778625954244 70
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 13.358778625954244 89
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7194067ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7194070198> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 8.015267175572546 26
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 9.54198473282446 32
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 13.358778625954244 51
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 13.740458015267222 62
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 13.740458015267222 71
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 13.740458015267222 90
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c64ada0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a8d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 9.923664122137438 33
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 13.740458015267222 52
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 14.1221374045802 63
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 14.1221374045802 72
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 14.1221374045802 91
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c72c550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 8.778625954198503 28
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 10.305343511450417 34
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 14.1221374045802 53
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 14.50381679389318 64
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 14.50381679389318 73
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 14.50381679389318 92
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a8d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 9.160305343511482 29
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 10.687022900763395 35
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 14.50381679389318 54
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 14.885496183206158 65
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 14.885496183206158 74
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 14.885496183206158 93
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c550> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 9.54198473282446 30
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 11.068702290076374 36
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 14.885496183206158 55
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 15.267175572519136 66
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 15.267175572519136 75
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 15.267175572519136 94
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0eb8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c72c550> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 9.923664122137438 31
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 11.450381679389352 37
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 15.267175572519136 56
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 15.648854961832114 67
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 15.648854961832114 76
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 15.648854961832114 95
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7194070198> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 10.305343511450417 32
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 11.83206106870233 38
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 15.648854961832114 57
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 16.030534351145093 68
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 16.030534351145093 77
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 16.030534351145093 96
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7194067dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a8d0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 10.687022900763395 33
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 12.213740458015309 39
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 16.030534351145093 58
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 16.41221374045807 69
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 16.41221374045807 78
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 16.41221374045807 97
Completed Iteration #22
Best Reward: 0.3816793893129784
coverage_call_count 500
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7194067e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a8d0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 11.068702290076374 34
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 12.595419847328287 40
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 16.41221374045807 59
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 16.79389312977105 70
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 16.79389312977105 79
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 16.79389312977105 98
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c741e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0eb8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c72c550> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 11.450381679389352 35
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 12.977099236641266 41
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 16.79389312977105 60
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 17.175572519084028 71
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 17.175572519084028 80
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 17.175572519084028 99
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->4->29->3->14->5->18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7194067358> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 11.83206106870233 36
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 13.358778625954244 42
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 17.175572519084028 61
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 17.557251908397006 72
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 17.557251908397006 81
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 17.557251908397006 100
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0eb8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c72c550> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 12.213740458015309 37
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 13.740458015267222 43
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 17.557251908397006 62
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 17.938931297709985 73
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 17.938931297709985 82
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 17.938931297709985 101
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbc88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 12.595419847328287 38
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 14.1221374045802 44
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 17.938931297709985 63
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 18.320610687022963 74
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 18.320610687022963 83
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 18.320610687022963 102
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7194067c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 12.977099236641266 39
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 14.50381679389318 45
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 18.320610687022963 64
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 18.70229007633594 75
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 18.70229007633594 84
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 18.70229007633594 103
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c665978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0eb8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f717c72c550> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 13.358778625954244 40
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 14.885496183206158 46
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 18.70229007633594 65
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 19.08396946564892 76
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 19.08396946564892 85
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 19.08396946564892 104
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c741550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 13.740458015267222 41
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 15.267175572519136 47
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 19.08396946564892 66
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 19.4656488549619 77
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 19.4656488549619 86
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 19.4656488549619 105
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c753278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 14.1221374045802 42
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 15.648854961832114 48
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 19.4656488549619 67
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 19.847328244274877 78
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 19.847328244274877 87
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 19.847328244274877 106
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c70f780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067c88> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 14.50381679389318 43
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 16.030534351145093 49
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 19.847328244274877 68
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 20.229007633587855 79
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 20.229007633587855 88
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 20.229007633587855 107
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->4->29->3->14->5->18->3
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7c18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0fd0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 6.870229007633611 19
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 14.885496183206158 44
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 16.41221374045807 50
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 20.229007633587855 69
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 20.610687022900834 80
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 20.610687022900834 89
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 20.610687022900834 108
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c767518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 7.25190839694659 20
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 15.267175572519136 45
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 16.79389312977105 51
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 20.610687022900834 70
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 20.992366412213812 81
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 20.992366412213812 90
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 20.992366412213812 109
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c72c5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb588> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67f278> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 7.633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 11.068702290076374 30
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 15.648854961832114 46
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 17.175572519084028 52
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 20.992366412213812 71
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 21.37404580152679 82
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 21.37404580152679 91
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 21.37404580152679 110
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 8.015267175572546 22
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 11.450381679389352 31
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 16.030534351145093 47
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 17.557251908397006 53
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 21.37404580152679 72
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 21.75572519083977 83
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 21.75572519083977 92
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 21.75572519083977 111
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c753978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7828> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0fd0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67fe48> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 8.396946564885525 23
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 11.83206106870233 32
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 16.41221374045807 48
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 17.938931297709985 54
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 21.75572519083977 73
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 22.137404580152747 84
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 22.137404580152747 93
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 22.137404580152747 112
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 8.778625954198503 24
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 12.213740458015309 33
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 16.79389312977105 49
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 18.320610687022963 55
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 22.137404580152747 74
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 22.519083969465726 85
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 22.519083969465726 94
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 22.519083969465726 113
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c767780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e80> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 9.160305343511482 25
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 12.595419847328287 34
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 17.175572519084028 50
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 18.70229007633594 56
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 22.519083969465726 75
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 22.900763358778704 86
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 22.900763358778704 95
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 22.900763358778704 114
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7679e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767780> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e80> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 9.54198473282446 26
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 12.977099236641266 35
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 17.557251908397006 51
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 19.08396946564892 57
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 22.900763358778704 76
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 23.282442748091682 87
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 23.282442748091682 96
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 23.282442748091682 115
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e80> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 9.923664122137438 27
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 13.358778625954244 36
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 17.938931297709985 52
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 19.4656488549619 58
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 23.282442748091682 77
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 23.66412213740466 88
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 23.66412213740466 97
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 23.66412213740466 116
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c6d66a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c6a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7679e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7674a8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767780> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e80> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 6.106870229007654 17
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 10.305343511450417 28
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 13.740458015267222 37
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 18.320610687022963 53
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 19.847328244274877 59
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 23.66412213740466 78
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 24.04580152671764 89
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 24.04580152671764 98
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 24.04580152671764 117
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e80> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f716df8be10> 6.488549618320633 18
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 10.687022900763395 29
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 14.1221374045802 38
backprop <src.mcts.MCTS_Node object at 0x7f717c67f7b8> 18.70229007633594 54
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 20.229007633587855 60
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 24.04580152671764 79
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 24.427480916030618 90
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac88> 24.427480916030618 99
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 24.427480916030618 118
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->4->29->3->14->5->18->3->0
Best Reward: 0.3816793893129784
iteration: 5
found coverage increase 0.3816793893129784
Current Total Coverage 67.55725190839695
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7530f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7676a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7672e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7676a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f719407ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71941bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7032b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7032b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c703ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e5f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f717c79e320> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c63fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7194053160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7194053160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de515f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de619e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0460b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df994a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de61c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de619e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71941bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de613c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de51438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de511d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0466a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0059e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0053c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0053c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0054a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0053c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0056a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0057b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c0056a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0056a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0056a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716c077cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c01f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f716c005e48> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad518> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c49b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c49b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0d64e0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ade48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ade48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ade48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0054e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0054e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1cf8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0683c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0683c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0309e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0309e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc18> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ade10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0add30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd154e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd150b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd156d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd151d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0305f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0305f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0305f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0305f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fccd198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc87080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc870f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd156d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c09f080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc506a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc503c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc506d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc506d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcabd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 8
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 9
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b38> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15898> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc772e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc772e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 67.55725190839695
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2971d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 19
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 20
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 21
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 6
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 22
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0409b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 7
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 23
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 8
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 24
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 9
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 25
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 10
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 26
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 27
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 28
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 29
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 30
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc969e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 31
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 32
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 17
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 33
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 34
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 35
Completed Iteration #24
Best Reward: 0.3816793893129784
coverage_call_count 1400
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.3816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.3816793893129784 36
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fd280f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 0.7633587786259568 21
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.7633587786259568 37
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 1.1450381679389352 22
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 1.1450381679389352 38
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c068710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 1.5267175572519136 23
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 1.5267175572519136 39
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fc87780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd280f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 1.908396946564892 24
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 1.908396946564892 40
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fccd320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 2.2900763358778704 25
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 2.2900763358778704 41
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fd15f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 2.671755725190849 26
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 2.671755725190849 42
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->1->19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ee10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 3.053435114503827 11
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 3.053435114503827 27
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 3.053435114503827 43
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fd28f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 3.4351145038168056 28
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 3.4351145038168056 44
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c01f3c8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 3.816793893129784 29
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 3.816793893129784 45
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c068128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f5f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15f60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 4.198473282442762 30
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 4.198473282442762 46
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd320> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 4.198473282442762 31
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 4.198473282442762 47
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c030780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd28fd0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 4.580152671755741 32
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 4.580152671755741 48
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad9b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f3c8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 4.961832061068719 33
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 4.961832061068719 49
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c030630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0adeb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28f98> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 5.343511450381698 18
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 5.343511450381698 34
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 5.343511450381698 50
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->1->19->4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c09f0b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f7b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068710> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd28fd0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 5.725190839694676 35
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 5.725190839694676 51
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fccd5c0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 5.725190839694676 17
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 6.106870229007654 36
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 6.106870229007654 52
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068710> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd28fd0> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 6.106870229007654 37
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 6.106870229007654 53
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c040470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd5c0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 6.488549618320633 38
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 6.488549618320633 54
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c0adf28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 6.870229007633611 39
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 6.870229007633611 55
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 7.25190839694659 24
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 7.25190839694659 40
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 7.25190839694659 56
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 7.633587786259568 25
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 7.633587786259568 41
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 7.633587786259568 57
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c09f9e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f7b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c068710> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f712fd28fd0> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 7.633587786259568 23
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 8.015267175572546 26
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 8.015267175572546 42
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 8.015267175572546 58
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fd15438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28fd0> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 8.015267175572546 24
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 8.396946564885525 43
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 8.396946564885525 59
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f7b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c068710> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f712fd28fd0> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 8.396946564885525 25
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 8.778625954198503 28
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 8.778625954198503 44
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 8.778625954198503 60
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0adf28> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 8.396946564885525 26
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 8.778625954198503 29
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 8.778625954198503 45
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 8.778625954198503 61
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030128> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f715c068710> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f712fd28fd0> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 8.396946564885525 27
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 8.778625954198503 30
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 8.778625954198503 46
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 8.778625954198503 62
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->1->19->4->17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 4.580152671755741 17
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 8.396946564885525 28
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 8.778625954198503 31
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 8.778625954198503 47
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 8.778625954198503 63
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 8.778625954198503 29
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 9.160305343511482 32
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 9.160305343511482 48
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 9.160305343511482 64
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c09f198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030be0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01fb00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 9.160305343511482 30
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 9.54198473282446 33
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 9.54198473282446 49
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 9.54198473282446 65
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 5.343511450381698 20
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 9.160305343511482 31
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 9.54198473282446 34
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 9.54198473282446 50
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 9.54198473282446 66
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c01fba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 5.725190839694676 21
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 9.54198473282446 32
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 9.923664122137438 35
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 9.923664122137438 51
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 9.923664122137438 67
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c0c44a8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d69e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0adf28> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 6.106870229007654 22
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 9.923664122137438 33
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 10.305343511450417 36
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 10.305343511450417 52
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 10.305343511450417 68
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c01fe10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0adf28> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 6.488549618320633 23
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 10.305343511450417 34
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 10.687022900763395 37
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 10.687022900763395 53
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 10.687022900763395 69
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c005080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6550> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 6.870229007633611 24
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 10.687022900763395 35
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 11.068702290076374 38
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 11.068702290076374 54
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 11.068702290076374 70
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->1->19->4->17->8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c005588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030be0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc50> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c01fb00> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 7.25190839694659 25
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 11.068702290076374 36
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 11.450381679389352 39
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 11.450381679389352 55
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 11.450381679389352 71
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 7.633587786259568 26
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 11.450381679389352 37
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 11.83206106870233 40
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 11.83206106870233 56
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 11.83206106870233 72
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fb00> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 7.633587786259568 27
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 11.450381679389352 38
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 11.83206106870233 41
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 11.83206106870233 57
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 11.83206106870233 73
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fccd940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c42e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030be0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc50> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f715c01fb00> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 8.015267175572546 28
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 11.83206106870233 39
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 12.213740458015309 42
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 12.213740458015309 58
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 12.213740458015309 74
Completed Iteration #4
Best Reward: 0.3816793893129784
coverage_call_count 1500
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c005a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fb00> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 8.396946564885525 29
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 12.213740458015309 40
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 12.595419847328287 43
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 12.595419847328287 59
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 12.595419847328287 75
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c01f908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 8.778625954198503 30
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 12.595419847328287 41
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 12.977099236641266 44
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 12.977099236641266 60
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 12.977099236641266 76
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c09f630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005a58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01fb00> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 9.160305343511482 31
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 12.977099236641266 42
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 13.358778625954244 45
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 13.358778625954244 61
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 13.358778625954244 77
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fb00> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 9.54198473282446 32
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 13.358778625954244 43
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 13.740458015267222 46
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 13.740458015267222 62
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 13.740458015267222 78
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716de40ac8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 7.25190839694659 24
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 9.923664122137438 33
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 13.740458015267222 44
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 14.1221374045802 47
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 14.1221374045802 63
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 14.1221374045802 79
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fb00> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 7.25190839694659 25
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 9.923664122137438 34
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 13.740458015267222 45
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 14.1221374045802 48
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 14.1221374045802 64
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 14.1221374045802 80
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c040d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 4.580152671755741 15
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 7.633587786259568 26
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 10.305343511450417 35
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 14.1221374045802 46
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 14.50381679389318 49
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 14.50381679389318 65
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 14.50381679389318 81
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fccd390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040d68> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 4.961832061068719 16
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 8.015267175572546 27
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 10.687022900763395 36
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 14.50381679389318 47
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 14.885496183206158 50
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 14.885496183206158 66
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 14.885496183206158 82
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f712fc962e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 5.343511450381698 17
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 8.396946564885525 28
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 11.068702290076374 37
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 14.885496183206158 48
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 15.267175572519136 51
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 15.267175572519136 67
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 15.267175572519136 83
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->1->19->4->17->8->10
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c005198> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96a20> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040d68> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 8.778625954198503 29
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 11.450381679389352 38
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 15.267175572519136 49
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 15.648854961832114 52
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 15.648854961832114 68
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 15.648854961832114 84
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716de51e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96a20> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c040d68> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 6.106870229007654 19
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 9.160305343511482 30
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 11.83206106870233 39
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 15.648854961832114 50
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 16.030534351145093 53
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 16.030534351145093 69
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 16.030534351145093 85
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c0774e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 6.488549618320633 20
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 9.54198473282446 31
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 12.213740458015309 40
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 16.030534351145093 51
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 16.41221374045807 54
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 16.41221374045807 70
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 16.41221374045807 86
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716de517b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 6.870229007633611 21
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 9.923664122137438 32
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 12.595419847328287 41
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 16.41221374045807 52
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 16.79389312977105 55
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 16.79389312977105 71
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 16.79389312977105 87
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716de61c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 7.25190839694659 22
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 10.305343511450417 33
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 12.977099236641266 42
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 16.79389312977105 53
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 17.175572519084028 56
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 17.175572519084028 72
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 17.175572519084028 88
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716de61978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de517b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40940> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 4.580152671755741 13
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 7.633587786259568 23
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 10.687022900763395 34
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 13.358778625954244 43
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 17.175572519084028 54
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 17.557251908397006 57
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 17.557251908397006 73
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 17.557251908397006 89
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61c88> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 4.961832061068719 14
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 8.015267175572546 24
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 11.068702290076374 35
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 13.740458015267222 44
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 17.557251908397006 55
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 17.938931297709985 58
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 17.938931297709985 74
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 17.938931297709985 90
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c077400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fb38> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de517b8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f716de40940> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 5.343511450381698 15
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 8.396946564885525 25
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 11.450381679389352 36
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 14.1221374045802 45
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 17.938931297709985 56
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 18.320610687022963 59
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 18.320610687022963 75
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 18.320610687022963 91
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c005668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40940> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 5.725190839694676 16
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 8.778625954198503 26
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 11.83206106870233 37
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 14.50381679389318 46
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 18.320610687022963 57
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 18.70229007633594 60
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 18.70229007633594 76
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 18.70229007633594 92
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0774e0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 5.725190839694676 17
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 8.778625954198503 27
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 11.83206106870233 38
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 14.50381679389318 47
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 18.320610687022963 58
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 18.70229007633594 61
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 18.70229007633594 77
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 18.70229007633594 93
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->1->19->4->17->8->10->6
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c79e668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40940> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 6.106870229007654 18
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 9.160305343511482 28
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 12.213740458015309 39
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 14.885496183206158 48
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 18.70229007633594 59
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 19.08396946564892 62
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 19.08396946564892 78
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 19.08396946564892 94
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f719407af98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 6.488549618320633 19
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 9.54198473282446 29
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 12.595419847328287 40
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 15.267175572519136 49
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 19.08396946564892 60
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 19.4656488549619 63
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 19.4656488549619 79
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 19.4656488549619 95
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f7194053d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 6.870229007633611 20
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 9.923664122137438 30
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 12.977099236641266 41
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 15.648854961832114 50
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 19.4656488549619 61
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 19.847328244274877 64
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 19.847328244274877 80
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 19.847328244274877 96
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40940> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 7.25190839694659 21
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 10.305343511450417 31
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 13.358778625954244 42
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 16.030534351145093 51
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 19.847328244274877 62
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 20.229007633587855 65
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 20.229007633587855 81
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 20.229007633587855 97
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716c005e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40940> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 7.633587786259568 22
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 10.687022900763395 32
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 13.740458015267222 43
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 16.41221374045807 52
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 20.229007633587855 63
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 20.610687022900834 66
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 20.610687022900834 82
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 20.610687022900834 98
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f208> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 4.198473282442762 12
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 8.015267175572546 23
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 11.068702290076374 33
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 14.1221374045802 44
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 16.79389312977105 53
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 20.610687022900834 64
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 20.992366412213812 67
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 20.992366412213812 83
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 20.992366412213812 99
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4dd8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77f208> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 8.015267175572546 24
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 11.068702290076374 34
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 14.1221374045802 45
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 16.79389312977105 54
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 20.610687022900834 65
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 20.992366412213812 68
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 20.992366412213812 84
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 20.992366412213812 100
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f717c77f128> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40940> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 8.396946564885525 25
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 11.450381679389352 35
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 14.50381679389318 46
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 17.175572519084028 55
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 20.992366412213812 66
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 21.37404580152679 69
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 21.37404580152679 85
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 21.37404580152679 101
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7f716de61eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053710> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0682e8> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7f715c0ada90> 8.778625954198503 26
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 11.83206106870233 36
backprop <src.mcts.MCTS_Node object at 0x7f715c0400b8> 14.885496183206158 47
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e860> 17.557251908397006 56
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ac8> 21.37404580152679 67
backprop <src.mcts.MCTS_Node object at 0x7f711b2979b0> 21.75572519083977 70
backprop <src.mcts.MCTS_Node object at 0x7f711b2f16d8> 21.75572519083977 86
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 21.75572519083977 102
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->1->19->4->17->8->10->6->15
Best Reward: 0.3816793893129784
iteration: 37
found coverage increase 0.3816793893129784
Current Total Coverage 67.93893129770993
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71d7a894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a76a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7676a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7678d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c767e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71941bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 1600
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7032e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7032e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71941b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c70fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f717c72c320> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940674e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71d7a89518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940672b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940672b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71940676a0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 1700
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d66a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6658d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6656d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd287b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 17
Completed Iteration #17
Best Reward: 0
coverage_call_count 1900
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5080> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f716df8b940> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df995f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df995f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716dfd55f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6926a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6926a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc508d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df99438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df99f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507f0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc666a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc661d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc661d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc661d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeefd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeefd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2972e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfee048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeefd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2973c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b0724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2973c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b0722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f17f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0728d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0725f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 2100
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0725f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b0725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b0726d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183862e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d1cc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183865f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183865f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 2200
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183b1240> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbcc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbcc0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183864e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2973c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7535c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d17f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7535c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d16a0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183794e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183797f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183791d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183797f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183430b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183791d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183797f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 13
Completed Iteration #12
Best Reward: 0
coverage_call_count 2300
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ed30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183430f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b0720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183430f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711830ac18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 67.93893129770993
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183860b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711831fbe0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 8
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fbe0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 9
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 10
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 11
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 5
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 12
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 13
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 14
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 6
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 15
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 7
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 16
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 8
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 17
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 9
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 18
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 10
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 19
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fbe0> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 20
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.3816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.3816793893129642 21
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182d8a58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.7633587786259284 13
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.7633587786259284 22
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8a58> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 0.7633587786259284 14
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.7633587786259284 23
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 1.1450381679388926 15
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 1.1450381679388926 24
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182e5eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 1.5267175572518568 16
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 1.5267175572518568 25
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 1.5267175572518568 17
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 1.5267175572518568 26
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 1.5267175572518568 18
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 1.5267175572518568 27
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 1.908396946564821 19
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 1.908396946564821 28
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 1.1450381679388926 7
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 1.908396946564821 20
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 1.908396946564821 29
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 1.1450381679388926 8
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 1.908396946564821 21
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 1.908396946564821 30
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5eb8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 1.1450381679388926 9
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 1.908396946564821 22
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 1.908396946564821 31
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711831fd68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 1.5267175572518568 10
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 2.290076335877785 23
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 2.290076335877785 32
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fd68> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 1.5267175572518568 11
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 2.290076335877785 24
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 2.290076335877785 33
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182d8278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d85c0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 1.908396946564821 12
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 2.6717557251907493 25
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 2.6717557251907493 34
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 1.5267175572518568 7
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 2.290076335877785 13
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 3.0534351145037135 26
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 3.0534351145037135 35
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5eb8> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 2.6717557251907493 14
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 3.4351145038166777 27
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 3.4351145038166777 36
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d85c0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 2.6717557251907493 15
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 3.4351145038166777 28
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 3.4351145038166777 37
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 2.6717557251907493 16
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 3.4351145038166777 29
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 3.4351145038166777 38
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8278> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d85c0> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 2.6717557251907493 17
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 3.4351145038166777 30
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 3.4351145038166777 39
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->4->2
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182ef400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 3.0534351145037135 18
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 3.816793893129642 31
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 3.816793893129642 40
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182efe48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2208> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e5eb8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 3.4351145038166777 19
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 4.198473282442606 32
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 4.198473282442606 41
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182ef9b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 3.816793893129642 20
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 4.58015267175557 33
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 4.58015267175557 42
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182e5518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 4.198473282442606 21
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 4.9618320610685345 34
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 4.9618320610685345 43
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182fc630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc080> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5eb8> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 4.58015267175557 22
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 5.343511450381499 35
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 5.343511450381499 44
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
coverage_call_count 2400
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711830a2e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 4.9618320610685345 23
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 5.725190839694463 36
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 5.725190839694463 45
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182efba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 4.58015267175557 15
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 5.343511450381499 24
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 6.106870229007427 37
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 6.106870229007427 46
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182e5fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e56a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 5.725190839694463 25
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 6.488549618320391 38
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 6.488549618320391 47
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711831fd68> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 5.725190839694463 26
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 6.488549618320391 39
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 6.488549618320391 48
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->4->2->6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182fcc50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e56a0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 6.106870229007427 27
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 6.870229007633355 40
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 6.870229007633355 49
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182fcf60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 5.725190839694463 19
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 6.488549618320391 28
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 7.25190839694632 41
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 7.25190839694632 50
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5fd0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e56a0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 5.725190839694463 20
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 6.488549618320391 29
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 7.25190839694632 42
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 7.25190839694632 51
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 6.106870229007427 21
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 6.870229007633355 30
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 7.633587786259284 43
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 7.633587786259284 52
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 6.488549618320391 22
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 7.25190839694632 31
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 8.015267175572248 44
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 8.015267175572248 53
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182acc18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1f60> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 6.870229007633355 23
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 7.633587786259284 32
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 8.396946564885212 45
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 8.396946564885212 54
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182acf28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e56a0> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 7.25190839694632 24
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 8.015267175572248 33
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 8.778625954198176 46
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 8.778625954198176 55
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182a1c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 7.633587786259284 25
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 8.396946564885212 34
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 9.16030534351114 47
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 9.16030534351114 56
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->4->2->6->17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcf60> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 8.015267175572248 26
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 8.778625954198176 35
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 9.541984732824105 48
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 9.541984732824105 57
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182ac5c0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac780> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1c50> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 8.396946564885212 27
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 9.16030534351114 36
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 9.923664122137069 49
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 9.923664122137069 58
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182e5630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac780> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1c50> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 8.778625954198176 28
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 9.541984732824105 37
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 10.305343511450033 50
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 10.305343511450033 59
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182b67b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac780> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a1c50> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 9.16030534351114 29
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 9.923664122137069 38
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 10.687022900762997 51
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 10.687022900762997 60
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182b6eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6dd8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fc128> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fcf60> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 9.541984732824105 30
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 10.305343511450033 39
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 11.068702290075962 52
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 11.068702290075962 61
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182b6e48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6eb8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b6dd8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182fc128> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182fcf60> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 9.923664122137069 31
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 10.687022900762997 40
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 11.450381679388926 53
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 11.450381679388926 62
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118257ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 10.305343511450033 32
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 11.068702290075962 41
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 11.83206106870189 54
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 11.83206106870189 63
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118257da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 10.687022900762997 33
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 11.450381679388926 42
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 12.213740458014854 55
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 12.213740458014854 64
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182a17f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1a58> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcf60> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 11.068702290075962 34
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 11.83206106870189 43
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 12.595419847327818 56
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 12.595419847327818 65
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->4->2->6->17->4
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182fcbe0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257588> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 11.450381679388926 35
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 12.213740458014854 44
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 12.977099236640782 57
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 12.977099236640782 66
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182b6438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 11.83206106870189 36
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 12.595419847327818 45
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 13.358778625953747 58
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 13.358778625953747 67
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182ac9b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 6.488549618320391 18
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 8.778625954198176 25
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 12.213740458014854 37
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 12.977099236640782 46
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 13.74045801526671 59
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 13.74045801526671 68
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118257080> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 6.870229007633355 19
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 9.16030534351114 26
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 12.595419847327818 38
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 13.358778625953747 47
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 14.122137404579675 60
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 14.122137404579675 69
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182efc18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 7.25190839694632 20
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 9.541984732824105 27
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 12.977099236640782 39
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 13.74045801526671 48
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 14.50381679389264 61
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 14.50381679389264 70
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118261940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182613c8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 7.633587786259284 21
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 9.923664122137069 28
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 13.358778625953747 40
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 14.122137404579675 49
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 14.885496183205603 62
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 14.885496183205603 71
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182c27f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182613c8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 8.015267175572248 22
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 10.305343511450033 29
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 13.74045801526671 41
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 14.50381679389264 50
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 15.267175572518568 63
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 15.267175572518568 72
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182efbe0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef780> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c27f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182613c8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 8.396946564885212 23
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 10.687022900762997 30
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 14.122137404579675 42
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 14.885496183205603 51
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 15.648854961831532 64
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 15.648854961831532 73
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182e5588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6cf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5518> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7118343978> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 8.778625954198176 24
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 11.068702290075962 31
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 14.50381679389264 43
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 15.267175572518568 52
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 16.030534351144496 65
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 16.030534351144496 74
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182c2198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257588> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 9.16030534351114 25
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 11.450381679388926 32
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 14.885496183205603 44
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 15.648854961831532 53
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 16.41221374045746 66
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 16.41221374045746 75
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->4->2->6->17->4->11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182fcb00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6438> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 9.541984732824105 26
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 11.83206106870189 33
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 15.267175572518568 45
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 16.030534351144496 54
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 16.793893129770424 67
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 16.793893129770424 76
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257080> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 9.541984732824105 27
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 11.83206106870189 34
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 15.267175572518568 46
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 16.030534351144496 55
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 16.793893129770424 68
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 16.793893129770424 77
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182576a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac1d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257da0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 9.923664122137069 28
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 12.213740458014854 35
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 15.648854961831532 47
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 16.41221374045746 56
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 17.17557251908339 69
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 17.17557251908339 78
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac1d0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7118257da0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 9.923664122137069 29
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 12.213740458014854 36
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 15.648854961831532 48
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 16.41221374045746 57
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 17.17557251908339 70
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 17.17557251908339 79
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac1d0> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f7118257da0> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 3.0534351145037135 12
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 6.488549618320391 21
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 9.923664122137069 30
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 12.213740458014854 37
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 15.648854961831532 49
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 16.41221374045746 58
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 17.17557251908339 71
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 17.17557251908339 80
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711830acc0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac438> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b6438> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 6.870229007633355 22
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 10.305343511450033 31
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 12.595419847327818 38
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 16.030534351144496 50
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 16.793893129770424 59
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 17.557251908396353 72
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 17.557251908396353 81
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182e5e10> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 7.25190839694632 23
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 10.687022900762997 32
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 12.977099236640782 39
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 16.41221374045746 51
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 17.17557251908339 60
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 17.938931297709317 73
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 17.938931297709317 82
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
coverage_call_count 2500
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182d82b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 7.633587786259284 24
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 13.358778625953747 40
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 16.793893129770424 52
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 17.557251908396353 61
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 18.32061068702228 74
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 18.32061068702228 83
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118257908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 4.58015267175557 16
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 8.015267175572248 25
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 11.450381679388926 34
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 13.74045801526671 41
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 17.17557251908339 53
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 17.938931297709317 62
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 18.702290076335245 75
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 18.702290076335245 84
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711831f438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257a90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6438> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 8.396946564885212 26
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 11.83206106870189 35
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 14.122137404579675 42
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 17.557251908396353 54
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 18.32061068702228 63
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 19.08396946564821 76
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 19.08396946564821 85
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 4.9618320610685345 18
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 8.396946564885212 27
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 11.83206106870189 36
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 14.122137404579675 43
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 17.557251908396353 55
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 18.32061068702228 64
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 19.08396946564821 77
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 19.08396946564821 86
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->4->2->6->17->4->11->3
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71183fb5c0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 5.343511450381499 19
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 8.778625954198176 28
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 12.213740458014854 37
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 14.50381679389264 44
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 17.938931297709317 56
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 18.702290076335245 65
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 19.465648854961174 78
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 19.465648854961174 87
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118343da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efc18> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 5.725190839694463 20
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 9.16030534351114 29
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 12.595419847327818 38
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 14.885496183205603 45
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 18.32061068702228 57
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 19.08396946564821 66
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 19.847328244274138 79
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 19.847328244274138 88
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac9b0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 5.725190839694463 21
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 9.16030534351114 30
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 12.595419847327818 39
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 14.885496183205603 46
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 18.32061068702228 58
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 19.08396946564821 67
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 19.847328244274138 80
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 19.847328244274138 89
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 6.106870229007427 22
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 9.541984732824105 31
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 12.977099236640782 40
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 15.267175572518568 47
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 18.702290076335245 59
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 19.465648854961174 68
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 20.229007633587102 81
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 20.229007633587102 90
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711831f160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acd68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 6.488549618320391 23
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 9.923664122137069 32
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 13.358778625953747 41
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 15.648854961831532 48
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 19.08396946564821 60
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 19.847328244274138 69
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 20.610687022900066 82
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 20.610687022900066 91
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182ac710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 6.870229007633355 24
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 10.305343511450033 33
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 13.74045801526671 42
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 16.030534351144496 49
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 19.465648854961174 61
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 20.229007633587102 70
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 20.99236641221303 83
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 20.99236641221303 92
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118343f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 7.25190839694632 25
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 10.687022900762997 34
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 14.122137404579675 43
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 16.41221374045746 50
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 19.847328244274138 62
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 20.610687022900066 71
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 21.374045801525995 84
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 21.374045801525995 93
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118257b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 7.633587786259284 26
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 11.068702290075962 35
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 14.50381679389264 44
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 16.793893129770424 51
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 20.229007633587102 63
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 20.99236641221303 72
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 21.75572519083896 85
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 21.75572519083896 94
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0b8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71182acfd0> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 7.633587786259284 27
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 11.068702290075962 36
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 14.50381679389264 45
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 16.793893129770424 52
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 20.229007633587102 64
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 20.99236641221303 73
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 21.75572519083896 86
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 21.75572519083896 95
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118386c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71183792e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 4.58015267175557 15
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 8.015267175572248 28
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 11.450381679388926 37
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 14.885496183205603 46
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 17.17557251908339 53
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 20.610687022900066 65
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 21.374045801525995 74
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 22.137404580151923 87
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 22.137404580151923 96
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118386710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386780> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 8.396946564885212 29
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 11.83206106870189 38
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 15.267175572518568 47
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 17.557251908396353 54
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 20.99236641221303 66
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 21.75572519083896 75
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 22.519083969464887 88
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 22.519083969464887 97
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acd68> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 5.343511450381499 17
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 8.778625954198176 30
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 12.213740458014854 39
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 15.648854961831532 48
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 17.938931297709317 55
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 21.374045801525995 67
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 22.137404580151923 76
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 22.90076335877785 89
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 22.90076335877785 98
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118257668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acbe0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386c50> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71183792e8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7b8> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7f71182ac160> 9.16030534351114 31
backprop <src.mcts.MCTS_Node object at 0x7f71182d87b8> 12.595419847327818 40
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 16.030534351144496 49
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 18.32061068702228 56
backprop <src.mcts.MCTS_Node object at 0x7f71182e5f28> 21.75572519083896 68
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 22.519083969464887 77
backprop <src.mcts.MCTS_Node object at 0x7f7118343b38> 23.282442748090816 90
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 23.282442748090816 99
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->4->2->6->17->4->11->3->0
Best Reward: 0.3816793893129642
iteration: 67
found coverage increase 0.3816793893129642
Current Total Coverage 68.32061068702289
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183868d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b10f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 68.32061068702289
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.3816793893129926 3
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.3816793893129926 4
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 5
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 6
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 7
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 8
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 9
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 10
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 11
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 12
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 13
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 14
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 15
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 16
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71d7a894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 8
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 17
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 18
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 9
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 19
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 10
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 20
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 11
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 21
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcabb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 12
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 22
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 13
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 23
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 14
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 24
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 15
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 25
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 16
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 26
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 17
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 27
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 18
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 28
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 0.7633587786259852 8
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.7633587786259852 19
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 0.7633587786259852 29
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7118379b70> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab5c0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.1450381679389778 9
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.1450381679389778 20
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.1450381679389778 30
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5128> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 10
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 21
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 31
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab5c0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 11
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 22
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 32
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5128> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 12
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 23
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 33
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5128> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 13
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 24
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 34
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6711d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fcab5c0> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 14
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 25
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 35
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 15
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 26
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 36
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab5c0> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 16
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 27
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 37
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5128> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 17
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 28
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 38
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5128> 0.3816793893129926 6
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 18
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 29
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 39
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 19
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 30
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 40
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.5267175572519704 20
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.5267175572519704 31
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.5267175572519704 41
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #2
root->4->19
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c753128> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a710> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.908396946564963 21
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.908396946564963 32
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.908396946564963 42
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.908396946564963 22
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.908396946564963 33
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.908396946564963 43
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a710> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.7633587786259852 8
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.908396946564963 23
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.908396946564963 34
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.908396946564963 44
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.7633587786259852 9
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.908396946564963 24
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.908396946564963 35
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.908396946564963 45
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.7633587786259852 10
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.908396946564963 25
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.908396946564963 36
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.908396946564963 46
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 0.7633587786259852 11
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 1.908396946564963 26
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 1.908396946564963 37
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 1.908396946564963 47
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #3
root->4->19->3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 1.1450381679389778 12
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 2.2900763358779557 27
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 2.2900763358779557 38
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 2.2900763358779557 48
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c67f6a0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a710> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 1.5267175572519704 13
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 2.6717557251909483 28
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 2.6717557251909483 39
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 2.6717557251909483 49
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c6a80b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 1.908396946564963 14
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 3.053435114503941 29
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 3.053435114503941 40
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 3.053435114503941 50
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a710> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 1.908396946564963 9
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 1.908396946564963 15
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 3.053435114503941 30
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 3.053435114503941 41
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 3.053435114503941 51
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c692da0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a710> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 2.2900763358779557 16
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 3.4351145038169335 31
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 3.4351145038169335 42
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 3.4351145038169335 52
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692da0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c68a710> 1.1450381679389778 7
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 2.2900763358779557 11
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 2.2900763358779557 17
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 3.4351145038169335 32
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 3.4351145038169335 43
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 3.4351145038169335 53
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 2.2900763358779557 12
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 2.2900763358779557 18
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 3.4351145038169335 33
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 3.4351145038169335 44
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 3.4351145038169335 54
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2cf8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 2.6717557251909483 13
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 2.6717557251909483 19
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 3.816793893129926 34
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 3.816793893129926 45
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 3.816793893129926 55
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f71182e5080> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2cf8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 3.053435114503941 14
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 3.053435114503941 20
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 4.198473282442919 35
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 4.198473282442919 46
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 4.198473282442919 56
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f712fcab7b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 3.4351145038169335 15
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 3.4351145038169335 21
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 4.580152671755911 36
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 4.580152671755911 47
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 4.580152671755911 57
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #4
root->4->19->3->29
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2a20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e21d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab7b8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 3.816793893129926 16
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 3.816793893129926 22
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 4.961832061068904 37
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 4.961832061068904 48
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 4.961832061068904 58
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2278> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2cf8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 3.816793893129926 17
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 3.816793893129926 23
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 4.961832061068904 38
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 4.961832061068904 49
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 4.961832061068904 59
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c70f5c0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 4.198473282442919 18
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 4.198473282442919 24
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 5.343511450381897 39
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 5.343511450381897 50
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 5.343511450381897 60
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7194053898> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 4.580152671755911 19
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 4.580152671755911 25
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 5.725190839694889 40
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 5.725190839694889 51
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 5.725190839694889 61
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7194053470> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71940537f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a80b8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 4.961832061068904 20
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 4.961832061068904 26
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 6.106870229007882 41
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 6.106870229007882 52
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 6.106870229007882 62
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c7670b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 5.343511450381897 21
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 5.343511450381897 27
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 6.488549618320874 42
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 6.488549618320874 53
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 6.488549618320874 63
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5080> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2278> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2cf8> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 3.816793893129926 13
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 5.343511450381897 22
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 5.343511450381897 28
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 6.488549618320874 43
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 6.488549618320874 54
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 6.488549618320874 64
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #5
root->4->19->3->29->8
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
coverage_call_count 2700
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f7194053f98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.198473282442919 14
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 5.725190839694889 23
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 5.725190839694889 29
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 6.870229007633867 44
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 6.870229007633867 55
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 6.870229007633867 65
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f240> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.198473282442919 15
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 5.725190839694889 24
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 5.725190839694889 30
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 6.870229007633867 45
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 6.870229007633867 56
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 6.870229007633867 66
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.198473282442919 16
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 5.725190839694889 25
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 5.725190839694889 31
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 6.870229007633867 46
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 6.870229007633867 57
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 6.870229007633867 67
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c767fd0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.580152671755911 17
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 6.106870229007882 26
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 6.106870229007882 32
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 7.25190839694686 47
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 7.25190839694686 58
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 7.25190839694686 68
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c767320> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 4.961832061068904 18
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 6.488549618320874 27
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 6.488549618320874 33
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 7.633587786259852 48
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 7.633587786259852 59
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 7.633587786259852 69
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f716de61128> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.4351145038169335 12
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.343511450381897 19
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 6.870229007633867 28
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 6.870229007633867 34
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.015267175572845 49
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.015267175572845 60
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.015267175572845 70
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e21d0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f712fcab7b8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.343511450381897 20
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 6.870229007633867 29
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 6.870229007633867 35
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.015267175572845 50
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.015267175572845 61
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.015267175572845 71
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.343511450381897 21
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 6.870229007633867 30
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 6.870229007633867 36
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.015267175572845 51
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.015267175572845 62
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.015267175572845 72
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0055c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab7b8> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 2.2900763358779557 11
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.4351145038169335 15
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.343511450381897 22
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 6.870229007633867 31
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 6.870229007633867 37
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.015267175572845 52
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.015267175572845 63
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.015267175572845 73
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f978> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.4351145038169335 16
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.343511450381897 23
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 6.870229007633867 32
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 6.870229007633867 38
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.015267175572845 53
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.015267175572845 64
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.015267175572845 74
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.4351145038169335 17
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.343511450381897 24
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 6.870229007633867 33
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 6.870229007633867 39
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.015267175572845 54
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.015267175572845 65
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.015267175572845 75
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #6
root->4->19->3->29->8->14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 2.6717557251909483 12
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.816793893129926 18
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.725190839694889 25
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 7.25190839694686 34
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 7.25190839694686 40
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.396946564885837 55
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.396946564885837 66
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.396946564885837 76
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767320> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 2.6717557251909483 13
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.816793893129926 19
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.725190839694889 26
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 7.25190839694686 35
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 7.25190839694686 41
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.396946564885837 56
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.396946564885837 67
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.396946564885837 77
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 2.6717557251909483 14
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.816793893129926 20
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.725190839694889 27
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 7.25190839694686 36
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 7.25190839694686 42
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.396946564885837 57
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.396946564885837 68
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.396946564885837 78
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053898> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 2.6717557251909483 15
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 3.816793893129926 21
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 5.725190839694889 28
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 7.25190839694686 37
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 7.25190839694686 43
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.396946564885837 58
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.396946564885837 69
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.396946564885837 79
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f716c005588> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 3.053435114503941 16
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 4.198473282442919 22
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 6.106870229007882 29
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 7.633587786259852 38
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 7.633587786259852 44
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.77862595419883 59
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.77862595419883 70
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.77862595419883 80
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053898> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 3.053435114503941 17
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 4.198473282442919 23
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 6.106870229007882 30
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 7.633587786259852 39
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 7.633587786259852 45
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.77862595419883 60
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.77862595419883 71
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.77862595419883 81
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 3.053435114503941 18
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 4.198473282442919 24
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 6.106870229007882 31
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 7.633587786259852 40
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 7.633587786259852 46
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 8.77862595419883 61
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 8.77862595419883 72
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 8.77862595419883 82
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f715c0d63c8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 3.4351145038169335 19
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 4.580152671755911 25
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 6.488549618320874 32
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 8.015267175572845 41
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 8.015267175572845 47
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 9.160305343511823 62
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 9.160305343511823 73
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 9.160305343511823 83
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61128> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 3.4351145038169335 20
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 4.580152671755911 26
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 6.488549618320874 33
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 8.015267175572845 42
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 8.015267175572845 48
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 9.160305343511823 63
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 9.160305343511823 74
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 9.160305343511823 84
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f71182a1748> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 3.816793893129926 21
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 4.961832061068904 27
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 6.870229007633867 34
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 8.396946564885837 43
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 8.396946564885837 49
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 9.541984732824815 64
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 9.541984732824815 75
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 9.541984732824815 85
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c79e898> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767320> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 4.198473282442919 22
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 5.343511450381897 28
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 7.25190839694686 35
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 8.77862595419883 44
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 8.77862595419883 50
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 9.923664122137808 65
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 9.923664122137808 76
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 9.923664122137808 86
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0055f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005588> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 4.198473282442919 23
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 5.343511450381897 29
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 7.25190839694686 36
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 8.77862595419883 45
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 8.77862595419883 51
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 9.923664122137808 66
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 9.923664122137808 77
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 9.923664122137808 87
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f716c005c50> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 4.580152671755911 24
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 5.725190839694889 30
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 7.633587786259852 37
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 9.160305343511823 46
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 9.160305343511823 52
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 10.3053435114508 67
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 10.3053435114508 78
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 10.3053435114508 88
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c72c048> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716de409e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053898> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 4.961832061068904 25
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 6.106870229007882 31
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 8.015267175572845 38
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 9.541984732824815 47
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 9.541984732824815 53
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 10.687022900763793 68
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 10.687022900763793 79
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 10.687022900763793 89
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #7
root->4->19->3->29->8->14->1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6da0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 5.343511450381897 26
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 6.488549618320874 32
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 8.396946564885837 39
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 9.923664122137808 48
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 9.923664122137808 54
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 11.068702290076786 69
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 11.068702290076786 80
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 11.068702290076786 90
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f715c030ef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 5.725190839694889 27
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 6.870229007633867 33
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 8.77862595419883 40
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 10.3053435114508 49
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 10.3053435114508 55
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 11.450381679389778 70
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 11.450381679389778 81
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 11.450381679389778 91
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f716c077c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 6.106870229007882 28
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 7.25190839694686 34
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 9.160305343511823 41
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 10.687022900763793 50
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 10.687022900763793 56
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 11.832061068702771 71
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 11.832061068702771 82
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 11.832061068702771 92
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030ef0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 6.106870229007882 29
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 7.25190839694686 35
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 9.160305343511823 42
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 10.687022900763793 51
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 10.687022900763793 57
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 11.832061068702771 72
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 11.832061068702771 83
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 11.832061068702771 93
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f716de61ba8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005ef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6da0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 6.488549618320874 30
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 7.633587786259852 36
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 9.541984732824815 43
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 11.068702290076786 52
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 11.068702290076786 58
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 12.213740458015764 73
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 12.213740458015764 84
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 12.213740458015764 94
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6cf8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d60f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1748> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 6.870229007633867 31
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 8.015267175572845 37
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 9.923664122137808 44
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 11.450381679389778 53
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 11.450381679389778 59
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 12.595419847328756 74
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 12.595419847328756 85
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 12.595419847328756 95
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 2.6717557251909483 11
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 6.870229007633867 32
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 8.015267175572845 38
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 9.923664122137808 45
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 11.450381679389778 54
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 11.450381679389778 60
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 12.595419847328756 75
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 12.595419847328756 86
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 12.595419847328756 96
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f715c030eb8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 7.25190839694686 33
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 8.396946564885837 39
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 10.3053435114508 46
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 11.832061068702771 55
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 11.832061068702771 61
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 12.977099236641749 76
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 12.977099236641749 87
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 12.977099236641749 97
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7f717c77f828> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fac8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61ba8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f716c005ef0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6da0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 7.633587786259852 34
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 8.77862595419883 40
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 10.687022900763793 47
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 12.213740458015764 56
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 12.213740458015764 62
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 13.358778625954741 77
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 13.358778625954741 88
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 13.358778625954741 98
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeef0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 7.633587786259852 35
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 8.77862595419883 41
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 10.687022900763793 48
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 12.213740458015764 57
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 12.213740458015764 63
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 13.358778625954741 78
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 13.358778625954741 89
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 13.358778625954741 99
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6da0> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 3.4351145038169335 15
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 7.633587786259852 36
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 8.77862595419883 42
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 10.687022900763793 49
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 12.213740458015764 58
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 12.213740458015764 64
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 13.358778625954741 79
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 13.358778625954741 90
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 13.358778625954741 100
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de409b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeef0> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 3.4351145038169335 16
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 7.633587786259852 37
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 8.77862595419883 43
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 10.687022900763793 50
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 12.213740458015764 59
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 12.213740458015764 65
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 13.358778625954741 80
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 13.358778625954741 91
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 13.358778625954741 101
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfeeef0> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7f716de61f28> 3.4351145038169335 17
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6d8> 7.633587786259852 38
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa90> 8.77862595419883 44
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 10.687022900763793 51
backprop <src.mcts.MCTS_Node object at 0x7f71183d1208> 12.213740458015764 60
backprop <src.mcts.MCTS_Node object at 0x7f71182b6320> 12.213740458015764 66
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 13.358778625954741 81
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 13.358778625954741 92
backprop <src.mcts.MCTS_Node object at 0x7f71183b1160> 13.358778625954741 102
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #8
root->4->19->3->29->8->14->1->2
Best Reward: 0.3816793893129926
iteration: 69
found coverage increase 0.3816793893129926
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0058d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0303c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd15d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0054a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df998d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2978> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0683c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0683c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e6a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c77ffd0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc663c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c47f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c47f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0689b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2976a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0689b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6657b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6657b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297e48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb6d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de514a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de510f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de510f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e9b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71940676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0056d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd282e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0685c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc505f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c01f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0402b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0402b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc878d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182615c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182615c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc779e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71180171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182614e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118017ac8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0405f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71180174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182612b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0405f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71180174a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc965c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028c50> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135faf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135fa4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135faf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71135ea198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc965c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea588> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135480b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135480b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135480b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135480b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135551d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 3300
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f711358eda0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135677b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135677b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135140f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135140f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135255c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135363c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135257f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135255c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135362b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135362b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135258d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 3400
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d55f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d55f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7113525a90> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182619b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135dae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134926d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134926d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc874a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135dae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134d5eb8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71180174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134557b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134747b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134747b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134062e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134065f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135679b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134629b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71134a9fd0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134924e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134924e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113536ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7113406940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135679b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc35f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc35f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a90b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a90b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134d5fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 3700
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112faed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa198> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112faea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112faeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa07b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134847b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fa09b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f599b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f59828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0deb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f363c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ab38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f363c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ab38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c01fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134627b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134627b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c040da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea128> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 7
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6658d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6658d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0683c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd28d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c040160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c665358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462630> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f719407ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0050b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f719407afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71941bbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e29e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046ac8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de40f28> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0addd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0addd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6921d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c46a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c09fc18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71d9e44278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 4100
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135eae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfeef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de612e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c72cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 16
Completed Iteration #18
Best Reward: 0
coverage_call_count 4200
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183795f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118257240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 4300
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ace10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de613c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ace10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6d60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b61d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de61ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b0725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc507b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b0724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ef048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134744e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc770b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182fcdd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c67f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcabd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcabd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcabcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c63f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c767518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711830aa90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194070048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c671208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc77c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b70> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343b70> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183fbac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 4600
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d16d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1080> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcab668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135257b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135257b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd18d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134066d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134066d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134066d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134067b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f592b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134064a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134066d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112feab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112feab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f593c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea550> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ace80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ace80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183b1e10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 68.70229007633588
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4800
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 4
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 5
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 6
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 7
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 8
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 9
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 10
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.3816793893129642 5
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 11
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 12
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71180287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 13
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182618d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 14
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.3816793893129642 6
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 15
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 16
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182618d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 17
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182618d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 18
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.3816793893129642 7
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.3816793893129642 19
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71134920b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 8
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 20
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 21
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 9
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 22
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 23
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 10
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 24
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 11
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 25
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 12
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 26
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 13
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 27
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 14
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 28
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 15
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 29
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 16
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 30
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 17
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 31
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 18
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 32
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 19
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 33
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 20
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 34
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 0.7633587786259284 21
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 0.7633587786259284 35
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112fea6a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028278> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.1450381679388926 22
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.1450381679388926 36
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.1450381679388926 23
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.1450381679388926 37
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.1450381679388926 24
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.1450381679388926 38
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.1450381679388926 25
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.1450381679388926 39
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f593c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.1450381679388926 26
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.1450381679388926 40
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.1450381679388926 27
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.1450381679388926 41
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.1450381679388926 28
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.1450381679388926 42
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->3
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135dadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.1450381679388926 29
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.1450381679388926 43
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71135faf98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 1.5267175572518568 7
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.5267175572518568 30
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.5267175572518568 44
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7113484390> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525048> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71135faf98> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 1.908396946564821 31
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 1.908396946564821 45
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3240> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 2.290076335877785 32
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 2.290076335877785 46
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7113406160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 2.6717557251907493 33
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 2.6717557251907493 47
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 3.0534351145037135 34
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 3.0534351145037135 48
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118028e80> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fafd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 3.4351145038166777 35
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 3.4351145038166777 49
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112fea160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028278> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 3.816793893129642 36
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 3.816793893129642 50
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7113555b38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea6a0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028278> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 4.198473282442606 37
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 4.198473282442606 51
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->3->26
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 4.198473282442606 38
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 4.198473282442606 52
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 4.198473282442606 16
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 4.198473282442606 39
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 4.198473282442606 53
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 4.58015267175557 17
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 4.58015267175557 40
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 4.58015267175557 54
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 2.290076335877785 10
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 4.58015267175557 18
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 4.58015267175557 41
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 4.58015267175557 55
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 2.290076335877785 11
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 4.58015267175557 19
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 4.58015267175557 42
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 4.58015267175557 56
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180171d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525048> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71135faf98> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 2.290076335877785 12
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 4.58015267175557 20
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 4.58015267175557 43
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 4.58015267175557 57
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406160> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 2.290076335877785 13
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 4.58015267175557 21
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 4.58015267175557 44
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 4.58015267175557 58
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711831fb38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3240> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 2.6717557251907493 14
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 4.9618320610685345 22
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 4.9618320610685345 45
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 4.9618320610685345 59
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->3->26->8
Best Reward: 0.3816793893129642
coverage_call_count 4900
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71135fa780> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 3.0534351145037135 15
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 5.343511450381499 23
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 5.343511450381499 46
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 5.343511450381499 60
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f712fc871d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 3.4351145038166777 16
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 5.725190839694463 24
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 5.725190839694463 47
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 5.725190839694463 61
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f4dc18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ef28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d400> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 3.816793893129642 17
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 6.106870229007427 25
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 6.106870229007427 48
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 6.106870229007427 62
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f4ddd8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 4.198473282442606 18
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 6.488549618320391 26
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 6.488549618320391 49
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 6.488549618320391 63
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711358e668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa780> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 4.58015267175557 19
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 6.870229007633355 27
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 6.870229007633355 50
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 6.870229007633355 64
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ef28> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d400> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 4.58015267175557 20
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 6.870229007633355 28
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 6.870229007633355 51
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 6.870229007633355 65
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 4.9618320610685345 21
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 7.25190839694632 29
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 7.25190839694632 52
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 7.25190839694632 66
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71134a9ef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 5.343511450381499 22
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 7.633587786259284 30
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 7.633587786259284 53
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 7.633587786259284 67
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9ef0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7118017898> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 5.725190839694463 23
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 8.015267175572248 31
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 8.015267175572248 54
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 8.015267175572248 68
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71135fa710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017898> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 6.106870229007427 24
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 8.396946564885212 32
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 8.396946564885212 55
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 8.396946564885212 69
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71135dab38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 6.488549618320391 25
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 8.778625954198176 33
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 8.778625954198176 56
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 8.778625954198176 70
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4ddd8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 6.870229007633355 26
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 9.16030534351114 34
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 9.16030534351114 57
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 9.16030534351114 71
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118017f28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 7.25190839694632 27
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 9.541984732824105 35
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 9.541984732824105 58
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 9.541984732824105 72
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->3->26->8->24
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f712fc87828> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 7.633587786259284 28
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 9.923664122137069 36
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 9.923664122137069 59
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 9.923664122137069 73
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71182c2358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 8.015267175572248 29
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 10.305343511450033 37
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 10.305343511450033 60
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 10.305343511450033 74
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7118017d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134925c0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71135dab38> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 8.396946564885212 30
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 10.687022900762997 38
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 10.687022900762997 61
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 10.687022900762997 75
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112fae898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 11.068702290075962 39
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 11.068702290075962 62
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 11.068702290075962 76
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112faeef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 11.450381679388926 40
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 11.450381679388926 63
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 11.450381679388926 77
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711b297ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555128> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4ddd8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 9.541984732824105 33
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 11.83206106870189 41
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 11.83206106870189 64
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 11.83206106870189 78
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 9.923664122137069 34
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 12.213740458014854 42
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 12.213740458014854 65
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 12.213740458014854 79
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711831f940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ecf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87828> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 10.305343511450033 35
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 12.595419847327818 43
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 12.595419847327818 66
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 12.595419847327818 80
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7113492940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 8.778625954198176 25
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 10.687022900762997 36
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 12.977099236640782 44
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 12.977099236640782 67
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 12.977099236640782 81
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71134a9898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555128> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f4ddd8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 9.16030534351114 26
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 11.068702290075962 37
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 13.358778625953747 45
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 13.358778625953747 68
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 13.358778625953747 82
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->3->26->8->24->0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f711358e6a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 9.541984732824105 27
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 11.450381679388926 38
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 13.74045801526671 46
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 13.74045801526671 69
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 13.74045801526671 83
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112fae8d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2974e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 9.923664122137069 28
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 11.83206106870189 39
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 14.122137404579675 47
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 14.122137404579675 70
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 14.122137404579675 84
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 9.923664122137069 29
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 11.83206106870189 40
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 14.122137404579675 48
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 14.122137404579675 71
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 14.122137404579675 85
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112fa07b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 8.778625954198176 26
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 10.305343511450033 30
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 12.213740458014854 41
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 14.50381679389264 49
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 14.50381679389264 72
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 14.50381679389264 86
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 10.687022900762997 31
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 12.595419847327818 42
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 14.885496183205603 50
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 14.885496183205603 73
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 14.885496183205603 87
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f36a90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa07b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 9.541984732824105 28
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 11.068702290075962 32
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 12.977099236640782 43
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 15.267175572518568 51
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 15.267175572518568 74
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 15.267175572518568 88
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2974e0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 9.541984732824105 29
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 12.977099236640782 44
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 15.267175572518568 52
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 15.267175572518568 75
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 15.267175572518568 89
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 9.541984732824105 30
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 11.068702290075962 34
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 12.977099236640782 45
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 15.267175572518568 53
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 15.267175572518568 76
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 15.267175572518568 90
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->3->26->8->24->0->7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0e48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae898> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 9.923664122137069 31
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 11.450381679388926 35
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 13.358778625953747 46
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 15.648854961831532 54
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 15.648854961831532 77
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 15.648854961831532 91
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 4.58015267175557 16
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 10.305343511450033 32
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 11.83206106870189 36
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 13.74045801526671 47
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 16.030534351144496 55
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 16.030534351144496 78
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 16.030534351144496 92
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f712fc87fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 10.687022900762997 33
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 12.213740458014854 37
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 14.122137404579675 48
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 16.41221374045746 56
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 16.41221374045746 79
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 16.41221374045746 93
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f364a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 5.343511450381499 18
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 11.068702290075962 34
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 12.595419847327818 38
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 14.50381679389264 49
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 16.793893129770424 57
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 16.793893129770424 80
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 16.793893129770424 94
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f36da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae860> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fae898> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 5.725190839694463 19
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 11.450381679388926 35
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 12.977099236640782 39
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 14.885496183205603 50
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 17.17557251908339 58
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 17.17557251908339 81
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 17.17557251908339 95
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112177550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 6.106870229007427 20
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 11.83206106870189 36
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 13.358778625953747 40
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 15.267175572518568 51
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 17.557251908396353 59
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 17.557251908396353 82
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 17.557251908396353 96
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112177e10> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 6.488549618320391 21
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 12.213740458014854 37
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 13.74045801526671 41
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 15.648854961831532 52
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 17.938931297709317 60
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 17.938931297709317 83
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 17.938931297709317 97
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71134a90b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 6.870229007633355 22
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 12.595419847327818 38
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 14.122137404579675 42
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 16.030534351144496 53
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 18.32061068702228 61
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 18.32061068702228 84
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 18.32061068702228 98
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f36908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36668> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa07b8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 6.488549618320391 18
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 7.25190839694632 23
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 12.977099236640782 39
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 14.50381679389264 43
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 16.41221374045746 54
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 18.702290076335245 62
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 18.702290076335245 85
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 18.702290076335245 99
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae898> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 7.25190839694632 24
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 12.977099236640782 40
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 14.50381679389264 44
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 16.41221374045746 55
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 18.702290076335245 63
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 18.702290076335245 86
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 18.702290076335245 100
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
coverage_call_count 5000
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->3->26->8->24->0->7->0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112f366a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71121771d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87fd0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 7.633587786259284 25
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 13.358778625953747 41
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 14.885496183205603 45
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 16.793893129770424 56
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 19.08396946564821 64
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 19.08396946564821 87
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 19.08396946564821 101
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa1d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 8.015267175572248 26
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 13.74045801526671 42
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 15.267175572518568 46
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 17.17557251908339 57
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 19.465648854961174 65
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 19.465648854961174 88
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 19.465648854961174 102
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f366a0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f71121771d0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc87fd0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 8.015267175572248 27
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 13.74045801526671 43
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 15.267175572518568 47
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 17.17557251908339 58
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 19.465648854961174 66
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 19.465648854961174 89
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 19.465648854961174 103
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f71134a97f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 8.396946564885212 28
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 14.122137404579675 44
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 15.648854961831532 48
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 17.557251908396353 59
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 19.847328244274138 67
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 19.847328244274138 90
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 19.847328244274138 104
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112110da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 8.778625954198176 29
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 14.50381679389264 45
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 16.030534351144496 49
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 17.938931297709317 60
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 20.229007633587102 68
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 20.229007633587102 91
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 20.229007633587102 105
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 8.015267175572248 25
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 8.778625954198176 30
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 14.50381679389264 46
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 16.030534351144496 50
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 17.938931297709317 61
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 20.229007633587102 69
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 20.229007633587102 92
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 20.229007633587102 106
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121771d0> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc87fd0> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 3.0534351145037135 12
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 8.015267175572248 26
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 14.50381679389264 47
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 16.030534351144496 51
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 17.938931297709317 62
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 20.229007633587102 70
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 20.229007633587102 93
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 20.229007633587102 107
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7f7112177f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177cc0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a97f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fa01d0> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7f71135485f8> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7f71134068d0> 8.396946564885212 27
backprop <src.mcts.MCTS_Node object at 0x7f7113455908> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7f712fc87748> 14.885496183205603 48
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 16.41221374045746 52
backprop <src.mcts.MCTS_Node object at 0x7f712fc660f0> 18.32061068702228 63
backprop <src.mcts.MCTS_Node object at 0x7f71182616d8> 20.610687022900066 71
backprop <src.mcts.MCTS_Node object at 0x7f7118261160> 20.610687022900066 94
backprop <src.mcts.MCTS_Node object at 0x7f716c01ff98> 20.610687022900066 108
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->3->26->8->24->0->7->0->1
Best Reward: 0.3816793893129642
iteration: 149
found coverage increase 0.3816793893129642
Current Total Coverage 69.08396946564885
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121107f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121290b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112177c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121290b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112177860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112faef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121105c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121104a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134a95f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120e16a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112177400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e16a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 5100
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d9b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121385f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120f0da0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71120ae518> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112177860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439e8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120430b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120435c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120519e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120519e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120189e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120189e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120189e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120aedd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120519b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 5300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120519b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120519b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112051c18> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d5c0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beeb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beeb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beeb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee898> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee4e0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee4e0> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120352b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120352b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121294e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120352b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcc88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b604a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b604a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b604a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60438> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b60fd0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113548588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a96d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135147f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a96d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113514b70> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135faa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fae080> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180178d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d4a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc87e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113514748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135559e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135559e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113548208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc668d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135559e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135559e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 25
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2977f0> 0.0 26
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135dae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135dae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182612b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135da6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135fa0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182618d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135dae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112faef60> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71180172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135daeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113455cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134926a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711358e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c01f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fae198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f4db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134a9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 5700
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f59a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135362b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fea6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f59a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135362b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f711b297f60> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112faec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fae0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c01fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f4d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711358e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1da0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118017128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b6cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113484b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113536780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135483c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc87518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134a9da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134062e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118028a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118028d30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112feaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112feaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b6c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112feaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f59400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183860f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183860f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183d1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183860f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c79eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113455748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711831f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711831f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135da668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118028a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134066d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118017128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b297710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112feaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c79eda0> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113484f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c63fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113567be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c63fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113514668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118343f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118261240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b27e470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113567ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182e5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182e59b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135255f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135255f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113492588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113525400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134064a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc77438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcabfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118343860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113525438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182c2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fcabfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182d8eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b0724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71135ea4e0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182acc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b27e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fa06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 12
Completed Iteration #0
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182acda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182efc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fcabfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b0722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182e5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0300b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c671f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b60dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113555dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fccda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b60dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b072d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0722b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0723c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118386e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1c18> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b0722b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134064a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711b072dd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71940530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182574a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182574a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112feaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711830a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182572e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c68acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c68a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfee160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c741c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6bb4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c741c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183861d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c741f60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194053e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c030eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de61a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118257588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113555dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c67f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711830a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113492588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6a8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ef5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6928d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194053780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194003a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c703048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c64a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7194067908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f722d812898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c005080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1b38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c70f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de407f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de407f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c703518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71d7a894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c72ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 6200
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de40898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2c88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7530f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c692240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fd1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7194067a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 8
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df8b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183b1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc50278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f59c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c005ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6921d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1828> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182c2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c0466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7118257ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c70f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c068f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118379400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71135ea1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e27b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e27b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fc96630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716de51400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c6e27b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716df99b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c7f1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711b2f1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f717c6e27b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f716de402e8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd15208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c046b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183799e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de51780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183799e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71183799e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c0d65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6928d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc96048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134741d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0de80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0de80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134741d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f716c077dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a10b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd28dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd28dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ae48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112177f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b482e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c077470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b482e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6e2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711b2bb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b48400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f712fd3ecc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c753630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113536e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c0057f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd15208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c77f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113474128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c692240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182b6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71134622e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112177cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112177550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112177e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f715c030eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121779e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121772e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121772e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fc964a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121779e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df8b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121774a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f712fc66898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c6d66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71135ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120e1e48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c77f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716de614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c040cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7118386da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a780> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121770b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113462a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121770b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121770b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 6500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a19b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f36358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71134d5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121770b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a19e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121295c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121296a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183792b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c665860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112018dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112129dd8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c64a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c0c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474da0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71134d5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120184a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112177588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112018470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120184a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e10f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120354e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120433c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716dfd5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120439b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111b9a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c01f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c7e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120e1ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113474518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c767748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120e1ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f71120ae358> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 18
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f715c09f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112035e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7113406be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f711211d240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb710> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f717c753630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f712fd3eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da58> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111beeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112138748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111b48a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121102e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7112129ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112129ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711211ddd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1add8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71120a1080> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71183a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a14e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112110080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a833c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716c046fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182fc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112129ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71121102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112ffa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aebbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112110630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aebbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71182ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aebbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112fc3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112051b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f1a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112051c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a836a0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f716df99e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71121388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112043ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad97b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110ad99e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 0
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a832e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112043f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a832e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a20> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711211d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7112f0d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a40080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a40b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a40c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a40390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a40470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a40390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a404e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111beeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a409e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a407f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120a1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a83be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112f1ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83be0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a831d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a404a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a40898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a035c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a110b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b27a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a404a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a114e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110b27a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db00> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a119b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a110f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a114a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a03588> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 5
Completed Iteration #0
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a3ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a3cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a3cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a110f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a115f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b7ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7113474cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71120aec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b0e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a030f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7112035a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110b7ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a030f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a030f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a40b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110a11710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a2acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bee780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a83e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a40748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110584320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110584358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110584160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110584e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105970b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110584fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110597860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105842e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bfc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110584a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105842e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110584c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f711200d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105842e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110584400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110597860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584ba8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110584d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110597940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110597940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aeb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a40828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a11d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a83f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ce7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110597940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110ab5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110ad9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7111bdbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a5db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7111bdb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a3c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110584e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110584b70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110b27a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71120ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a3cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110aebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f711200d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110a03cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a03eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110584780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110552320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110552518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a5d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110552908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110a2ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110597da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105a5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110a2a898> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 69.08396946564885
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110552c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110552d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110563160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110552400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110563160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110576470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110576668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f71105a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110576668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f7110552668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f7110563b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f71105769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f7110552e48> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f71105527b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 69.08396946564885
initial coverage: 66.7939
time passed (minutes): 60.089
iterations: 234
number of new inputs: 384
final coverage: 69.084
total coverage increase: 2.29008
