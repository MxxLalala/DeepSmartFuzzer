Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'nbc'], random_seed=1, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7f1fcc067f28>, tc2=<function tc2 at 0x7f1fcc078048>, tc3=<function tc3 at 0x7f1fcc078158>, tfc_threshold=121, time_period=3600, verbose=True)
initial coverage: 7.82443
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e48> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e48> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c95c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2438> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266903c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266907b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266903c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f26690908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266557f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fd68> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266747f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266901d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f26690668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047260b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047262b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047160b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266745c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f266746d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f786dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f78775828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f267a2630> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c97f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c97f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c97f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047372e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047372e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f9a3db7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266743c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266742e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266743c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266742e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26674cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266742e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f26720828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f60> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fc88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266901d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266901d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266745c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266556a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047160f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266556a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046977f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26674358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047263c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047263c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f470> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04580f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04580f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458358> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04936a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04936a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04936a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04936a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04936a0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e898> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Completed Iteration #0
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f865c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04586d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5db38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f772e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ccf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ccf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ccf8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 20
Completed Iteration #22
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ccf8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e922b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e924e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebecf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046978d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046978d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046978d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3edd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3edd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e010b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e719b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e010b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e010b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e016d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e719b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e714e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e714e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fc88> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da58> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e213c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e213c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e218d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e718d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df23c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 1400
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e018d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f9a3dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c92e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f9a3db7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667edd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fa20> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266552b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 6
Completed Iteration #10
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eda0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f868d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e715f8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f779b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f775f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f779e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f779b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f776a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f775f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf358> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b40f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046723c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 1700
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04588d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046975f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04588d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046971d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 1800
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe5f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e927b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e927b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e927b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e927b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb64a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26674438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d710> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266745c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267209b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047164a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f955c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047164a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f866a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266740b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b85c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f868d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e215c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 2000
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f864e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f864e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f864e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f864e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6935c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6937f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6937f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6937f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6933c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6937f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6419e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6417b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6419e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e6a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6936d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6936d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d54e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebb70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf79b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf79b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf79b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6936d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6936d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641be0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab557f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeedd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeedd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6412b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6412b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6412b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c8d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab174e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab176d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab315c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac46a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab312b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab173c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc37b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac45c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae59e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae59e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab461d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab461d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab461d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 2600
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab464a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb518> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f047164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047163c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 2700
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046975f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb2e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04584e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26690f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04937f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26720e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04937f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04937f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee04937f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047164a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa96438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26720a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493fd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26690048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 2800
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04672908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaac4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9fbfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04672e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f046b4630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff06a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb61d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04697eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ed3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f786dd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7c88> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f3e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f047371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f9a3dbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475be80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655d30> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2672fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0458080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcdac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6ebe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ef8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26674630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd6d8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee043e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaae54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e716d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f26655a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f046875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266e28d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04687080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04687d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb641898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1f04687710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f2cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04737400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f868d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0475b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab46d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f26655a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabf74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab555c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da7908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e217f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab555c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f266a4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e10> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6935f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6935f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6935f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6935f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6935f8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab559e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6933c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab553c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6933c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab553c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e218d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c2e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dd8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee04581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9eb6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f5d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04737400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f77470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f267a25f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f266b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d3d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb6fba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04716198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ee044f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9df28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21d68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f4a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e71320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f046b46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ee0493dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e208> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f267208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 3
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 4
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 5
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 6
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 7
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 8
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 9
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 10
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 11
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1f0473f5f8> 0.0 12
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04697eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab173c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab173c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabeeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab172e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab669b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ff0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9dcd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab173c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab8c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabc39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab550b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab172b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3300
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab664e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab666d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab666d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab664e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f2667ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1f04726940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab664e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab660f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab660f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66be0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa400f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa400f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa9e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e0ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1f04726940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab174a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa404e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa404e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa401d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e21a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9daccc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9d48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb66e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfda58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebe240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab550b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdda0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbfa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab25e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee1d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7df98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d550> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fe48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fa20> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e92860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e01128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed68> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 3600
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dacb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d395c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d395c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9ebed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebb693828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebb65c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ceda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebabee128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaa40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9de3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d399e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d399e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dbffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e5f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 3700
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c509b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c724e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5ff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c959e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d399b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9e9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50eb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c727b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ceda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3800
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c91d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72e80> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c374a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dace48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab177b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab55400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d0bf28> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8e48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4eb70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b12b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b12b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab66160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c95208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebaaaa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c37860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b00> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d39ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d1f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9581cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95697f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95699b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95697f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb950a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb950a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb950a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb950aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb950a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb950a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb950ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95697f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb950ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9da79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9579278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9569ac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9dfd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ebab17e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c506a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c506a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c722b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f86208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c90f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e5f8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c509b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c726a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c509b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c508d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c809b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cedb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9ced160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d4e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1ed9f869e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c801d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 7.8244274809160315
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 4100
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c505c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c80c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c2cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c505c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb959ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c505c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb959e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9d7d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb95c9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9cb88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c72780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c5f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c50b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1eb9c502e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 7.8244274809160315
initial coverage: 7.82443
time passed (minutes): 60.3944
iterations: 161
number of new inputs: 0
final coverage: 7.82443
total coverage increase: 0
