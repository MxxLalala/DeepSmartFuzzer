Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'nbc'], random_seed=1, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7f09177e9f28>, tc2=<function tc2 at 0x7f09177fa048>, tc3=<function tc3 at 0x7f09177fa158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 13.3803
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a17f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1470> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084641b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4127f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642ccc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4127f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4127f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c26a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c28d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c28d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c28d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f084642ce10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f85f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a20> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1d38d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1907b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1907b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1402b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084642c4a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1570b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d36a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c167e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c20b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4120f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5cb81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08cc698b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880682fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880682f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880682fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e5ca2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c66a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f093605f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c66a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868092cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868092ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f088001ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5d0e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868092f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5d58860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0868092eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084644ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806756d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806756d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806756d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806756d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132710> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4125c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1c21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f83c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f83c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1676d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e57b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868092eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c20b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c20b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c20b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a15c0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d16d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f926d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f926d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd898> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Completed Iteration #0
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4263c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5d58860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1907f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1907f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3b70> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680355c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826fa32b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1570b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1570b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec62e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec62e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f334e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33208> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 20
Completed Iteration #22
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33208> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a4a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ededd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1907f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1907f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1907f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6470> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e917b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e919e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e919e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e917b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e917b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea10f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 12
Completed Iteration #18
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5d58860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3358> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e819e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e819e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb70> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e706a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e703c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826eba978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e254e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e254e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ac8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd96a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826defc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826defc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826defc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f635f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e915f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826def3c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826edeef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d411d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d411d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d417f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daacc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 1400
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d306d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e48> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d368d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d301d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def978> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec69b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec69b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d30ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 6
Completed Iteration #10
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f921d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868092f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086804f7b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd748> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4263c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4263c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804f0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f093605f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f093605f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffda58> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 1700
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5cb81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801ccc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f093605f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f093605f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642cbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d35c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4263c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4263c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826deff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826defda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 1800
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826deffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826defbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826defbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5c18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826defc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e81898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5ca2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e810f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e810f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08cc698b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d750b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6438> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e252b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f093605f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1578d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e259b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806e2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868092ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd198> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d12b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f333c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d12b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 2000
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d655c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d655c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d65278> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e703c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e703c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e703c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e703c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e703c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e704e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d757b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d39b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d756a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ed68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ed68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd4e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d417f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806e2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d417f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826daa898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1328d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e707f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e707f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e707f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e707f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d410f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176186a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176004e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176004e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fe10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d410f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d416a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d416a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d416a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d410f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d410f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e70438> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd630> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fddbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763ef28> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f081763e0f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd70f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d415f8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f892b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f892b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081762af60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762acc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081762acc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f570f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f572b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f572b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f572b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f256d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f57470> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f322e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f322e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f254a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f322e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f322e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f136d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f133c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f133c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f133c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eea828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f32eb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efcd68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e959e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e950b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e959e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95780> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 2600
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e848d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e848d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f132e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e632e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e630f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63f28> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 2700
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdde80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdde80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91dd8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 2800
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817600630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d65ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176189b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1574a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176189b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1574a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1574a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08176006d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f093605f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5d3c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806e2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f088001c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1577f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebaeb8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176005f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddb70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebad68> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680358d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680358d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680356a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680358d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680357f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868092e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680357f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680357f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a54e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a1278> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084642c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e810f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e810f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1e55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e810f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f57eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826deff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826deff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826deff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826deff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826deff28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826deff28> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d752b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1671d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1671d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5ca2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c140320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c132a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d309e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0936059d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d309e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0817600be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5ca2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826defc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1670f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 3
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 4
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 5
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 6
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 7
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f890f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 8
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 9
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 10
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 11
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 12
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c140080> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c140978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c67b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c412d30> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3300
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0936059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f327b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7da0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f322e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f327b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f327f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f327b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5ca2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f322e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e198> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e631d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f896a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f890f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f896a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e84b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f325c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e841d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e841d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c1404e0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f133c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eeae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eeaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f13ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e840f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f894e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826daa240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e701d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f894e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f894e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e84fd0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e958d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816eea3c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163671d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163675c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163671d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163671d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f325c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b588> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f899b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163678d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163121d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163239e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163361d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163235f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 3600
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163235f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163239e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163239e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816312d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163670b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e844e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e844e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e701d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367978> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162904a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 3700
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162908d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816290fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162907f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e16a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d417f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e16a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08162e1ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162692e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbb00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3800
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162105c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162101d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162043c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162043c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816269b38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163122e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163122e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163122e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816312160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816269e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b831d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b831d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be44e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be41d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162694e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca438> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0748> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b830f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b834a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162047b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162047b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162042b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b404e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b404e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b40710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b404e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b604e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b503c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b503c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b500f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b500f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b500f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b503c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b40438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816269128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815be4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815be4940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b262b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b392b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b262b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b397f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b396d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b396d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b269e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b396d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b26630> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 4100
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b265f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b39828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b60ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa74e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa74e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa74e0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0815a87668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 4200
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e704e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e70860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7b00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163670b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fac8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c426ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f13390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826cd7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eea358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762a320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762af28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f136d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d817f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eea358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082c426c88> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d41080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163672b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081762ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163672b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163670b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e701d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163670b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f130f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826cd71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d817b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f130f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d817b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163670b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f321d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ede2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f32668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081763eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e70f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7208> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ede048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f89278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f33198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4ecc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f328d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163366a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163366a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d36240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d368d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084641bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084641b8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d4f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0d1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816f25320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816f25ef0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a877f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f336a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a877f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162c6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 16
Completed Iteration #16
Best Reward: 0
coverage_call_count 4500
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f323c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815a877f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d36e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826edea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5d30> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f259e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086804fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826defac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c190128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd90b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd90b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817618278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9da0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868092e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1329b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806a55c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0817618048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f332b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e397c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c0c6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a16a0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1325f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fbef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f4e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 9
Completed Iteration #13
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f7a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0868035390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e4e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d30710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f323c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f89be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816efc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162c6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163369b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e39ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c157668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08806757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163369b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081763ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816367d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815aa7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ffdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f32978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d81ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816336358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826eba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826def828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08806751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163362e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176006a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163362e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08801c5198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c167860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c167860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826d652b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d652b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816336b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08e5d3c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d81ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826eba8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08801c5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e1fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816efc550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f13d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1d39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e1aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c190908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 6
Completed Iteration #9
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084644afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817600470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0880675438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f5b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f637f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c4126a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e95438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0868035390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826fa3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826f639e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e633c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e633c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826edea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c132550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e250f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e250f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e63198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0817618828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e636d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e636d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f33198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e636d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daa0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826daae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d65e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ea12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 4800
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e104e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826e81940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e104e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c11c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826d75940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0880675438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e106a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e81940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af85c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826def198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e104a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e104a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e104a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816312cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162101d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d30710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163230b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162101d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086804f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e81940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816367d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fbef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816323240> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816eb5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d65550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082c412cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816312b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f25240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e63be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08680a1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081762ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816ff76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826dd9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e104a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d75eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162109e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815af8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b506a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b506a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b506a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b836d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b502e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815b502b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816323f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b836a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b836a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162100b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826daae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f573c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162100b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815a87908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b836a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ea1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b83d30> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816f57160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e10ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b409b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b406a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162696a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162699e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162699e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a7cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162694a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e63be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162049e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08680a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c412cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e102b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08176185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816269f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162e1cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f63390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e840f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e25eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176000b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e1a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e840f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e840f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e840f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08176000b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f922e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 21
Completed Iteration #21
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b392b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b50828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816210400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0710> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826d41080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b83080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af87f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f920b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f925f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815af87f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f925f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ebae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e95a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08163126d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0815bca390> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b18dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b505c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b264e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b392b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816e7cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b392b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826f92550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b264e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162a7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b266d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162e1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e10ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bca4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162048d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 5200
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b266d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162048d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815b26c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bc0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816323b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816290390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816290b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816269278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ae1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826e91978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0817600470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b50828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816e7c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08162e1b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08162bb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b60550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4518> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b395c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082c1c2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084642c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b395c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b609b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815be4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b39198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 11
Completed Iteration #15
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d280b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ec60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b83cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3b70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816fdd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bfaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826f92be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815b399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814ce74e0> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0816204160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c53588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c53160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c53898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c531d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 5400
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c53400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c53160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c531d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816210978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c53f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c53a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c53f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c53a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c53a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1c50> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b26e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb19b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815bcab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb19b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815be42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb19b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43898> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c028d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b39198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1a20> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 5500
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c17b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b18780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c024e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b399e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c026a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c024e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c024e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c024e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08147d6128> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b260b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c65588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c85f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0815ab4d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0814c85898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 5600
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b29e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b29e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814c368d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c539b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b60048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c539b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814d1cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147c1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081478e080> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c43438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c36d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c36cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c025f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c43128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147484e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08147b2128> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476f198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814711198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814711550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814711908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814711748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814711b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814711eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147292b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814711f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147297f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147111d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814711cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147297f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147297f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477ebe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c02f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0814711978> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147117b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081476f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d1c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081477e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814711dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814ce7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815b393c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814d28cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0816204710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814748da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814c65b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814c02cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147d69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081476f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f081476ff98> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081478ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147290f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147d6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814cf3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814711cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814748588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08147b2d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f081478e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f081479fcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081477e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146ff208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146ff5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08146dc828> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f081479f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146dc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08146f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146f1e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0814729080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dc8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0815bcab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0814729e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08147b2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08146dce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08146ffd68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 13.380281690140844
initial coverage: 13.3803
time passed (minutes): 60.0851
iterations: 227
number of new inputs: 0
final coverage: 13.3803
total coverage increase: 0
