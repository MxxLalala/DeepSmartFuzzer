Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='clustered_random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'nbc'], random_seed=2, runner='mcts_clustered', save_batch=False, tc1=<function tc1 at 0x7ff9a441cf28>, tc2=<function tc2 at 0x7ff9a442d048>, tc3=<function tc3 at 0x7ff9a442d158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 13.3803
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff90c695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2e8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee717f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee717f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13abe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee715c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee715c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff90c695a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee809b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a5f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1162e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1161d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1161d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 200
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1169b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1162e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1161d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1169b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1262b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1262b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1261d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1269e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1262b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff90c695a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee715c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0807b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0807b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 300
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0807b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff90c695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080978> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1165c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c6d8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e00387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e00383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9707281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200452e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff970712eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff970788d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff968019048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200452e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920045240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00384a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00380f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e00385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff97077e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ebe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1169e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808bb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 11
Completed Iteration #10
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1161d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c054c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00385c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038ef0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff90c695780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff90c695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0926d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0800f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080898> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 600
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0922b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1161d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0922b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0922b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0806a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee994a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee994a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee997b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 700
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00385c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00385c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ac88> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e00387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1265c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c2e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee713c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee804a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee713c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8eee716d8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1262e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee715f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1262e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1262e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e208> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87680b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87755c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 900
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87419b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87419b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87419e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87419b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87419b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee717f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee717f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87282b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87282b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87282b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87282b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 1000
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d48d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86912b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86918d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a28d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87412e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86919b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 1100
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2cf8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866beb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866beb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bcf8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 1200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81940f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81944e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81944e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81944e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a866be48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81019b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81011d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81701d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81019b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81705c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81709b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81705c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81709b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80decc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ded30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81010f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082898> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80eff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee802b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87684e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c88> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecf98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee800b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9727cc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee800b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff970788d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff970712e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920139748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920129c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff970712e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200452b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200451d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920045080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff970712eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920129b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e00382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb00> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e00383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff97077e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c5f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80822e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 1700
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80deb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80dea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80deb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80deb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920129b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ded30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ded30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81943c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81943c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0800f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1261d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1261d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1261d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1261d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ffd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c88> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee712e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 15
Completed Iteration #24
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080cc0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87280b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86915f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2dd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1166d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1166d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920129b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1164e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81017f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ec50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0926d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d53c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81704e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87288d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81707f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810edd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80984a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 16
Completed Iteration #14
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc1d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 20
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcf8> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920129b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81014e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81014e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5eccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81014e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81014a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5aff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afc50> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80987b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5151d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5155f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5152b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920045208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5aff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5159e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5235f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5235f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5235f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec3c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5235f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f470> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef60> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4870f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4874e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4875f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4873c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4873c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4871d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4873c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4875f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4873c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 2500
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2cf8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2cf8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e31d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5237b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4422e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5237b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4429b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4774a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1165c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4424a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ada0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ada0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1165c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3080> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4771d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4772b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4305c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4771d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aba8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4304e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4774a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4774a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4773c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4304e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4774a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4304e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81709e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0920b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0927b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0927b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81709e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0927b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e5f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4770f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaeb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae400> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1267b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86919e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4776d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86919e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2320> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81272b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81272b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff970788d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200453c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff92004c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920045048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fcc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 3000
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81274e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff920129c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff920129c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff920129c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff920129c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fe48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a819be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c05468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeeccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec6d8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86915f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec518> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec550> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4872e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4876a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80988d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e487898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4879e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4879e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4879e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5235c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5235c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54ffd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4422b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce160> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5238d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5155c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5155c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e515a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810eb00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7230b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7135c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7238d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7238d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5237b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7132e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bbb70> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ebe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe48> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3700
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6751d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b39b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6759b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68eef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68eef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acf8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1caa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e71d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e48> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e77f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d195e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e79b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6750f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1676d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6750f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6750f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1672b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1037f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1201d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1037f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d103c50> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1039e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1befd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1039e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1035f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1677f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1039e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1beac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173278> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1039b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1677b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1677b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1031d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e80f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 4100
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0912e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0415f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8a90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0555f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0559e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d055390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8768a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87680f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0910b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d091278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0410b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80824a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0410b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7231d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80824a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7237f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7237f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d73afd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7237f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7234a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7234a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5155c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee5c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7234a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e45a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d7234a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d723b00> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e54f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d47b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d041da0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d055080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86911d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1160f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86b2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ece10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200ec278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ecef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098b70> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 4400
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff96808b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cebe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee71e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cebe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cee80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb00> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e515d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbf60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80ef588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff90c695b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeddeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeedde10> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e515630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d73a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee99e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff96808b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920129c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d041f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ce550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a810ebe0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff920045128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff92004cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff970788d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87414a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff920045128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81702e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81709e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87414a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8170a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec06f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8741668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec04ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c470> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff92004cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c05468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec116828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a878d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9200bcf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a87410b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920129c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d723358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038d30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec13a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8728b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee80208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e442748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57c550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81941d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81941d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e45af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a8194358> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 10
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0926d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec092b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814a390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a874e240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e00389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8101278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5af828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e442198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9707281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920139748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee994e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8082080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200bc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81aec88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14ff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8691128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4771d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e477c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5afd68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4775c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e57cf98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d041390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0915c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81ae208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0915c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec126b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d091a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0915c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c1d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920129c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff920139748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec080278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a81941d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89ee7dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff92004cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec03fba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d173cf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8eee4aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a87759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5233c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4772b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9c0546d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8e0038f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4879e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4877b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4877b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e487b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4877b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6b32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a80def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a81d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5ccd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e58fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a34e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a38d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 3
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a80deb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff9200c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a819be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5230b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e42ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8ec0929e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4305c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 12
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeaef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d173b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6757f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e70f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1200f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cac50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1202e8> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1207f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1207f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1207f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1207f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1caeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a86c0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1036d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1037f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1037f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d103e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1037f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca080> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e44cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4872b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8e005a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d103d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4872b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e487e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e477908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d675128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec1169b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e523ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 5000
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1730b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d1030f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1957b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1957b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1957b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1959b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef320> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1957b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1952e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1952e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e5239b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1952e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d195940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d195eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1957b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec14f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a819be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4775c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4775c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d091fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e4775c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d6ef8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d63a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1209b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1e7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d167a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d7136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e523be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e430630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e978> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d120b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1bea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d167fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89e5a2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d64fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d62acc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 16
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d713940> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d37b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7048> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 6
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d63aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d6efc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8775c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec05e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a8127978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89dfd6160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8eeeae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d675128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d12fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1a3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8a866bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0efa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d713048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d62af60> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0ef400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 15
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2507f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e4305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d12fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2507f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2507f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d173b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff8ec15cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d65c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff8a814aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c250588> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d1be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d1ca278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 19
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2085f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cfd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 1
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2082e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2431d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2080> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
coverage_call_count 5500
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897bfeb70> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 7
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2435c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2435c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d167898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2509b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b29b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b29b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c250b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b595f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b67550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b673c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b676a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b67b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b679e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b67b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b679e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b67d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b595f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b679e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b595f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2436a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 8
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b67c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b67e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b67cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b598d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b67550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b67160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c21c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b677b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b598d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b598d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d62a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b598d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eda0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 14
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d68e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89e42a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b595f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b595f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e7b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 2
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b039e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b030f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b314a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b31828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b31940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b030f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b31fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897be6be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 11
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b317b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b67908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b31be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897adaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 13
Completed Iteration #21
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897adab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897adacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b317b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897adae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897adae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b9eb00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c243198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c33c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b31128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b31f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b31128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d0e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b8efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c243b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b31518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b674a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c243198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897be6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 13
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c208898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a84518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b59c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c23c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a84518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897b03668> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b039e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c23cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a915f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a84630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a84630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b59940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a915f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a917f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 17
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abc710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abc710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abc0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a914a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 15
Completed Iteration #18
Best Reward: 0
coverage_call_count 5800
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa09b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a914a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 9
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a91710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a919b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c22c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c208e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b9e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a84d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a849e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897abce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897bfe278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897aa06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2b2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897be6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a91ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897aa0ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a84ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897adacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b315c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897adacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a84ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a4cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897abc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a84f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b037f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897b03a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b3f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3fc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c250f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89c2d3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897adacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b3fc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897b03c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff89c33cf60> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 18
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b31eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a914e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a068d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a067b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a069e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897aa05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a069e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a062e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a13208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a069e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a069e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a13390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a13400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a13940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a067b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a13be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a067b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a13518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a13f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a13390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a06e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a23240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a13c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff897a06048> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 13.380281690140844
cluster_index 4
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a23588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a238d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a23b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a23048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a23048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a239e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a061d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a060b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897ada828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a239e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a06898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 5900
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897b03e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a239e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a4cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897ada828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a239e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a23588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff897a4c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7ff89d06b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7ff897a06748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7ff897a062b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 13.380281690140844
initial coverage: 13.3803
time passed (minutes): 60.0983
iterations: 230
number of new inputs: 0
final coverage: 13.3803
total coverage increase: 0
